{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO8VRG1UF0DwIN1/h18YYog",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/MVA/blob/2023/ex15notebookB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MVA2023 ex15notebookB\n",
        "\n",
        "<img width=64 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/MVA-logo15.png\"> https://www-tlab.math.ryukoku.ac.jp/wiki/?MVA/2023"
      ],
      "metadata": {
        "id": "P4preLw7SzqH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I226xIKJbqtM"
      },
      "source": [
        "# いつものいろいろインポート\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()\n",
        "\n",
        "# SciPy の DCT と FFT の関数\n",
        "from scipy.fft import dct, fft, ifft, fftfreq\n",
        "\n",
        "# 科学技術計算のライブラリ SciPy の中の WAVE ファイルを扱うモジュール\n",
        "from scipy.io.wavfile import read, write"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "## 演習問題 - 音のデータの DFT\n",
        "----\n",
        "\n",
        "音のデータをDFTして分析してみましょう．"
      ],
      "metadata": {
        "id": "W6bu4DEYG3g3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 準備"
      ],
      "metadata": {
        "id": "EyNVaMlP992A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ネットから WAVE 形式のファイルを入手するので，WAVE形式のファイルを読み込む関数を定義しておきます．"
      ],
      "metadata": {
        "id": "SxS0wttR-PXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WAVE ファイルを読み込む関数\n",
        "#\n",
        "def readWAVE(filename):\n",
        "\n",
        "    framerate, data = read(filename)\n",
        "\n",
        "    if data.ndim == 1:\n",
        "        nchannels = 1\n",
        "    else:\n",
        "        nchannels = data.shape[1]\n",
        "    nframes = data.shape[0]\n",
        "\n",
        "    print('filename = ', filename)\n",
        "    print('nchannels = ', nchannels)       # チャンネル数\n",
        "    print('framerate = ', framerate)       # 標本化周波数\n",
        "    print('nframes = ', nframes)             # フレーム数\n",
        "    print('duration = {0:.2f}[sec]'.format(nframes / framerate))   # 長さ（秒単位）\n",
        "    print('dtype = ', data.dtype)            # データ型（量子化ビット数に対応）\n",
        "\n",
        "    assert data.dtype == 'uint8' or data.dtype == 'int16' or data.dtype == 'int32' or data.dtype == 'float32'\n",
        "\n",
        "    # 最初の10秒分だけ取り出す（元がそれより短ければそのまま）\n",
        "    nframesNew = min(framerate * 10, nframes)\n",
        "    if nchannels == 1:\n",
        "        dataNew = data[:nframesNew]\n",
        "    else:\n",
        "        # 多チャンネル信号なら0番目と1番目の平均値を取り出す\n",
        "        if data.dtype == 'float32':  # 浮動小数点数のときは [0, 1] の値なので普通に足して2で割る\n",
        "            dataNew = (data[:nframesNew, 0] + data[:nframesNew, 1])/2\n",
        "        else: # 整数型のときはオーバーフローする可能性があるので，いったん64bit整数にしてから\n",
        "            data64 = (data[:nframesNew, 0].astype(np.int64) + data[:nframesNew, 1].astype(np.int64))//2\n",
        "            dataNew = data64.astype(data.dtype)\n",
        "\n",
        "    return framerate, dataNew"
      ],
      "metadata": {
        "id": "DK5GJ-9w-PXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 正弦波"
      ],
      "metadata": {
        "id": "leAPcOXNLRV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "データを準備します．"
      ],
      "metadata": {
        "id": "B96OF8-lD05x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "framerate = 8000       # 標本化周波数\n",
        "vmax = 2**(15-2)       # 16bit量子化で最大振幅の 1/4\n",
        "duration = 2*framerate # 2[s]\n",
        "\n",
        "t = np.arange(duration)\n",
        "\n",
        "freq1 = [200, 400, 600]\n",
        "freq2 = [1200, 400, 800]\n",
        "\n",
        "# signal1\n",
        "signal1 = vmax * np.sin((2*np.pi*t/(framerate/freq1[0]))) \\\n",
        " + vmax/2 * np.sin((2*np.pi*t/(framerate/freq1[1]))) \\\n",
        " + vmax/4 * np.sin((2*np.pi*t/(framerate/freq1[2]))) \\\n",
        " + vmax/2 * np.random.randn(len(t)) # ランダムノイズ\n",
        "\n",
        "# signal2\n",
        "signal2 = vmax * np.sin((2*np.pi*t/(framerate/freq2[0]))) \\\n",
        " + vmax/2 * np.sin((2*np.pi*t/(framerate/freq2[1]))) \\\n",
        " + vmax/4 * np.sin((2*np.pi*t/(framerate/freq2[2]))) \\\n",
        " + vmax/2 * np.random.randn(len(t)) # ランダムノイズ\n",
        "\n",
        "# グラフに描く\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.plot(signal1, '-o', label='signal1')\n",
        "ax.plot(signal2, '-o', label='signal2')\n",
        "ax.axhline(0, color='gray')\n",
        "ax.set_xlim(0, 100)\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oxOU09OYNKt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`signal1` と `signal2` という2つの音のデータを作りました．どちらも，周波数の異なる3つの正弦波を足し合わせたものにノイズを乗せてあります．上のグラフからそれぞれがどんな音か想像する...のは難しいので，WAVE 形式のファイルとして出力して手元のPCにダウンロードし，音を鳴らしてみましょう．\n",
        "\n",
        "1. 次のコードセルに記されたコメントに従ってコードを修正して実行\n",
        "1. 手元に `signal1.wav` と `signal2.wav` というファイルがダウンロードされる．初めて実行すると，「複数ファイルの一括ダウンロードの許可」を求めるポップアップウィンドウが現れるかもしれません．その場合，許可するとダウンロードが始まります．\n",
        "1. 手元のPCでダウンロードされたファイルを再生．WAVE 形式のファイルは，Windows でも macOS でも，OS標準の音楽プレイヤーで再生できるはずです．"
      ],
      "metadata": {
        "id": "HZ9kckd9EXtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "if 1 == 0: # ← の 0 を 1 に修正\n",
        "    write('signal1.wav', framerate, signal1.astype('int16'))\n",
        "    write('signal2.wav', framerate, signal2.astype('int16'))\n",
        "    files.download('signal1.wav')\n",
        "    files.download('signal2.wav')"
      ],
      "metadata": {
        "id": "iDsIuAtNHrx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，`signal1` と `signal2` に DFT を適用してそれぞれのフーリエ係数を求め，振幅スペクトルを描きます．"
      ],
      "metadata": {
        "id": "ReSFdpS6HnMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(signal1)\n",
        "freq = fftfreq(N, d=1/framerate)\n",
        "\n",
        "# signal1 の振幅スペクトル\n",
        "c_dft = fft(signal1)\n",
        "amp1 = np.abs(c_dft)/N # 絶対値\n",
        "\n",
        "# signal2 の振幅スペクトル\n",
        "c_dft = fft(signal2)\n",
        "amp2 = np.abs(c_dft)/N # 絶対値\n",
        "\n",
        "fig, ax = plt.subplots(2, 3, figsize=(16, 8))\n",
        "\n",
        "ax[0, 0].stem(amp1, markerfmt=' ', label='signal1 |Ck|')\n",
        "ax[0, 0].set_xlabel('k')\n",
        "ax[0, 0].legend()\n",
        "\n",
        "ax[0, 1].stem(amp1, markerfmt=' ', label='signal1 |Ck|')\n",
        "ax[0, 1].set_xlim(0, 3000)\n",
        "ax[0, 1].set_xticks(np.arange(0, 3000, 400))\n",
        "ax[0, 1].set_xlabel('k')\n",
        "ax[0, 1].legend()\n",
        "\n",
        "ax[0, 2].stem(freq, amp1, markerfmt=' ', label='signal1 |Ck|')\n",
        "ax[0, 2].set_xlim(0, 1500)\n",
        "ax[0, 2].set_xticks(np.arange(0, 1500, 200))\n",
        "ax[0, 2].set_xlabel('Hz')\n",
        "ax[0, 2].legend()\n",
        "\n",
        "ax[1, 0].stem(amp2, markerfmt=' ', label='signal2 |Ck|')\n",
        "ax[1, 0].set_xlabel('k')\n",
        "ax[1, 0].legend()\n",
        "\n",
        "ax[1, 1].stem(amp2, markerfmt=' ', label='signal2 |Ck|')\n",
        "ax[1, 1].set_xlim(0, 3000)\n",
        "ax[1, 1].set_xticks(np.arange(0, 3000, 400))\n",
        "ax[1, 1].set_xlabel('k')\n",
        "ax[1, 1].legend()\n",
        "\n",
        "ax[1, 2].stem(freq, amp2, markerfmt=' ', label='signal2 |Ck|')\n",
        "ax[1, 2].set_xlim(0, 1500)\n",
        "ax[1, 2].set_xticks(np.arange(0, 1500, 200))\n",
        "ax[1, 2].set_xlabel('Hz')\n",
        "ax[1, 2].legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CKP7ShhI4Zs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上段が `signal1` の振幅スペクトル，下段が `signal2` の振幅スペクトルです．\n",
        "左は，横軸 $k$，縦軸 $|c_k|$ で横軸の範囲を $[0, N-1]$ として描いたもの，真ん中は，横軸の範囲を狭めたものです．\n",
        "右の図では，横軸の範囲は真ん中と同じですが，横軸の単位を周波数 [Hz] として描いています．\n",
        "\n",
        "`signal1` と `signal2` のどちらの音も，周波数の異なる3つの正弦波を足し合わせたものにノイズを乗せて作ってあります．元のデータの波形を眺めたり音を聞いたりしただけではどんな成分が含まれているのか分かりづらいですが，振幅スペクトルを見ると一目瞭然となっています．"
      ],
      "metadata": {
        "id": "y8uTfozjIZ1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 問題1\n",
        "\n",
        "次のことをやろう／考えよう．\n",
        "\n",
        "(1) `signal1` と `signal2` は，どちらの方が高い音に聞こえますか？\n",
        "\n",
        "(2) それぞれの音に含まれる成分のうち，主要な（振幅が大きい）成分は，周波数が何Hzのものですか？ それぞれの音で3つずつ答えなさい．\n",
        "\n",
        "(3) 振幅スペクトルによると，`signal1` と `signal2` ではどちらの方が高い周波数の成分を含んでいますか？ （(2)で求めた主要な成分に注目して考えよう）\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ePDU_DdCHJMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 猫の鳴き声\n",
        "\n",
        "別の音のデータで実験しましょう．\n",
        "\n"
      ],
      "metadata": {
        "id": "cOc2sZ1VLU7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WAVE ファイルを入手します．"
      ],
      "metadata": {
        "id": "tyBBxgdv-PXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WAVE ファイルを入手\n",
        "#\n",
        "### こちらのサイトの素材を利用させてもらってます http://www.ne.jp/asahi/music/myuu/wave/wave.htm\n",
        "\n",
        "! wget -nc http://www.ne.jp/asahi/music/myuu/wave/cat1.wav\n",
        "fnCat = 'cat1.wav'\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists(fnCat):\n",
        "    print(f'{fnCat}のダウンロードがうまくできていないようです')"
      ],
      "metadata": {
        "id": "L2-We3hi-PXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，`cat1` と `cat2` という二つの配列を作ります．"
      ],
      "metadata": {
        "id": "wsMcEgGg-PXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cat1\n",
        "fr_cat1, cat1 = readWAVE('cat1.wav')\n",
        "N_cat1 = len(cat1)\n",
        "print(fr_cat1, N_cat1)\n",
        "\n",
        "# cat2\n",
        "cat2 = np.copy(cat1)\n",
        "N_cat2 = len(cat2)\n",
        "fr_cat2 = fr_cat1//2\n",
        "print(fr_cat2, N_cat2)\n",
        "write('cat2.wav', fr_cat2, cat2.astype('int16'))"
      ],
      "metadata": {
        "id": "qEHG1pC2-PXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`WavFileWarning` という警告が出るかもしれませんが，気にしないでokです．"
      ],
      "metadata": {
        "id": "T0B8Py6u-PXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "次のセルをコメントに従って修正してから実行し，それぞれのWAVEファイルをダウンロードして音を聞いてみてください．"
      ],
      "metadata": {
        "id": "KW7a-e8oUTpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "if 1 == 0: # ← の 0 を 1 に修正\n",
        "    files.download('cat1.wav')\n",
        "    files.download('cat2.wav')"
      ],
      "metadata": {
        "id": "tf0nL-M-M8Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 問題2\n",
        "\n",
        "上記の `cat1` と `cat2` のデータに DFT を適用して振幅スペクトルを描くと，下図のようになりました．音を聞いた結果から，どちらが `cat1` でどちらが `cat2` かを考えなさい．\n",
        "\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/ex13catspec.png\">"
      ],
      "metadata": {
        "id": "ngjVdgr1TDD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 楽器が出す音の性質と音の高さの知覚"
      ],
      "metadata": {
        "id": "0ssN6wo5f-bP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ギターのような弦楽器では，両端が固定された（指で押さえることで固定される位置が変わったりもしますね）弦が振動しそれが空気を振動させることで音が生み出されます．このとき，弦の振動は，下図に示すようなパターンを示します．左は両端が固定された弦の振動としては最も波長が長いもの，真ん中は波長がその $\\frac{1}{2}$，右は波長 $\\frac{1}{3}$ の振動を表しています．これら以外に波長 $\\frac{1}{4}, \\frac{1}{5}, \\ldots$ の振動も現れます．\n",
        "実際の弦の振動はこれらを合成したものとなりますので，そこから生まれる空気の振動もまた，ある波長の波と，その $\\frac{1}{自然数}$ 倍の波長の波が混ざったものとなります．\n",
        "したがって，弦楽器から生み出される音には，最も波長の長い振動に対応した最も低い周波数（これを基本周波数といいます）の成分と，その自然数倍の周波数の成分（倍音）が含まれます．ちなみに，管楽器の場合は少し様子が異なりますが，その音はやはり基本周波数の成分とその倍音から成ります．"
      ],
      "metadata": {
        "id": "ZyTnOL0Es-MM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(16, 3))\n",
        "\n",
        "t = np.linspace(0, np.pi, num=100)\n",
        "\n",
        "# 基本波長\n",
        "ax[0].plot(t, np.sin(t), '-', color='red')\n",
        "ax[0].set_ylim(-1.5, 1.5)\n",
        "ax[0].plot(t, -np.sin(t), '--', color='red')\n",
        "ax[0].axhline(0, color='gray')\n",
        "ax[0].xaxis.set_visible(False)\n",
        "ax[0].yaxis.set_visible(False)\n",
        "\n",
        "# 波長 1/2 = 周波数 2 倍\n",
        "ax[1].plot(t, np.sin(2*t), '-', color='red')\n",
        "ax[1].set_ylim(-1.5, 1.5)\n",
        "ax[1].plot(t, -np.sin(2*t), '--', color='red')\n",
        "ax[1].axhline(0, color='gray')\n",
        "ax[1].xaxis.set_visible(False)\n",
        "ax[1].yaxis.set_visible(False)\n",
        "\n",
        "# 波長 1/3 = 周波数 3 倍\n",
        "ax[2].plot(t, np.sin(3*t), '-', color='red')\n",
        "ax[2].set_ylim(-1.5, 1.5)\n",
        "ax[2].plot(t, -np.sin(3*t), '--', color='red')\n",
        "ax[2].axhline(0, color='gray')\n",
        "ax[2].xaxis.set_visible(False)\n",
        "ax[2].yaxis.set_visible(False)"
      ],
      "metadata": {
        "id": "ydLjq_wbDLcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "一方，人間の聴覚系が知覚する音の高さは基本周波数と強く関連しており，基本的には，基本周波数の高い音ほど高い音に聞こえます．楽器や演奏の仕方が異なると，同じ音の高さでも音色が異なって聞こえますが，これは，基本周波数が同じで，倍音成分の含まれ方が異なるためです．基本周波数の成分がほとんど含まれず周波数2倍以上の倍音成分しか含まれないような音でも，基本周波数に対応した高さの音として知覚されます．"
      ],
      "metadata": {
        "id": "ddbFrVuRJzuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### ギターの音\n",
        "\n",
        "ギターの音を録音したデータから，何の音が鳴っているのかを当てよう．\n"
      ],
      "metadata": {
        "id": "p0331MyZVlDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WAVE ファイルを入手します．"
      ],
      "metadata": {
        "id": "KRxdkDYviEKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WAVE ファイルを入手\n",
        "#\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/Sound-Guitar1-C.wav\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/Sound-Guitar2-E.wav\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/Sound-Guitar3-G.wav\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/Sound-Guitar4-ChordC.wav\n",
        "fnList = ['Sound-Guitar1-C.wav', 'Sound-Guitar2-E.wav', 'Sound-Guitar3-G.wav', 'Sound-Guitar4-ChordC.wav']\n",
        "\n",
        "import os\n",
        "\n",
        "for fn in fnList:\n",
        "    if not os.path.exists(fn):\n",
        "        print(f'{fn}のダウンロードがうまくできていないようです')"
      ],
      "metadata": {
        "id": "b1bEiScviEKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4つのWAVEファイルをダウンロードして聞いてみましょう．\n",
        "音感の優れたひとは聞いただけで何の音かわかるでしょうが，わからないふりをして先へ進みましょう．\n",
        "ちなみに，これらの音は，本物のギターを鳴らして録音したものではなく，コンピュータで作り出した音です．ギターの音っぽい倍音成分のパターンを知っていれば，それっぽい波形を合成できる，というわけです．"
      ],
      "metadata": {
        "id": "BM3EvovITSIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "if 1 == 0: # ← の 0 を 1 に修正\n",
        "    for fn in fnList:\n",
        "        files.download(fn)"
      ],
      "metadata": {
        "id": "dl05phvIRlzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4つのWAVEファイルのデータを読み込んで，np.array のリストに格納します．`guitar[0]`, `guitar[1]`, `guitar[2]`, `guitar[3]` のそれぞれが音のデータを格納した1次元配列です．"
      ],
      "metadata": {
        "id": "oVMNVqMrV0rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "guitar = []\n",
        "\n",
        "for i, fn in enumerate(fnList):\n",
        "    print(f'##### guitar[{i}] #####')\n",
        "    fr, dat = readWAVE(fn)\n",
        "    dat = dat.astype(float)\n",
        "    dat -= np.mean(dat)\n",
        "    guitar.append(dat)\n",
        "    if i == 0:\n",
        "        N_guitar = len(dat)\n",
        "        framerate = fr\n",
        "    else:\n",
        "        assert len(dat) == N_guitar and fr == framerate\n",
        "    print()"
      ],
      "metadata": {
        "id": "xvGpGlLvZmeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "それぞれの音の信号の波形を眺めてみましょう．"
      ],
      "metadata": {
        "id": "Xq5Cwryomi2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(4, 2, figsize=(16, 10))\n",
        "\n",
        "t = np.linspace(0, N_guitar/framerate, num=N_guitar, endpoint=False)\n",
        "\n",
        "for i in range(len(guitar)):\n",
        "    ax[i, 0].plot(t, guitar[i], label=f'guitar[{i}]')\n",
        "    ax[i, 0].set_ylim(-150, 150)\n",
        "    ax[i, 0].legend()\n",
        "    ax[i, 1].plot(t, guitar[i], 'o', markersize=4, label=f'guitar[{i}]')\n",
        "    ax[i, 1].axhline(0, color='gray')\n",
        "    ax[i, 1].set_xlim(0.3, 0.305)\n",
        "    ax[i, 1].set_ylim(-150, 150)\n",
        "    ax[i, 1].legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9WVeLDsLAens"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "それぞれの図は，横軸を時間（単位は[s]（秒））として音の信号の波形を描いたものです．4つとも2秒強の音です．右の図は，時刻 $0.3$[s] から $0.305[s]$ までの $0.005$ [s] 間のデータ点をプロットしたものです．\n",
        "これらを見ただけでは，どれがどんな音なのかまるで想像がつきません．\n",
        "\n",
        "では，これらのデータに DFT を適用してフーリエ係数を求め，振幅スペクトルを描いてみましょう．"
      ],
      "metadata": {
        "id": "uti6wL5BmpXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# amp[i] が guitar[i] の振幅スペクトル\n",
        "amp = []\n",
        "for i in range(len(guitar)):\n",
        "    coef = fft(guitar[i]) # DFT\n",
        "    amp.append(np.abs(coef)/N_guitar) # 振幅スペクトル\n",
        "freq = fftfreq(N_guitar, d=1/framerate)\n",
        "\n",
        "# 振幅スペクトルを描く\n",
        "fig, ax = plt.subplots(4, 3, figsize=(16, 10))\n",
        "\n",
        "for i in range(len(guitar)):\n",
        "    ax[i, 0].stem(amp[i], markerfmt=' ', label=f'guitar[{i}] |Ck|')\n",
        "    ax[i, 0].set_xlabel('k')\n",
        "    ax[i, 0].legend()\n",
        "    ax[i, 1].stem(amp[i], markerfmt=' ', label=f'guitar[{i}] |Ck|')\n",
        "    ax[i, 1].set_xlim(0, 3000)\n",
        "    ax[i, 1].set_xlabel('k')\n",
        "    ax[i, 1].legend()\n",
        "    ax[i, 2].stem(freq, amp[i], markerfmt=' ', label=f'guitar[{i}] |Ck|')\n",
        "    ax[i, 2].set_xlim(0, 3000*framerate/N_guitar)\n",
        "    ax[i, 2].set_xlabel('Hz')\n",
        "    ax[i, 2].legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EAcOFG9mjJy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "図の見方については，この notebook の上の方で同じようなことをやっているので，説明を省略します．右端の列だけ横軸の単位が違っていることに注意してください．いずれの振幅スペクトルも「弦楽器が出す音の性質」で説明したことを反映したものとなっているのが分かります．\n",
        "\n",
        "次のセルを実行すると，上の右端の列のどれか一つの振幅スペクトルを拡大表示させることができます．コメントにしたがって `i, xmin, xmax, step` の値を適当に定めて実行してみよう．"
      ],
      "metadata": {
        "id": "ccKf8WdWKQ_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(16, 6))\n",
        "\n",
        "# guitar[i] の i (i = 0, 1, 2, 3)\n",
        "i = 0\n",
        "\n",
        "# [xmin, xmax] が横軸の範囲，step が目盛の間隔\n",
        "xmin, xmax, step = 0, 600, 20\n",
        "\n",
        "ax.stem(freq, amp[i], markerfmt=' ', label=f'guitar[{i}] |Ck|')\n",
        "ax.set_xlim(xmin, xmax) # 横軸の範囲\n",
        "ax.set_ylim(0, 6) # 縦軸の範囲\n",
        "ax.set_xticks(np.arange(xmin, xmax, step))\n",
        "ax.set_xlabel('Hz')\n",
        "ax.legend()\n",
        "\n",
        "plt.setp(ax.get_xticklabels(), rotation=60, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tz8qrIqUl5lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 問題3\n",
        "\n",
        "次のことを考えて／調べてメモしておこう：\n",
        "\n",
        "(1) `guitar[0]`, `guitar[1]`, `guitar[2]` の振幅スペクトルを観察して，それぞれの音の基本周波数を推測しよう．下の表を用いて，それが何の音であるかを当てよう．\n",
        "\n",
        "(2) `guitar[3]` の振幅スペクトルと `guitar[0]`, `guitar[1]`, `guitar[2]` の振幅スペクトルの間にはどんな関係があるか考えよう．\n",
        "\n",
        "|基本周波数[Hz]|音名|ハ長調での...|\n",
        "|---:|:---:|:---:|\n",
        "|261.6|C4|ド|\n",
        "|293.7|D4|レ|\n",
        "|329.6|E4|ミ|\n",
        "|349.2|F4|ファ|\n",
        "|392.0|G4|ソ|\n",
        "|440|A4|ラ|\n",
        "|493.9|B4|シ|\n",
        "\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: ここでは，A4 の基本周波数を 440[Hz]として十二平均律を用いたときの1オクターブの範囲の音の基本周波数の値を示しています．\n",
        "</span>\n",
        "\n"
      ],
      "metadata": {
        "id": "gXXKcqAJN8OX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mogWiA65Ad4X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}