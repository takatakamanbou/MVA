{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO/ouJ6mAW5KwlHZAhDOJBy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/MVA/blob/2022/ex10notebookA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MVA2022 ex10notebookA\n",
        "\n",
        "<img width=64 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/MVA-logo10.png\"> https://www-tlab.math.ryukoku.ac.jp/wiki/?MVA/2022"
      ],
      "metadata": {
        "id": "P4preLw7SzqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# いつものいろいろインポート\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()"
      ],
      "metadata": {
        "id": "9HCsHgFjR6jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SciPy の 統計関数群の中の正規分布モジュール (scipy.stats.norm) と多変量正規分布モジュール (scipy.stats.multivariate_normal)\n",
        "from scipy.stats import norm, multivariate_normal"
      ],
      "metadata": {
        "id": "bvL1s89p8I2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 判別分析 (1)\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Snu_5I6aGJS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 判別分析とは\n",
        "\n"
      ],
      "metadata": {
        "id": "aTbB0PMlNM9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 例： $(\\mbox{身長}, \\mbox{体重})$ から「人間」か「ほげ星人」かを判別する"
      ],
      "metadata": {
        "id": "yrG3yyVZwUoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "「人間」と「ほげ星人」あわせて200人分の $(\\mbox{身長[cm]}, \\mbox{体重[kg]})$ の数値を集めたデータがあったとします．それぞれのデータには，人間の数値なのかほげ星人の数値なのかを表す変数も含まれているとします（注）．\n",
        "以下のセルの出力の `Height` 列は身長，`Weight` 列は体重を表します．`Class` 列の値は，人間を表す `Human` とほげ星人を表す `Hoge` のいずれかです．\n",
        "\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: これは，説明を理解してもらいやすくするために作った嘘のデータです．このデータ中のほげ星人に近い身長・体重のひとがいたとしても，そのひとが人間ではないというようなことを主張するものではありません．\n",
        "</span>"
      ],
      "metadata": {
        "id": "PZMaFYJyx3Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 人間 vs ほげ星人\n",
        "URL = 'https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/humanvshoge.csv'\n",
        "dfHoge = pd.read_csv(URL)\n",
        "dfHoge"
      ],
      "metadata": {
        "id": "rTD4kySfwAvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Class` の値で色分けして (`Height`, `Weight`) の散布図を描いてみると，次のようになっています．"
      ],
      "metadata": {
        "id": "2D-NArPxzw_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 「人間 vs ほげ星人」の散布図\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "dfTmp = dfHoge.loc[dfHoge['Class'] == 'Human']\n",
        "ax.scatter(dfTmp['Height'], dfTmp['Weight'], label='Human')\n",
        "dfTmp = dfHoge.loc[dfHoge['Class'] == 'Hoge']\n",
        "ax.scatter(dfTmp['Height'], dfTmp['Weight'], label='Hoge')\n",
        "xmin, xmax = 0, 250\n",
        "ymin, ymax = 0, 150\n",
        "ax.set_xlim(xmin, xmax)\n",
        "ax.set_xlabel('Height')\n",
        "ax.set_ylim(ymin, ymax)\n",
        "ax.set_ylabel('Weight')\n",
        "ax.set_aspect('equal')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "np8JcQZewZgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このようなデータが与えられたときに，「人間かほげ星人か分からない（`Class` の値が未知な）ひとの (`Height`, `Width`) の値から，そのひとの `Class` を決定したい」というのが，判別分析の問題の一つの例です．"
      ],
      "metadata": {
        "id": "kssLUmzd0Udc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 問題設定"
      ],
      "metadata": {
        "id": "HiV9-P_h1jmS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の例では，個々のデータが「人間」と「ほげ星人」のどちらのグループに属するのか決めることを考えていました．判別分析では，これらのグループのことを，**クラス** (class) や **カテゴリ** (category) と呼ぶことがあります．この例では「人間」クラスと「ほげ星人」クラスの二つを考えていますが，クラスの数は3つ以上あっても構いません．\n",
        "\n",
        "判別分析でやりたいことを一般化して説明すると，次のようになります：\n",
        "\n",
        "> 多変量のデータがあり，その個々のデータは複数のクラスのうちのいずれかに所属しているとする．これらのデータを基にして，新しいデータがどのクラスに所属するのかを決定する仕組み（これを **判別関数** といいます）を作りたい．\n",
        "\n",
        "統計学ではこのような問題を **判別分析** (discriminant analysis) と呼びますが，機械学習等の分野では，**分類** (classification) や **識別** (discrimination)，あるいは **パターン認識** (pattern recognition) と呼びます（「機械学習I/II」の授業で出てきます）．\n"
      ],
      "metadata": {
        "id": "lLJioPrg5TdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "これまで扱ってきた多変量解析手法では，変数はすべて量的な変数でしたが，判別分析では，説明変数が量的な変数で，被説明変数は質的な変数（注）となっているとみなせます．\n",
        "\n",
        "<span style=\"font-size: 75%\">\n",
        "※ 注意: より詳しく言うと，「人間」と「ほげ星人」みたいに少数の値をとる，「カテゴリカル」な変数．\n",
        "</span>\n"
      ],
      "metadata": {
        "id": "N712j48D3Tzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 例： Fisher のアヤメのデータ"
      ],
      "metadata": {
        "id": "kKUL6bCcwn98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "判別分析の問題の例をもう一つあげます．植物の [アヤメ](https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%A4%E3%83%A1) の種を分類する問題です．"
      ],
      "metadata": {
        "id": "gEIrkufhAe9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fisher のアヤメのデータ\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris(as_frame=True)\n",
        "dfIris = iris.frame\n",
        "dfIris['species'] = 'hoge'\n",
        "for k, tn in enumerate(iris.target_names):\n",
        "    dfIris.loc[dfIris['target'] == k, 'species'] = tn\n",
        "dfIris.drop(columns='target', inplace=True)\n",
        "dfIris"
      ],
      "metadata": {
        "id": "xY299w7IWHTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このデータは，\n",
        "\n",
        "- Iris setosa: [Wikipedia](https://en.wikipedia.org/wiki/Iris_setosa)，[Wikipedia日本語版 ヒオウギアヤメ]( https://ja.wikipedia.org/wiki/%E3%83%92%E3%82%AA%E3%82%A6%E3%82%AE%E3%82%A2%E3%83%A4%E3%83%A1)\n",
        "- Iris versicolor [Wikipedia](https://en.wikipedia.org/wiki/Iris_versicolor)\n",
        "- Iris virginica [Wikipedia](https://en.wikipedia.org/wiki/Iris_virginica)\n",
        "\n",
        "という3種のアヤメの`sepal length`（がく片の長さ[cm]），`sepal width`（がく片の幅[cm]），`petal length`（花弁の長さ[cm]），`petal width`（花弁の幅[cm]）の数値から成るものです．\n",
        "\n",
        "4つの数値が組になったデータですので，先の例のようにそのまま散布図を描くことはできませんが，4つのうち任意の2つの変数を選んで散布図を描くと，次のようになっています．"
      ],
      "metadata": {
        "id": "kCbQqQHUBBw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seaborn のペアプロット関数（多次元データの変数間の散布図等を自動的に描いてくれる）\n",
        "seaborn.pairplot(dfIris, hue='species')"
      ],
      "metadata": {
        "id": "7xEXhiVsw4Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このデータに対する判別分析の問題は，\n",
        "何らかの方法で，(`sepal length`, `sepal width` , `petal length`, `petal width`) という4つの数値から，この数値の組を持つアヤメの `species` （setosa / versicolor / virginica のいずれか）を予測する，ということになります．"
      ],
      "metadata": {
        "id": "CHLCmVHJEBGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "余談ですが，このアヤメのデータは，有名な統計学者である Ronald Fisher が判別分析の研究に用いたことから，「Fisher's Iris data set」として知られています．多変量解析や機械学習・パターン認識の教科書等によく出てきます．ここでは，scikit-learn という機械学習ライブラリで提供されているものを利用しています．\n",
        "\n",
        "- Ronald Fisher （ロナルド・フィッシャー）:  イギリスの統計学者・進化生物学者， 1890 - 1962， [Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%8A%E3%83%AB%E3%83%89%E3%83%BB%E3%83%95%E3%82%A3%E3%83%83%E3%82%B7%E3%83%A3%E3%83%BC)\n",
        "- [sklearn.datasets.load_iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)"
      ],
      "metadata": {
        "id": "Lz6_svUWIM8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 2クラス1次元の判別分析\n",
        "\n",
        "ここでは，データは1次元，つまり1つの変数のみから成るものとし，さらにクラスの数を 2 に限定して，判別分析の考え方や具体的な方法を説明します．"
      ],
      "metadata": {
        "id": "eOdlNbkqK9IB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 考え方\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "48I5n5mzNDdd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "判別分析では，データの背後に正規分布を仮定します．つまり，個々のデータは，何らかの決まったパラメータを持った正規分布から抽出された標本だとします．その正規分布は，クラスごとに一つずつ考えます．例えば，1次元のデータを「クラス1」と「クラス2」の2クラスに分類する問題の場合，\n",
        "\n",
        "- クラス1の正規分布 ${\\cal N}(\\mu_1, \\sigma_1^2)$\n",
        "- クラス2の正規分布 ${\\cal N}(\\mu_2, \\sigma_2^2)$\n",
        "\n",
        "という2つを考えます．これらの正規分布のパラメータは，与えられたデータから適当な方法で推定します．\n",
        "\n",
        "このとき，「$x$ という値をもつデータがクラス1の正規分布から得られたとすることの尤度」と，「$x$ という値をもつデータがクラス2の正規分布から得られたとすることの尤度」を求めてやれば，「$x$ という値をもつデータは，尤度のより大きい方の正規分布に対応するクラスに属すと判定する」ことができるでしょう．これが，判別分析の基本的な考え方です．\n",
        "\n",
        "上記の2つの正規分布の場合，尤度はぞれぞれ\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\ell_1(x) &= \\frac{1}{\\sqrt{2\\pi\\sigma_1^2}} \\exp{\\left( - \\frac{(x-\\mu_1)^2}{2\\sigma_1^2}\\right)} \\qquad (1)\\\\\n",
        "\\ell_2(x) &= \\frac{1}{\\sqrt{2\\pi\\sigma_2^2}} \\exp{\\left( - \\frac{(x-\\mu_2)^2}{2\\sigma_2^2}\\right)} \\qquad (2)\\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "と表せます．この $\\ell_1(x)$ と $\\ell_2(x)$ の値を求めて，「\n",
        "$\\ell_1(x) \\geq \\ell_2(x)$ ならクラス1，さもなくばクラス2に属すと判定する」ことになります．\n",
        "\n",
        "下図において，青い方がクラス1の，オレンジの方がクラス2の正規分布の確率密度関数だったとすると，次のようになります．\n",
        "\n",
        "- $\\ell_1(x_1) > \\ell_2(x_1)$ なので，$x = x_1$ のデータはクラス1に分類\n",
        "- $\\ell_1(x_2) < \\ell_2(x_2)$ なので，$x = x_2$ のデータはクラス2に分類\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/likelihood.png\">"
      ],
      "metadata": {
        "id": "US_5BdUtSAoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### マハラノビス距離と線形判別関数"
      ],
      "metadata": {
        "id": "zPjAw3w1Ymi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の説明では，2クラスの正規分布は平均も分散も任意としています．しかし，これにもう少し制約を加えると，判別のための計算が（判別関数が）より簡単な式になります．具体的には，「2クラスの正規分布は分散が等しい」，つまり，$\\sigma_1^2 = \\sigma_2^2 = \\sigma^2$ と表せると仮定します．\n",
        "\n",
        "このときは，対数尤度 $\\ell_1(x), \\ell_2(x)$ のかわりに次の量を求めて大小を比較することで，対数尤度を用いたときと等価な判別ができます（注）．\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "D_1^2(x) &= \\frac{(x-\\mu_1)^2}{\\sigma^2} \\qquad (3)\\\\\n",
        "D_2^2(x) &= \\frac{(x-\\mu_2)^2}{\\sigma^2} \\qquad (4)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "ただし，負号がなくなったので大小関係は逆になることに注意．$D_1^2(x) \\leq D_2^2(x)$ ならクラス1，さもなくばクラス2とすることになります．\n",
        "\n",
        "※ 注意: この場合，$\\frac{1}{\\sigma^2}$ もなくしても構わないのですが，2次元以上の場合の説明とあわせる（＆↓のマハラノビス距離の説明をする）ためにあえて残しています．"
      ],
      "metadata": {
        "id": "5jx1GjT-ZH1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここで出てくる\n",
        "\n",
        "$$\n",
        "D(x) = \\sqrt{\\frac{(x-\\mu)^2}{\\sigma^2}} \\qquad (5)\n",
        "$$\n",
        "\n",
        "のことを，**マハラノビス距離** (Mahalanobis' distance) といいます（式$(3),(4)$はマハラノビス距離の2乗）．ちゃんとした説明は省略しますが，これは，「$x$ から ${\\cal N}(\\mu,\\sigma^2)$ までの距離」を表す量と考えることができます．\n",
        "\n",
        "余談ですが，マハラノビスは統計学者の名前です．\n",
        "\n",
        "Prasanta Chandra Mahalanobis（プラサンタ・チャンドラ・マハラノビス）：  インドの統計学者， 1893 - 1972，[Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%97%E3%83%A9%E3%82%B5%E3%83%B3%E3%82%BF%E3%83%BB%E3%83%81%E3%83%A3%E3%83%B3%E3%83%89%E3%83%A9%E3%83%BB%E3%83%9E%E3%83%8F%E3%83%A9%E3%83%8E%E3%83%93%E3%82%B9)"
      ],
      "metadata": {
        "id": "vVuqmeCsbfeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "式 $(3),(4)$ を用いて次式で定義される関数 $z(x)$ を，**線形判別関数** といいます：\n",
        "\n",
        "$$\n",
        "z(x) = \\frac{D_2^2(x) - D_1^2(x)}{2} \\qquad (6)\n",
        "$$\n",
        "\n",
        "あるデータ $x$ について $z(x) \\ge 0$ ならばこのデータはクラス1に属すると判定し，$z(x) < 0$ ならばクラス2に属すると判定します．\n",
        "\n",
        "この式は，次のように変形していくと，$x$ の一次式となっています．これが，「線形」判別関数と呼ばれる所以です．\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "z(x) &= \\frac{1}{2\\sigma^2}\\left( (x-\\mu_2)^2 - (x-\\mu_1)^2 \\right) \\\\\n",
        "&= \\frac{1}{2\\sigma^2}\\left( x^2 - 2\\mu_2 x + \\mu_2^2 - (x^2 - 2\\mu_1 x + \\mu_1^2) \\right)\\\\\n",
        "&= \\frac{1}{2\\sigma^2}\\left( 2(\\mu_1 - \\mu_2)x - (\\mu_1^2 - \\mu_2^2) \\right) \\\\\n",
        "&= \\frac{\\mu_1 - \\mu_2}{2\\sigma^2}\\left( 2x - (\\mu_1 + \\mu_2)\\right) \\\\\n",
        "&= \\frac{\\mu_1 - \\mu_2}{\\sigma^2}\\left( x - \\frac{\\mu_1 + \\mu_2}{2}\\right) & (7)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "$z(x) = 0 \\Leftrightarrow x = \\frac{\\mu_1+\\mu_2}{2}$ ですので，2つの平均の中点がクラス1とクラス2を分ける境界となることが分かります．\n",
        "\n"
      ],
      "metadata": {
        "id": "hXOIURCdfbrm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "判別分析の手法としては，判別関数が線形ではないものもいろいろ考えられるので，線形である場合の判別分析をそうでない場合と区別して，**線形判別分析** (Linear Discriminant Analysis, LDA) と呼ぶこともあります．Ronald Fisher が最初に研究したと考えられており，*Fisher's Linear Discriminant* と呼ぶこともあります．"
      ],
      "metadata": {
        "id": "z37y2KGXpxcG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 「人間」vs「ほげ星人」の判別分析"
      ],
      "metadata": {
        "id": "uUuJMHP-Y_wn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "実際の例として，「人間」vs「ほげ星人」で，身長の数値のみから人間かほげ星人か判別する問題を考えてみましょう．\n",
        "\n",
        "まず，「人間」と「ほげ星人」それぞれの身長の平均 $\\mu_1, \\mu_2$ を推定します（ここでは標本平均を用いています）．\n",
        "\n"
      ],
      "metadata": {
        "id": "TVXxV58KRLOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_Human が「人間」の身長，X_Hoge が「ほげ星人」の身長\n",
        "X_Human = dfHoge.loc[dfHoge['Class'] == 'Human', 'Height'].to_numpy()\n",
        "X_Hoge  = dfHoge.loc[dfHoge['Class'] == 'Hoge',  'Height'].to_numpy()\n",
        "\n",
        "# それぞれの平均\n",
        "mu1 = np.mean(X_Human)\n",
        "mu2 = np.mean(X_Hoge)\n",
        "print(f'mu1 = {mu1:.2f}, mu2 = {mu2:.2f}')"
      ],
      "metadata": {
        "id": "wGJoagWzwwlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に，共通の分散 $\\sigma^2$ を次のようにして推定します（ここでは標本分散を用いています）．\n",
        "\n",
        "$$\n",
        "\\hat{\\sigma}^2 = \\frac{1}{\\mbox{データの総数}}\\left( \\sum_{n:\\mbox{人間}} (x_n - \\mu_1)^2 + \\sum_{n:\\mbox{ほげ星人}} (x_n - \\mu_2)^2 \\right)\n",
        "$$\n"
      ],
      "metadata": {
        "id": "1Aktii5GxUNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (X_Human - mu1) と (X_Hoge - mu2) の2乗の平均\n",
        "XX = np.hstack((X_Human - mu1, X_Hoge - mu2))\n",
        "sigma2 = np.mean(XX**2)\n",
        "print(f'sigma2 = {sigma2:.2f}')"
      ],
      "metadata": {
        "id": "vbAILOP7yaPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "身長のヒストグラムに ${\\cal N}(\\mu_1, \\sigma^2)$ と ${\\cal N}(\\mu_2, \\sigma^2)$ それぞれの確率密度関数を重ねて描くと，こんなんです．\n",
        "\n"
      ],
      "metadata": {
        "id": "PfnkvIqYxAjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xmin, xmax = 80, 220\n",
        "bins = np.linspace(xmin, xmax, 28)\n",
        "xx = np.linspace(xmin, xmax, 100)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.hist(X_Human, bins=bins, alpha=0.8, label='Human', density=True)\n",
        "ax.hist(X_Hoge,  bins=bins, alpha=0.8, label='Hoge',  density=True)\n",
        "\n",
        "# 人間クラスの正規分布\n",
        "px1 = norm.pdf(xx, loc=mu1, scale=np.sqrt(sigma2))\n",
        "ax.plot(xx, px1, linewidth=2, color='blue')\n",
        "\n",
        "# ほげ星人クラスの正規分布\n",
        "px2 = norm.pdf(xx, loc=mu2, scale=np.sqrt(sigma2))\n",
        "ax.plot(xx, px2, linewidth=2, color='red')\n",
        "\n",
        "# 判別境界\n",
        "ax.axvline((mu1+mu2)/2, color='purple', label=f'z(x) = 0')\n",
        "\n",
        "ax.set_xlim(xmin, xmax)\n",
        "ax.set_xlabel('Height')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BjV1gR1xOwx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "紫の直線は，判別関数 $z(x)$ の値が $0$ となる $x$ の値を表します．$z(x)$ によって人間クラスとほげ星人クラスを判別するときに，この点がちょうど2クラスの境界となっています．式$(7)$ の下に書いた通り，$z(x) = 0 \\Leftrightarrow x = \\frac{\\mu_1+\\mu_2}{2}$ です．"
      ],
      "metadata": {
        "id": "O5zQFJ8T1oGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'(mu1+mu2)/2 = {(mu1+mu2)/2:.2f}')"
      ],
      "metadata": {
        "id": "udDmiFvs3Xsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "したがって，\n",
        "\n",
        "- 身長が 160cm のひとは，$z(160) > 0$ なので，人間と予測される\n",
        "- 身長が 140cm のひとは，$z(140) < 0$ なので，ほげ星人と予測される\n",
        "\n",
        "ことになります．\n"
      ],
      "metadata": {
        "id": "EFSdMNZQtHCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "与えられたデータのそれぞれについて判別関数の値を計算し，予測が正しいかどうか調べてみましょう．"
      ],
      "metadata": {
        "id": "GLgaCUu3uQ0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Z_Human[n] は X_Human[n] の判別関数の値\n",
        "Z_Human = (mu1 - mu2)/sigma2*(X_Human - (mu1 + mu2)/2)\n",
        "# Z_Hoge[n] は X_Hoge[n] の判別関数の値\n",
        "Z_Hoge  = (mu1 - mu2)/sigma2*(X_Hoge  - (mu1 + mu2)/2)\n",
        "\n",
        "cntHuman = np.sum(Z_Human >= 0)\n",
        "cntHoge  = np.sum(Z_Hoge < 0)\n",
        "print(f'人間:    正解数/データ数 = {cntHuman}/{len(X_Human)}')\n",
        "print(f'ほげ星人: 正解数/データ数 = {cntHoge}/{len(X_Hoge)}')"
      ],
      "metadata": {
        "id": "NAs1cWetuic8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "人間については100人中96人を正しく人間と判別し（残り4人はほげ星人と判別した），ほげ星人については100人全員を正しくほげ星人と判別しています．\n",
        "上のヒストグラムと密度関数のグラフからもおおよそ予想できる結果となっていますね．"
      ],
      "metadata": {
        "id": "c2UuQJ1pud9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に，体重の方のデータで同じことをやってみましょう．"
      ],
      "metadata": {
        "id": "qrl7wV1-1i_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_Human が「人間」の体重，X_Hoge が「ほげ星人」の体重\n",
        "X_Human = dfHoge.loc[dfHoge['Class'] == 'Human', 'Weight'].to_numpy()\n",
        "X_Hoge  = dfHoge.loc[dfHoge['Class'] == 'Hoge',  'Weight'].to_numpy()\n",
        "\n",
        "# それぞれの平均\n",
        "mu1 = np.mean(X_Human)\n",
        "mu2 = np.mean(X_Hoge)\n",
        "print(f'mu1 = {mu1:.2f}, mu2 = {mu2:.2f}')\n",
        "\n",
        "# (X_Human - mu1) と (X_Hoge - mu2) の2乗の平均\n",
        "XX = np.hstack((X_Human - mu1, X_Hoge - mu2))\n",
        "sigma2 = np.mean(XX**2)\n",
        "print(f'sigma2 = {sigma2:.2f}')\n",
        "\n",
        "# 判別境界\n",
        "print(f'(mu1+mu2)/2 = {(mu1+mu2)/2:.2f}')"
      ],
      "metadata": {
        "id": "2r_DO6vf2Ky0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xmin, xmax = 0, 150\n",
        "bins = np.linspace(xmin, xmax, 28)\n",
        "xx = np.linspace(xmin, xmax, 100)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.hist(X_Human, bins=bins, alpha=0.8, label='Human', density=True)\n",
        "ax.hist(X_Hoge,  bins=bins, alpha=0.8, label='Hoge',  density=True)\n",
        "\n",
        "# 人間クラスの正規分布\n",
        "px1 = norm.pdf(xx, loc=mu1, scale=np.sqrt(sigma2))\n",
        "ax.plot(xx, px1, linewidth=2, color='blue')\n",
        "\n",
        "# ほげ星人クラスの正規分布\n",
        "px2 = norm.pdf(xx, loc=mu2, scale=np.sqrt(sigma2))\n",
        "ax.plot(xx, px2, linewidth=2, color='red')\n",
        "\n",
        "# 判別境界\n",
        "ax.axvline((mu1+mu2)/2, color='purple', label=f'z(x) = 0')\n",
        "\n",
        "ax.set_xlim(xmin, xmax)\n",
        "ax.set_xlabel('Weight')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lWakVKG-2l9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "クラスを予測させてみると...\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nTzBueqA2zi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Z_Human[n] は X_Human[n] の判別関数の値\n",
        "Z_Human = (mu1 - mu2)/sigma2*(X_Human - (mu1 + mu2)/2)\n",
        "# Z_Hoge[n] は X_Hoge[n] の判別関数の値\n",
        "Z_Hoge  = (mu1 - mu2)/sigma2*(X_Hoge  - (mu1 + mu2)/2)\n",
        "\n",
        "cntHuman = np.sum(Z_Human >= 0)\n",
        "cntHoge  = np.sum(Z_Hoge < 0)\n",
        "print(f'人間:    正解数/データ数 = {cntHuman}/{len(X_Human)}')\n",
        "print(f'ほげ星人: 正解数/データ数 = {cntHoge}/{len(X_Hoge)}')"
      ],
      "metadata": {
        "id": "5cp_dANFw1MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "体重を変数とした場合の判別の境界は約 81 kgで，値がこれ以下なら人間，これより大きければほげ星人と予測される結果となりました．\n",
        "ヒストグラムと密度関数のグラフから明らかなように，人間とほげ星人の値が入り混じっていますので，あまりよい予測ができていません．\n"
      ],
      "metadata": {
        "id": "k6V2SedNwzSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 2クラス多次元の判別分析"
      ],
      "metadata": {
        "id": "_dmxvPd-9SK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "前のセクションでは，判別分析の方法を，具体的な計算の仕方も含めて説明するために，最も簡単な2クラス1次元の場合に限定して考えていました．(身長,体重)という2つの変数を持つデータを例にしてはいましたが，どちらかの変数だけで判別分析を行っていました．ここでは，2つ以上の変数を持つ多次元データの判別分析について説明し（クラス数は2に限定したまま），両方の変数を使って判別分析する実験を行ってみます．"
      ],
      "metadata": {
        "id": "Nar3kMPyxo1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 考え方\n",
        "\n"
      ],
      "metadata": {
        "id": "XktmhDszwQnJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "多次元データの場合も考え方は同じです．$D$ 次元のデータを「クラス1」と「クラス2」の2クラスに分類する問題の場合，\n",
        "\n",
        "- クラス1の正規分布 ${\\cal N}\\left(\\mathbf{\\mu}_1, \\Sigma_1\\right)$\n",
        "- クラス2の正規分布 ${\\cal N}\\left(\\mathbf{\\mu}_2, \\Sigma_2\\right)$\n",
        "\n",
        "という2つを考えます．これらの正規分布のパラメータについては，与えられたデータから適当な方法で推定します．\n",
        "\n",
        "このとき，「$\\mathbf{x}$ という値をもつデータがクラス1の正規分布から得られたとすることの尤度」 $\\ell_1(\\mathbf{x})$ と，「$\\mathbf{x}$ という値をもつデータがクラス2の正規分布から得られたとすることの尤度」$\\ell_2(\\mathbf{x})$ はそれぞれ，次式で与えられます．\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\ell_1(\\mathbf{x}) &= \\frac{1}{\\sqrt{(2\\pi)^D|\\Sigma_1|}} \\exp{\\left( -\\frac{1}{2} (\\mathbf{x}-\\mathbf{\\mu}_1)^{\\top}\\Sigma_1^{-1}(\\mathbf{x}-\\mathbf{\\mu}_1) \\right)} & (8)\\\\\n",
        "\\ell_2(\\mathbf{x}) &= \\frac{1}{\\sqrt{(2\\pi)^D|\\Sigma_2|}} \\exp{\\left( -\\frac{1}{2} (\\mathbf{x}-\\mathbf{\\mu}_2)^{\\top}\\Sigma_2^{-1}(\\mathbf{x}-\\mathbf{\\mu}_2) \\right)} & (9)\\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "クラスが未知のデータ $\\mathbf{x}$ のクラスを判別したいときは，$\\ell_1(\\mathbf{x}), \\ell_2(\\mathbf{x})$ の値を計算して，$\\ell_1(\\mathbf{x}) \\geq \\ell_2(\\mathbf{x})$ なら $\\mathbf{x}$ はクラス1に属するとし，さもなくばクラス2に属するとします．\n",
        "しかし実際には，計算を簡単にするため，尤度の代わりにその対数をとった対数尤度を使うことがよくあります．\n",
        "\n",
        "いまの場合，対数尤度は次のようになります．\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\log{\\ell_1(\\mathbf{x})} &= -\\frac{D}{2}\\log(2\\pi) - \\frac{1}{2}\\log{|\\Sigma_1|} -\\frac{1}{2} (\\mathbf{x}-\\mathbf{\\mu}_1)^{\\top}\\Sigma_1^{-1}(\\mathbf{x}-\\mathbf{\\mu}_1)  & (10)\\\\\n",
        "\\log{\\ell_2(\\mathbf{x})} &= -\\frac{D}{2}\\log(2\\pi) - \\frac{1}{2}\\log{|\\Sigma_2|} - \\frac{1}{2} (\\mathbf{x}-\\mathbf{\\mu}_2)^{\\top}\\Sigma_2^{-1}(\\mathbf{x}-\\mathbf{\\mu}_2) & (11)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "$\\log x$ は単調増加関数ですので，\n",
        "$\\log{\\ell_1(\\mathbf{x})} \\geq \\log{\\ell_2(\\mathbf{x})}$ なら $\\mathbf{x}$ はクラス1に属するとし，さもなくばクラス2に属するとする，ということになります．\n",
        "式$(9),(10)$の第1項 $-\\frac{D}{2}\\log(2\\pi)$ は両者で共通ですので，値の大小を比較するためだけなら無視しても構いません．\n"
      ],
      "metadata": {
        "id": "oueqUTFwwcPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### マハラノビス距離と線型判別関数"
      ],
      "metadata": {
        "id": "bFp9iPaNzVn2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1次元の場合と同様に，多次元のデータの場合も，2クラスの正規分布に制約条件を加えることで，判別のための計算が（判別関数が）より簡単な式になります．具体的には，2クラスの正規分布は分散共分散行列が共通で，平均のみが異なると仮定します．\n",
        "\n",
        "$\\Sigma_1 = \\Sigma_2 = \\Sigma$ とおくと，式$(9),(10)$ の第1項に加えて第2項も両者で共通になりますので，2つの対数尤度の大小を比較するかわりに，次の2つの量の大小を比較すればよいことになります．\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "D_1^2(\\mathbf{x}) &= (\\mathbf{x}-\\mathbf{\\mu}_1)^{\\top}\\Sigma^{-1}(\\mathbf{x}-\\mathbf{\\mu}_1) & (12)\\\\\n",
        "D_2^2(\\mathbf{x}) &= (\\mathbf{x}-\\mathbf{\\mu}_2)^{\\top}\\Sigma^{-1}(\\mathbf{\\mathbf{x}}-\\mathbf{\\mu}_2)  & (13)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "ただし，対数尤度の式にあった負号がなくなっていますので，大小関係は逆になります．$D_1^2(\\mathbf{x}) \\leq D_2^2(\\mathbf{x})$ ならクラス1，さもなくばクラス2，です．"
      ],
      "metadata": {
        "id": "aUDZWlEdzibV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1次元のときと同様に，式$(12),(13)$ に出てくる\n",
        "\n",
        "$$\n",
        "D(\\mathbf{x}) = \\sqrt{(\\mathbf{x}-\\mathbf{\\mu})^{\\top}\\Sigma^{-1}(\\mathbf{x}-\\mathbf{\\mu}) } \\qquad (14)\n",
        "$$\n",
        "\n",
        "という量のことを，**マハラノビス距離** (Mahalanobis' distance) といいます（式$(12),(13)$はマハラノビス距離の2乗）．これは，「$\\mathbf{x}$ から ${\\cal N}(\\mathbf{\\mu},\\Sigma)$ までの距離」を表す量と考えることができます．"
      ],
      "metadata": {
        "id": "y2Oz7UBI2wTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "例えば，下図のような2次元正規分布があったとしましょう．青い★が平均 $\\mathbf{\\mu}$ です．白い円は，$\\mathbf{\\mu}$ とのユークリッド距離がある一定値をとる点の集合です．一方，色付きの楕円（の輪郭線）は，$\\mathbf{\\mu}$ とのマハラノビス距離が一定値をとる点の集合です（前回，手計算で楕円になることを確認してましたね）．ユークリッド距離で測ると点 $A$ と $\\mathbf{\\mu}$ の距離は $B$ と $\\mathbf{\\mu}$ の距離と等しいですが，マハラノビス距離で測ると点AよりBの方が$\\mathbf{\\mu}$ に近いことになります．\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/Mahalanobis.png\">\n",
        "\n",
        "このように，マハラノビス距離は，扱っている正規分布の広がり方（データの散らばり方）を考慮した測り方をするものとなっています．"
      ],
      "metadata": {
        "id": "gMrn696DzhuR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1次元の場合の線形判別関数と同様に，式 $(12),(13)$ を用いて次式で定義される関数 $z(\\mathbf{x})$ を，**線形判別関数** といいます：\n",
        "\n",
        "$$\n",
        "z(\\mathbf{x}) = \\frac{D_2^2(\\mathbf{x}) - D_1^2(\\mathbf{x})}{2} \\qquad (15)\n",
        "$$\n",
        "\n",
        "あるデータ $\\mathbf{x}$ について $z(\\mathbf{x}) \\ge 0$ ならばこのデータはクラス1に属すると判定し，$z(\\mathbf{x}) < 0$ ならばクラス2に属すると判定します．\n",
        "\n",
        "以下に示すように，この式は，変形していくと $\\mathbf{x}$ の一次式となっています．\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "z(\\mathbf{x}) &= \\frac{1}{2}\\left( \n",
        "(\\mathbf{x}-\\mathbf{\\mu}_2)^{\\top}\\Sigma^{-1}(\\mathbf{x}-\\mathbf{\\mu}_2) - (\\mathbf{x}-\\mathbf{\\mu}_1)^{\\top}\\Sigma^{-1}(\\mathbf{\\mathbf{x}}-\\mathbf{\\mu}_1)  \\right)\\\\\n",
        "&= \\frac{1}{2}\\left( \\mathbf{x}^{\\top}\\Sigma^{-1}\\mathbf{x} - \\mathbf{x}^{\\top}\\Sigma^{-1}\\mathbf{\\mu}_2 - \\mathbf{\\mu}_2^{\\top}\\Sigma^{-1}\\mathbf{x} + \\mathbf{\\mu}_2^{\\top}\\Sigma^{-1}\\mathbf{\\mu}_2 -\\left( \\mathbf{x}^{\\top}\\Sigma^{-1}\\mathbf{x} - \\mathbf{x}^{\\top}\\Sigma^{-1}\\mathbf{\\mu}_1 - \\mathbf{\\mu}_1^{\\top}\\Sigma^{-1}\\mathbf{x} + \\mathbf{\\mu}_1^{\\top}\\Sigma^{-1}\\mathbf{\\mu}_1\\right) \\right)\\\\\n",
        "&= \\frac{1}{2}\\left( -2\\mathbf{\\mu}_2^{\\top}\\Sigma^{-1}\\mathbf{x} + \\mathbf{\\mu}_2^{\\top}\\Sigma^{-1}\\mathbf{\\mu}_2 + 2\\mathbf{\\mu}_1^{\\top}\\Sigma^{-1}\\mathbf{x} - \\mathbf{\\mu}_1^{\\top}\\Sigma^{-1}\\mathbf{\\mu}_1 \\right)\\\\\n",
        "&= (\\mathbf{\\mu}_1 - \\mathbf{\\mu}_2)^{\\top}\\Sigma^{-1}\\mathbf{x} - \\frac{1}{2}(\\mathbf{\\mu}_1 - \\mathbf{\\mu}_2)^{\\top}\\Sigma^{-1}(\\mathbf{\\mu}_1+\\mathbf{\\mu}_2)\\\\\n",
        "&= (\\mathbf{\\mu}_1 - \\mathbf{\\mu}_2)^{\\top}\\Sigma^{-1}\\left( \\mathbf{x} - \\frac{\\mathbf{\\mu}_1+\\mathbf{\\mu}_2}{2} \\right) \\qquad (16)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "$z(\\mathbf{x}) = 0 \\Leftrightarrow \\mathbf{x} = \\frac{\\mathbf{\\mu}_1+\\mathbf{\\mu}_2}{2}$ ですので，クラス1とクラス2を分ける境界は，2つの平均の中点を通り，ベクトル $\\Sigma^{-1}(\\mathbf{\\mu}_1 - \\mathbf{\\mu}_2)$ に垂直な $(D-1)$次元平面（$D=2$のときは直線）となります（注）．\n",
        "\n",
        "※注意: 高校のベクトルの項で学ぶ直線の方程式の話の3次元以上への一般化．$\\mathbf{n}^{\\top}(\\mathbf{x}-\\mathbf{p}) = \\mathbf{n}\\cdot (\\mathbf{x}-\\mathbf{p}) = 0$ を満たす点 $\\mathbf{x}$ は，点 $\\mathbf{p}$ を通り $\\mathbf{n}$ を法線ベクトルとする平面上にあります．\n"
      ],
      "metadata": {
        "id": "POGjPSfS3gys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 「人間」vs「ほげ星人」の判別分析"
      ],
      "metadata": {
        "id": "8HS6FBQx8okO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "「人間」vs「ほげ星人」の $(身長, 体重)$ データを判別分析してみましょう．\n",
        "\n"
      ],
      "metadata": {
        "id": "mMfsDydN8wsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを格納した2次元配列をつくる\n",
        "X_Human = dfHoge.loc[dfHoge['Class'] == 'Human', ['Height', 'Weight']].to_numpy()\n",
        "X_Hoge  = dfHoge.loc[dfHoge['Class'] == 'Hoge',  ['Height', 'Weight']].to_numpy()\n",
        "\n",
        "print('人間の最初の5人')\n",
        "print(X_Human[:5, :])\n",
        "print()\n",
        "print('ほげ星人の最初の5人')\n",
        "print(X_Hoge[:5, :])"
      ],
      "metadata": {
        "id": "iV04lERq992L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず，人間の平均 `mu_Human` とほげ星人の平均 `mu_Hoge` を求めます．\n"
      ],
      "metadata": {
        "id": "biYHsua3-ADm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 人間クラスとほげ星人クラスそれぞれの平均\n",
        "mu_Human = np.mean(X_Human, axis=0)\n",
        "mu_Hoge  = np.mean(X_Hoge,  axis=0)\n",
        "print('mu_Human = ', mu_Human)\n",
        "print('mu_Hoge  = ', mu_Hoge)"
      ],
      "metadata": {
        "id": "uAivus6g9UlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に，共通の分散共分散行列 `cov` を求めます．"
      ],
      "metadata": {
        "id": "9R-IYgnA-qU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 平均を引いたデータ行列をつくる\n",
        "XX = np.vstack((X_Human - mu_Human, X_Hoge - mu_Hoge))\n",
        "print(XX.shape)\n",
        "\n",
        "# それを用いて共通の分散共分散行列を求める\n",
        "cov = XX.T @ XX / len(XX)\n",
        "print(cov)"
      ],
      "metadata": {
        "id": "bK2OAaAi9pdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "判別分析の結果を直感的に理解できるように，データの散布図に重ねて，人間クラスほげ星人クラスそれぞれの推定された正規分布の等高線を描いてみましょう．"
      ],
      "metadata": {
        "id": "ECZaBhml_4a3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### 判別分析の結果を可視化する\n",
        "#\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "xmin, xmax = 0, 250\n",
        "ymin, ymax = 0, 150\n",
        "xx, yy = np.mgrid[xmin:xmax:0.1, xmin:xmax:0.1]\n",
        "\n",
        "# 人間クラスの散布図と推定された正規分布の等高線\n",
        "ax.scatter(X_Human[:, 0], X_Human[:, 1], label='Human')\n",
        "zz = multivariate_normal.pdf(np.dstack((xx, yy)), mean=mu_Human, cov=cov)\n",
        "ax.contour(xx, yy, zz, colors='blue')\n",
        "\n",
        "# ほげ星人クラスの散布図と推定された正規分布の等高線\n",
        "ax.scatter(X_Hoge[:, 0], X_Hoge[:, 1], label='Hoge')\n",
        "zz = multivariate_normal.pdf(np.dstack((xx, yy)), mean=mu_Hoge, cov=cov)\n",
        "ax.contour(xx, yy, zz, colors='red')\n",
        "\n",
        "# 判別境界\n",
        "w = np.linalg.inv(cov) @ (mu_Human - mu_Hoge)\n",
        "mu_mu = (mu_Human + mu_Hoge)/2\n",
        "xp0, yp0 = w @ mu_mu / w[0], 0\n",
        "xp1, yp1 = w @ (mu_mu - [0, ymax]) / w[0], ymax\n",
        "ax.plot([xp0, xp1], [yp0, yp1], color='purple', label=f'z(x)=0')\n",
        "\n",
        "ax.set_xlim(xmin, xmax)\n",
        "ax.set_xlabel('Height')\n",
        "ax.set_ylim(ymin, ymax)\n",
        "ax.set_ylabel('Weight')\n",
        "ax.set_aspect('equal')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nibMnU19_TJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "この図に描かれた紫色の直線は，判別分析によって得られた2クラスの境界，すなわち，判別関数 $z(\\mathbf{x}) = 0$ となる $\\mathbf{x}$ の値の集合（直線）です．\n",
        "$(\\mbox{身長},\\mbox{体重}) = (150, 60)$ のひとは人間と判別され，$(150, 100)$ のひとはほげ星人と判別されることがわかります．"
      ],
      "metadata": {
        "id": "fVmO-s5mFOz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "式$(16)$の判別関数の値を実際に計算して，上記の通りになることを確認してみましょう（注）．\n",
        "\n",
        "※注: ここでは，簡単のため，式$(16)$の通りに分散共分散行列の逆行列を求めて判別関数の値を計算しています．しかし，実用的には，分散共分散行列の固有値分解を利用して式$(16)$を変形し，逆行列を使わずに済むようした方が効率的です（\n",
        "$\\Sigma = U\\Lambda U^{\\top}$ のとき，$\\Sigma^{-1} = U\\Lambda^{-1}U^{\\top}$．$\\Lambda$ は固有値を並べた対角行列，$U$ は固有ベクトルを並べた行列．$\\Lambda$ は対角行列なので，$\\Sigma^{-1}$ よりも $\\Lambda^{-1}$ の方がずっと簡単に求まる）．\n",
        "\n"
      ],
      "metadata": {
        "id": "qXvQCUluTv7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 判別したいデータ\n",
        "XX = np.array([[150,  60],\n",
        "               [150, 100],\n",
        "               [180, 145],\n",
        "               [180, 146]])\n",
        "\n",
        "# cov の逆行列\n",
        "covI = np.linalg.inv(cov)\n",
        "\n",
        "# 判別関数の値を求める\n",
        "ZZ = (XX - (mu_Human + mu_Hoge)/2) @ covI @ (mu_Human - mu_Hoge)\n",
        "\n",
        "# 結果の表示\n",
        "for n in range(len(XX)):\n",
        "    print(f'値 {XX[n, :]} のひとの判別関数の値は {ZZ[n]: .2f} なので', end='')\n",
        "    if ZZ[n] >= 0:\n",
        "        s = '人間'\n",
        "    else:\n",
        "        s = 'ほげ星人'\n",
        "    print(f' {s} と判別されます')"
      ],
      "metadata": {
        "id": "5rS83z8ZR6-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "元のデータの判別結果がどうなるかも計算してみましょう．"
      ],
      "metadata": {
        "id": "GeI3WQcs12uJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Z_Human[n] は X_Human[n] の判別関数の値\n",
        "Z_Human = (X_Human - (mu_Human + mu_Hoge)/2) @ covI @ (mu_Human - mu_Hoge)\n",
        "# Z_Hoge[n] は X_Hoge[n] の判別関数の値\n",
        "Z_Hoge  = (X_Hoge  - (mu_Human + mu_Hoge)/2) @ covI @ (mu_Human - mu_Hoge)\n",
        "\n",
        "cntHuman = np.sum(Z_Human >= 0)\n",
        "cntHoge  = np.sum(Z_Hoge < 0)\n",
        "print(f'人間:    正解数/データ数 = {cntHuman}/{len(X_Human)}')\n",
        "print(f'ほげ星人: 正解数/データ数 = {cntHoge}/{len(X_Hoge)}')"
      ],
      "metadata": {
        "id": "NqABQQ-5UZpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "身長と体重という2つの値を組み合わせて予測できるため，こちらの方が良い結果が得られたようです．"
      ],
      "metadata": {
        "id": "i4ErVf-k2iuI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9m-vSXFf2daz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}