{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPDGYhrC0d1CVzzFTReTlus",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/MVA/blob/main/MVA2024_ex06notebookA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MVA2024 ex06notebookA\n",
        "\n",
        "<img width=64 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/MVA-logo.png\"> https://www-tlab.math.ryukoku.ac.jp/wiki/?MVA/2024"
      ],
      "metadata": {
        "id": "P4preLw7SzqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "## 主成分分析 (1)\n",
        "----\n",
        "\n",
        "**主成分分析** (Principal Component Analysis, PCA) は，多変量（多次元）のデータが与えられたときに，そのデータが含む情報をなるべく損なわずにより低次元のデータに変換するための多変量解析手法です．\n",
        "$D$個の変数から成る（$D$次元の）データが与えられたときに，それを$H \\leq D$ 個の変数で表す（$H$次元に変換する）ことを目的とします．この変換によってデータの次元数が削減されますので，このような操作は **次元削減** (Dimensionaliry Reduction) と呼ばれることもあります．主成分分析は，次元削減のための手法の一つです．"
      ],
      "metadata": {
        "id": "W3zGBgJJSWv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 準備"
      ],
      "metadata": {
        "id": "AnF3LvGC-RA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### インポート"
      ],
      "metadata": {
        "id": "-r3rONyR0WWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# いろいろインポート\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()"
      ],
      "metadata": {
        "id": "9HCsHgFjR6jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### データの準備"
      ],
      "metadata": {
        "id": "fBCG8Qf30aCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のコードセルでは，「SSDSE-家計消費」というデータセットを読み込んで前処理を行うコードを実行します．\n",
        "データについての説明も表示します．"
      ],
      "metadata": {
        "id": "bbOleIhc3Adl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/DiningOutSpendingData.py\n",
        "from DiningOutSpendingData import DiningOutSpendingData\n",
        "data = DiningOutSpendingData()\n",
        "kinki5 = data.kinki5()\n",
        "tohoku6 = data.tohoku6()\n",
        "data.info()"
      ],
      "metadata": {
        "id": "HAQpB-ZR0J77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のコードセルを実行すると，最初の5件のデータを表示します．"
      ],
      "metadata": {
        "id": "PklMsJfA3UzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame 表示時の小数部の表示桁数\n",
        "pd.options.display.precision = 1\n",
        "# DataFrame を入手して最初の5件を表示\n",
        "dfFeature = data.getDataFrame()\n",
        "dfFeature.head(5)"
      ],
      "metadata": {
        "id": "NuiXtwOg0pQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### やりたいこと\n",
        "\n"
      ],
      "metadata": {
        "id": "t3_tnPEFSdwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上でやっていた準備作業では，47都道府県の県庁所在市の13種類の外食支出金額（ひとりあたり，単位は円）の数値が得られました．このデータでは47の市ごとにその特徴が13個の変数で表されていますので，13次元のデータといえます．\n",
        "これだけ変数の数が多いと，それらの数値を眺めただけで各市の傾向を理解するのは困難です．そこで，「このようなデータをもっと低次元で（少ない数の変数で）表す」ことを考えます．主成分分析は，このようなことを行うための手法です．\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x4T73RygUZFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 13種類の支出金額ならべた配列を作る\n",
        "X = data.getArray()\n",
        "print(X[:5, :])\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "HUSYBMdWX4pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，上記のデータに主成分分析を適用して，13次元のデータを2次元に変換したものが得られます．\n",
        "\n",
        "<!---\n",
        "ここでは [scikit-learn](https://scikit-learn.org/) という Python 向けの機械学習ライブラリを使っています．scikit-learn については授業の範囲外ですので，コードの中身の理解は必須ではありません．\n",
        "cf. [sklearn.decomposition.PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
        "--->\n",
        "ここでは，[statsmodels](https://www.statsmodels.org/) という Python 向け統計分析ライブラリを使っています．\n",
        "cf. [statsmodels.multivariate.pca.PCA](https://www.statsmodels.org/dev/generated/statsmodels.multivariate.pca.PCA.html)"
      ],
      "metadata": {
        "id": "Bt9Fkmu9Xygz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 主成分分析を利用して X を2次元に次元削減した Y を得る（標準化あり）\n",
        "from statsmodels.multivariate.pca import PCA\n",
        "pca = PCA(X, ncomp=2, standardize=True, demean=True, normalize=False)\n",
        "Y = pca.scores\n",
        "print(Y[:5, :])\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "CleoPdEcYRaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`X` は13次元のデータだったので `shape` が `(47, 13)` でしたが，それを変換して得られた `Y` の `shape` は `(47, 2)` です．各市の特徴を2つの数値で表したものとなっています．"
      ],
      "metadata": {
        "id": "wdinbegMZHxC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2次元のデータなので，散布図に描けます．描いてみるとこんなん："
      ],
      "metadata": {
        "id": "atqBdfaTZ1_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Y の散布図\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.scatter(Y[:, 0], Y[:, 1])\n",
        "ax.scatter(Y[kinki5, 0], Y[kinki5, 1], label='kinki5')\n",
        "ax.scatter(Y[tohoku6, 0], Y[tohoku6, 1], label='tohoku6')\n",
        "ax.set_xlim(-4.5, 4.5)\n",
        "ax.set_ylim(-4.5, 4.5)\n",
        "ax.set_aspect('equal')\n",
        "ax.axhline(0, color='gray') # x軸\n",
        "ax.axvline(0, color='gray') # y軸\n",
        "ax.legend()\n",
        "for n in range(len(Y)):\n",
        "    plt.annotate(f'{n}', (Y[n, 0]+0.1, Y[n, 1]+0))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V5U0udPcaDMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "横軸が `Y` の0列目の値，縦軸が 1 列目の値です．各点に付された番号は，行番号（0から始まる）に対応しています．\n",
        "\n",
        "これを見ると，ほげ市とふが市は点が近いところにある → 似た傾向にありそうだ，といったことを読み取れそうですね．また，ちゃんとした説明は後にしますが，得られた値を見て各市の特徴をつかむことも容易になります．\n",
        "\n",
        "この図では，わかりやすくするために，近畿5府県と東北6県の点の色を変えてみています．それぞれ，元の13次元のデータはこんなんです："
      ],
      "metadata": {
        "id": "2N7CgbzjaLJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 近畿5府県\n",
        "dfFeature.iloc[data.kinki5(), :]"
      ],
      "metadata": {
        "id": "tXhL5ldxaqFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 東北6県\n",
        "dfFeature.iloc[data.tohoku6(), :]"
      ],
      "metadata": {
        "id": "rdsom-Ohas_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# お好きなところをどぞ\n",
        "dfFeature.iloc[3, :]  # 行番号で\n",
        "#dfFeature.query('City == \"札幌市\"')  # City 列の値で"
      ],
      "metadata": {
        "id": "EzUf4EWs1N4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここでは13次元のデータを2次元にしたので散布図を描いてみせましたが，いつでもどんなデータでも2次元にする，という話ではないことに注意してください．13次元のデータを4次元にしたり，1万次元のデータを10次元にしたり，データの性質と分析の目的によって次元数は様々です．"
      ],
      "metadata": {
        "id": "2157C0n1dFLb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 1次元に次元削減する場合の主成分分析"
      ],
      "metadata": {
        "id": "MCZcd48bd8_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "↑に書いたことをもう一度書いておきます：\n",
        "\n",
        "> **主成分分析** (Principal Component Analysis, PCA) は，多変量（多次元）のデータが与えられたときに，そのデータが含む情報をなるべく損なわずにより低次元のデータに変換するための多変量解析手法です．\n",
        "$D$個の変数から成る（$D$次元の）データが与えられたときに，それを$H \\leq D$ 個の変数で表す（$H$次元に変換する）ことを目的とします．この変換によってデータの次元数が削減されますので，このような操作は **次元削減** (Dimensionaliry Reduction) と呼ばれることもあります．主成分分析は，次元削減のための手法の一つです．\n",
        "\n",
        "\n",
        "ここでは，まずは $H = 1$ の場合について考えます．"
      ],
      "metadata": {
        "id": "-_i1D3h9mLEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 考え方"
      ],
      "metadata": {
        "id": "zIOyXkrembkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "主成分分析では，「データが含む情報をなるべく損なわずにより低次元のデータに変換する」ということを，「**変換後のデータの分散がなるべく大きくなるように（元のデータの分散を保つように）する**」ということで達成しようとします．\n",
        "ここでは，元のデータの次元数 $D = 2$ の場合を例として，これを1次元に次元削減する場合を図に描きながら考えてみましょう．\n"
      ],
      "metadata": {
        "id": "WrGVPXTSm8Dx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "下図の左は，とある2次元のデータを散布図に描いたものです．二つの破線はそれぞれ，横軸と縦軸の値の平均を表しています．\n",
        "このデータの値を，それらの平均が $\\pmb{0}$ になるように平行移動させると，散布図は下図の右のようになります．\n",
        "以降，このように平均が $\\pmb{0}$ になるように平行移動させたデータの集合を\n",
        "$$\n",
        "\\{ \\pmb{x}_n \\in R^{D} | n = 1, 2, \\ldots, N\\} \\qquad (1)\n",
        "$$\n",
        "と表すことにします．\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/pcafig01.png\">\n"
      ],
      "metadata": {
        "id": "-c1lfi3GkKTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このようなデータを1次元にする線形変換は，$D$次元列ベクトル $\\pmb{u}$ をひとつ定めて，下図のように$D$次元列ベクトル $\\pmb{x}$ を1つの実数値 $y$ に変換する操作と考えられます．\n",
        "\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/pcafig02.png\">\n",
        "\n",
        "この図の左の赤い直線は，ベクトル $\\pmb{u}$ の向きを表しています．個々のデータ $\\pmb{x}$ に対して，「その点がこの赤い直線上に落とす影」を考えて，この直線上でのその影の位置を $y$ とおくと，右図に示すように\n",
        "\n",
        "$$\n",
        "y = \\Vert\\pmb{x}\\Vert\\cos\\theta \\qquad (2)\n",
        "$$\n",
        "\n",
        "となります．$\\theta$ は $\\pmb{x}$ と $\\pmb{u}$ の成す角，$\\|\\pmb{x}\\|$ は $\\pmb{x}$ のノルム（大きさ）です．\n",
        "$\\pmb{u}\\cdot\\pmb{x} = \\|\\pmb{u}\\|\\|\\pmb{x}\\|\\cos\\theta$ であることから，上の式は，次のように書き換えられます．\n",
        "\n",
        "$$\n",
        "y = \\frac{\\pmb{u}\\cdot\\pmb{x}}{\\|\\pmb{u}\\|} \\qquad (3)\n",
        "$$\n",
        "\n",
        "与えられたデータに対して，ベクトル $\\pmb{u}$ を適当に定めてやれば，この式によって $D$ 次元のデータを1つの実数値に変換できます．\n",
        "\n",
        "ここで，ベクトル $\\pmb{u}$  として，向きが同じでノルムのみ異なる二つの候補があったとしてみましょう．その場合，得られる $y$ の値はどちらを用いても同じとなります．つまり，ここで考えている変換では，ベクトル $\\pmb{u}$ の向きのみが重要ということになります．\n",
        "そのため，ベクトル $\\pmb{u}$ のノルムは $1$ に限定して（つまり，$\\pmb{u}$ は単位ベクトルに限定して）考えることができます．この場合，$\\Vert\\pmb{u}\\Vert = 1$ ですので，上の式はより簡単に\n",
        "\n",
        "$$\n",
        "y = \\pmb{u}\\cdot\\pmb{x} \\qquad (4)\n",
        "$$\n",
        "\n",
        "と表せます．"
      ],
      "metadata": {
        "id": "EopPQdzVnEGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以上より，$D$次元の単位ベクトル $\\pmb{u}$ を適当に定めれば，$y_n = \\pmb{u}\\cdot\\pmb{x}_n$ という式で1次元への次元削減ができることが分かりました．\n",
        "では，$\\pmb{u}$ はどのように定めればよいでしょうか？\n",
        "\n",
        "主成分分析の目的は，「変換後のデータの分散がなるべく大きくなるように（元のデータの分散を保つように）」することでした．$\\pmb{u}$の向きを変えると，変換後の値 $y_n$ の分散の大きさも変化します．\n",
        "以下の図(a), (b), (c) は，3種類の $\\pmb{u}$ で2次元のデータを1次元に変換した様子と，変換後の値の分散を示しています．\n",
        "右図は横軸に $y_n$ の値をとっており，`variance` の値が $y_n$ の分散です．\n",
        "\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/pcafig03.png\">\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/pcafig04.png\">\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/pcafig05.png\">\n",
        "\n",
        "図を見ると，データの散らばりが大きい方向を $\\pmb{u}$ が向いたときに，変換後の分散が大きくなっていることがわかります．\n",
        "直感的な説明になりますが，変換後の値だけを見て元のデータの様子を想像するなら，分散が大きい方が，個々の値の違いがわかりやすくてうれしいですね．\n",
        "\n",
        "ここまで，データを1次元に次元削減する場合限定で，主成分分析の考え方を説明してきました．\n",
        "次のセクションでは，このような主成分分析の問題をきちんと定式化して，その解がどのようなものかを説明します．"
      ],
      "metadata": {
        "id": "0HVeIJQGvmIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 主成分分析の問題設定とその解（1次元にする場合）"
      ],
      "metadata": {
        "id": "yTqwvU2Q0jd8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "［主成分分析の問題設定（1次元にする場合）］\n",
        "\n",
        "$N$個の$D$次元ベクトルから成るデータ\n",
        "\n",
        "$$\n",
        "\\{ \\pmb{x}_n \\in R^{D}  | n = 1, 2, \\ldots, N\\} \\qquad (5)\n",
        "$$\n",
        "\n",
        "が与えられるとする．このデータの平均は $\\mathbf{0}$ である，つまり，\n",
        "\n",
        "$$\n",
        "\\frac{1}{N}\\sum_{n=1}^{N}\\pmb{x}_{n} = \\pmb{0} \\qquad (6)\n",
        "$$\n",
        "\n",
        "と仮定する（平均が $\\pmb{0}$でない場合は，平均を求めてそれをデータから差し引いたものをあらためて $\\pmb{x}_n$ とおけばよい）．\n",
        "このとき，$D$ 次元単位ベクトル $\\pmb{u}$ を用いて，$D$ 次元ベクトル $\\pmb{x}$ を次のように1つの実数値 $y_n$ に変換することを考える．\n",
        "\n",
        "$$\n",
        "y_n = \\pmb{u}\\cdot \\pmb{x}_n \\quad (n = 1, 2, \\ldots, N) \\qquad (7)\n",
        "$$\n",
        "\n",
        "ベクトル $\\pmb{u}$ を，$\\Vert\\pmb{u}\\Vert = 1$ の任意のベクトルの中で $y_n$の分散が最大となるように定めたい．\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "C0p945uO1KZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "これが主成分分析の問題設定です．\n",
        "この問題の解，つまり，$y_n$ の分散を最大にする $\\pmb{u}$ は，「**データ $\\{\\pmb{x}_n\\}$ の分散共分散行列を $V$ とするとき，その最大の固有値に対応する単位固有ベクトル（ノルムが1の固有ベクトル）**」となります（導出過程は後述）．\n",
        "\n",
        "ここで，**分散共分散行列** （「共分散行列」ともいう） は，次のように定められます：\n",
        "\n",
        "$\\pmb{x}_n$($n=1,2,\\ldots,N$)を $D$ 次元列ベクトル（$D\\times 1$ 行列）とするとき，その分散共分散行列 $V$ は\n",
        "\n",
        "$$\n",
        "V = \\frac{1}{N}\\sum_{n=1}^{N}(\\pmb{x}_{n} - \\bar{\\pmb{x}})(\\pmb{x}_{n} - \\bar{\\pmb{x}})^{\\top} \\qquad (8)\n",
        "$$\n",
        "\n",
        "という $D\\times D$ 行列です（$\\bar{\\pmb{x}}$ は $\\pmb{x}_n$ の平均）．$V$ の $(i,j)$ 要素 $V_{i,j}$ は\n",
        "\n",
        "$$\n",
        "V_{i,j} = \\frac{1}{N}\\sum_{n=1}^{N}(x_{n,i}-\\bar{x}_{i})(x_{n,j}-\\bar{x}_{j})  \\qquad (i, j = 1, 2, \\ldots, D) \\qquad (9)\n",
        "$$\n",
        "\n",
        "という式で表されますが，これは $\\pmb{x}_n$ の $i$ 番目の要素と $j$ 番目の要素の間の **共分散** です（注）．\n",
        "\n",
        "今の問題設定では，$\\pmb{x}_n$ の平均は $\\bar{\\pmb{x}} = \\pmb{0}$ と仮定していますので，\n",
        "\n",
        "$$\n",
        "V = \\frac{1}{N}\\sum_{n=1}^{N}\\pmb{x}_{n}\\pmb{x}_{n}^{\\top} \\qquad (10)\n",
        "$$\n",
        "\n",
        "となります．\n",
        "まとめると，ここに示した主成分分析の解のベクトル $\\pmb{u}$ は，次のステップで求められます．\n",
        "\n",
        "1. データから $V$ を計算する\n",
        "1. その固有値固有ベクトルを求める\n",
        "1. 最大の固有値に対応する単位固有ベクトルを $\\pmb{u}$ とする\n",
        "\n",
        "<br>\n",
        "<hr width=\"50%\" align=\"left\">\n",
        "<span style=\"font-size: 75%\">\n",
        "※注： ここでは「分散共分散行列」や「共分散」についてはこれ以上は深入りしません．「データ分析」を履修したひとは，「相関係数」の話で登場していますので，そのときの資料が参考になるかもしれません\n",
        "（<a href=\"https://www-tlab.math.ryukoku.ac.jp/wiki/?Data/2024#ex05\">2024年度「データ分析」ex05 散布図と相関</a>）．\n",
        "</span>\n"
      ],
      "metadata": {
        "id": "eACBZ0j485rE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ［発展］主成分分析の問題の解の導出（1次元にする場合）\n",
        "\n",
        "上記の解の導出過程の概略を以下に示します．"
      ],
      "metadata": {
        "id": "ftx-JdAM8-2R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "仮定より $\\pmb{x}_n$ の平均が $\\pmb{0}$ なので，$y_n$ の平均を $\\bar{y}$ とおくと\n",
        "\n",
        "$$\n",
        "\\bar{y} = \\frac{1}{N}\\sum_{n=1}^{N}y_n = \\frac{1}{N}\\sum_{n=1}^{N}\\pmb{u}\\cdot\\pmb{x}_{n} = \\pmb{u}\\cdot\\left( \\frac{1}{N}\\sum_{n=1}^{N}\\pmb{x}_n\\right) = \\pmb{u}\\cdot\\pmb{0} = 0 \\qquad (11)\n",
        "$$\n",
        "\n",
        "が成り立ちます．そのため，$y_n$ の分散は\n",
        "\n",
        "$$\n",
        "\\frac{1}{N}\\sum_{n=1}^{N}(y_n - \\bar{y})^2 = \\frac{1}{N}\\sum_{n=1}^{N}y_n^2 \\qquad (12)\n",
        "$$\n",
        "\n",
        "と表せます．この式は，次のように変形できます．\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\frac{1}{N}\\sum_{n=1}^{N}y_n^2 &= \\frac{1}{N}\\sum_{n=1}^{N} (\\pmb{u}\\cdot\\pmb{x}_n)(\\pmb{u}\\cdot\\pmb{x}_n) \\qquad (13)\\\\\n",
        "&= \\frac{1}{N}\\sum_{n=1}^{N} \\left(\\pmb{u}^{\\top}\\pmb{x}_n\\right) \\left(\\pmb{u}^{\\top}\\pmb{x}_n\\right)^{\\top} \\qquad (14)\\\\\n",
        "&= \\frac{1}{N}\\sum_{n=1}^{N} \\pmb{u}^{\\top}\\pmb{x}_n\\pmb{x}_n^{\\top} \\pmb{u} \\qquad (15)\\\\\n",
        "&= \\pmb{u}^{\\top}\\left( \\frac{1}{N}\\sum_{n=1}^{N}\\pmb{x}_n\\pmb{x}_n^{\\top}\\right) \\pmb{u} = \\pmb{u}^{\\top}V\\pmb{u} \\qquad (16)\n",
        "\\end{aligned}\n",
        "$$\n",
        "<!---\n",
        "ただし，\n",
        "$$\n",
        "V = \\frac{1}{N}\\sum_{n=1}^{N}\\mathbf{x}_n\\mathbf{x}_n^{\\top}\n",
        "$$\n",
        "は，$\\mathbf{x}_n$ の平均が $\\mathbf{0}$ であるため，$\\mathbf{x}_n$の分散共分散行列に一致します．\n",
        "--->\n"
      ],
      "metadata": {
        "id": "Nys0svaO20HI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "いま求めたいのは，$y_n$ の分散 $\\pmb{u}^\\top V\\pmb{u}$ を最大にするベクトル $\\pmb{u}$ です．ただし，$\\pmb{u}$ は単位ベクトルに限定されていますので，$\\Vert\\pmb{u}\\Vert = 1$ という条件があります．\n",
        "このような制約条件付きの最適化問題を解く定番の手法は，「ラグランジュの未定乗数法」です（注）．\n",
        "この問題の場合，ラグランジュ乗数を $\\lambda$ として，\n",
        "\n",
        "$$\n",
        "L = \\pmb{u}^{\\top}V\\pmb{u} - \\lambda(\\pmb{u}^{\\top}\\pmb{u} - 1) \\qquad (17)\n",
        "$$\n",
        "\n",
        "とおけば，$\\frac{\\partial L}{\\partial \\pmb{u}} = \\pmb{0}$ を満たす $\\pmb{u}$ が解の候補となります．\n",
        "\n",
        "<br>\n",
        "<hr width=\"50%\" align=\"left\">\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: 「ラグランジュの未定乗数法」は，大学初年次の微積分で学んでいる...かも．興味のあるひとは数学の参考書を調べてね．\n",
        "</span>"
      ],
      "metadata": {
        "id": "O7wp00oc5zgi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここで，\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial \\pmb{u}} = 2V\\pmb{u} - 2\\lambda\\pmb{u} \\qquad (18)\n",
        "$$\n",
        "\n",
        "なので（注），解は\n",
        "\n",
        "$$\n",
        "V\\pmb{u} = \\lambda\\pmb{u} \\qquad (19)\n",
        "$$\n",
        "\n",
        "を満たさねばなりません．この式より，$V$ の単位固有ベクトルが解の候補であることがわかります．この式を $L$ の式に代入すると，\n",
        "\n",
        "$$\n",
        "L = \\lambda\\pmb{u}^\\top\\pmb{u} - \\lambda\\cdot 0 = \\lambda \\qquad (20)\n",
        "$$\n",
        "\n",
        "となります．解の候補は $V$ の単位固有ベクトルであり，そのときの $L$ の値が固有値に等しいということですので，$L$ を最大にする解は，$V$の最大固有値に対する固有ベクトルとなります．\n",
        "\n",
        "<br>\n",
        "<hr width=\"50%\" align=\"left\">\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: $\\frac{\\partial L}{\\partial \\pmb{u}}$ は，「$L$を $\\pmb{u}$ の各要素で偏微分したものをならべたベクトル」です．\n",
        "</span>"
      ],
      "metadata": {
        "id": "mJMtkVi69mKN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 2次元以上に次元削減する場合の主成分分析"
      ],
      "metadata": {
        "id": "bjM1Hxoo2Z4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **主成分分析** (Principal Component Analysis, PCA) は，多変量（多次元）のデータが与えられたときに，そのデータが含む情報をなるべく損なわずにより低次元のデータに変換するための多変量解析手法です．\n",
        "$D$個の変数から成る（$D$次元の）データが与えられたときに，それを$H \\leq D$ 個の変数で表す（$H$次元に変換する）ことを目的とします．この変換によってデータの次元数が削減されますので，このような操作は **次元削減** (Dimensionaliry Reduction) と呼ばれることもあります．主成分分析は，次元削減のための手法の一つです．\n",
        "\n",
        "\n",
        "$2 \\leq H \\leq D$ の場合の主成分分析について説明します．"
      ],
      "metadata": {
        "id": "GIVlsGuVIa-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$D$ 次元列ベクトル $\\pmb{x}$ に対して，$H$ 個の $D$ 次元列ベクトル $\\pmb{u}_1, \\pmb{u}_2, \\ldots,  \\pmb{u}_H$ を横にならべた行列を\n",
        "\n",
        "$$\n",
        "U = \\begin{pmatrix} \\pmb{u}_1 & \\pmb{u}_2 & \\cdots & \\pmb{u}_H \\end{pmatrix} \\qquad (21)\n",
        "$$\n",
        "\n",
        "とおきます．$U$ は $D\\times H$ 行列です．このとき，$\\pmb{x}$ に左から\n",
        "\n",
        "$$\n",
        "U^{\\top}\n",
        "=\n",
        "\\begin{pmatrix} \\pmb{u}_1 & \\pmb{u}_2 & \\cdots & \\pmb{u}_H \\end{pmatrix}^{\\top}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "\\pmb{u}_1^{\\top} \\\\ \\pmb{u}_2^{\\top} \\\\ \\vdots \\\\ \\pmb{u}_H^{\\top}\n",
        "\\end{pmatrix} \\qquad (22)\n",
        "$$\n",
        "\n",
        "をかけたものを $\\pmb{y}$ とおくと，\n",
        "\n",
        "$$\n",
        "\\pmb{y} = U^{\\top}\\pmb{x}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "\\pmb{u}_1^{\\top} \\\\ \\pmb{u}_2^{\\top} \\\\ \\vdots \\\\ \\pmb{u}_H^{\\top}\n",
        "\\end{pmatrix} \\pmb{x}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "\\pmb{u}_1^{\\top}\\pmb{x} \\\\ \\pmb{u}_2^{\\top}\\pmb{x} \\\\ \\vdots \\\\ \\pmb{u}_H^{\\top}\\pmb{x}\n",
        "\\end{pmatrix}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "\\pmb{u}_1\\cdot\\pmb{x} \\\\ \\pmb{u}_2\\cdot\\pmb{x} \\\\ \\vdots \\\\ \\pmb{u}_H\\cdot\\pmb{x}\n",
        "\\end{pmatrix}  \\qquad (23)\n",
        "$$\n",
        "\n",
        "は $H$ 次元ベクトルになります．したがって，何らかの方法で $H$ 個の $D$ 次元ベクトル $\\pmb{u}_1, \\pmb{u}_2, \\ldots, \\pmb{u}_H$ を定めてそれらをならべた行列 $U$ を作り，式$(23)$ の $\\pmb{y} = U^{\\top}\\pmb{x}$ という計算を行うことで，$D$ 次元のデータを $H$ 次元に変換することができます．\n",
        "\n",
        "<img width=800 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/dimreduction_new.png\">\n"
      ],
      "metadata": {
        "id": "XMLVhOrzTmWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "では，$\\pmb{u}_1, \\ldots, \\pmb{u}_H$ はどのように定めればよいのでしょうか．\n",
        "いろいろな考え方ができるのですが，主成分分析では，「データが含む情報をなるべく損なわずにより低次元のデータに変換する」ために，「**変換後のデータの分散の総和がなるべく大きくなるように（元のデータの分散を保つように）**（注）」します．$H = 1$ の場合，これを実現するには，「データの分散共分散行列の最大固有値に対応する単位固有ベクトル」を選べばよい，ということでした．\n",
        "\n",
        "$H = 2$ の場合は，$\\pmb{u}_1$を「データの分散共分散行列の最大固有値に対応する単位固有ベクトル」とした上で，$\\pmb{u}_2$ を「データの分散のうち $\\pmb{u}_1$ で説明しきれなかった分を最もよく説明できる向き」にとります．\n",
        "これは，$\\pmb{u}_2$ を，「$\\pmb{u}_1$ に直交しかつ大きさが $1$ のベクトルの中で，$y_2 = \\pmb{u}_2\\cdot\\pmb{x}$ の分散が最も大きくなるものとする」ことを意味し，$\\pmb{u}_2$ を「データの分散共分散行列の2番目に大きな固有値に対応する固有ベクトル」の向きにとればよいことがわかっています（数学的にきちんとした議論は省略します）．\n",
        "\n",
        "<br>\n",
        "<hr width=\"50%\" align=\"left\">\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: 一般の（$H \\geq 2$の）場合，$\\pmb{y}$ の各要素間の共分散が $0$ になるように（分散共分散行列が対角行列になるように）かつ各要素の分散（分散共分散行列の対角要素）の和が最大になるようにします．\n",
        "</span>"
      ],
      "metadata": {
        "id": "pAOZuV5aJQor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "下図は，$D=3$ の場合を図示しています．左の図のピンクのベクトルは $\\pmb{u}_1$ を表しており，このデータはこのベクトルの向きに最も分散が大きくなっています．\n",
        "中央の緑色の平面は，原点を通りかつピンクのベクトルと直交しています．$\\pmb{u}_2$ は，この平面内の様々な向きのベクトルたち（?で示されているもの）の中から選ぶことになります．このとき，下図右のように，この緑の平面上でデータ点を眺めたときに分散が最も大きくなる方向を選べば，$y_2$の分散を最大化することになります．\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/pcafig06.png\">"
      ],
      "metadata": {
        "id": "ZXRpJN7sNMz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$H \\geq 3$ の場合も，$\\pmb{u}_2$ と同じように一つずつベクトルを追加していくと考えることができます．すなわち，$\\pmb{u}_3$ は，$\\pmb{u}_{1}, \\pmb{u}_2$ の両方に直交する単位ベクトルの中で分散最大の方向のものとし，$\\pmb{u}_4$ は $\\pmb{u}_{1}, \\pmb{u}_2, \\pmb{u}_3$ の全てに直交し...，という具合です．そして，結論として，次のことがいえます．\n",
        "\n",
        "---\n",
        "\n",
        "［主成分分析］\n",
        "\n",
        "$N$個の$D$次元列ベクトルから成るデータ\n",
        "\n",
        "$$\n",
        "\\{ \\pmb{x}_n  | n = 1, 2, \\ldots, N\\}\n",
        "$$\n",
        "\n",
        "を，$D \\times H$ 行列 $U$ によって\n",
        "\n",
        "$$\n",
        "\\mathbf{y}_n = U^{\\top}\\mathbf{x}_n\n",
        "$$\n",
        "\n",
        "と $H$ 次元に変換することを考える．ただし，$\\{\\pmb{x}_n\\}$ の平均は $\\pmb{0}$ とする．\n",
        "このとき，変換後のデータの分散の総和がなるべく大きくなるように（元のデータの分散を保つように）したいならば，$U$ を次のように構成すればよい．\n",
        "\n",
        "1. データの分散共分散行列の固有値と固有ベクトルを求める．固有値を $\\lambda_1 \\geq \\lambda_2 \\geq \\lambda_3 \\geq \\cdots \\geq \\lambda_D$ とし，それぞれに対応する単位固有ベクトルを $\\pmb{u}_1, \\pmb{u}_2, \\ldots, \\pmb{u}_D$ とおく（注）．\n",
        "2. $\\pmb{u}_1, \\pmb{u}_2, \\ldots, \\pmb{u}_H$ をならべて， $D\\times H$ 行列 $U$ を $U = \\begin{pmatrix} \\pmb{u}_1 & \\pmb{u}_2 & \\cdots & \\pmb{u}_H \\end{pmatrix}$ とする．\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "<hr width=\"50%\" align=\"left\">\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: 分散共分散行列は対称行列であるため，固有値は必ず実数となります．また，$0$ 以上となることもいえます．\n",
        "</span>\n"
      ],
      "metadata": {
        "id": "OrEf0iSLUtkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 主成分と主成分スコア"
      ],
      "metadata": {
        "id": "NhDUc51hZ2tp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$D$ 個の変数から成るベクトル $\\pmb{x}$ を上記の手順で $H$ 個の変数から成るベクトル $\\pmb{y}$ に変換したとき，得られる $H$ 個の変数のうち $h$ 番目のもの（$\\pmb{y}$ の $h$ 番目の要素，$h = 1, 2, \\ldots, H$）を，**第 $h$ 主成分** と呼びます．\n",
        "上記の説明から分かるように，番号の小さい主成分ほど元のデータの分散をよく表す変数となっています．\n",
        "直感的な言い方になりますが，番号の小さい主成分ほど元のデータの散らばりをよく表す重要な変数といえます．\n",
        "また，一つのデータを変換して得られる$H$個の主成分のうち，第 $h$ 主成分の変数の値のことを，**第 $h$ 主成分スコア** と呼びます．\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PjpHUPHfag4s"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qIms0G6fxxk-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}