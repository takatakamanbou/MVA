{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPX2+fJh+43guOTmVnNTpJb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/MVA/blob/main/MVA2024_ex15notebookB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MVA2024 ex15notebookB\n",
        "\n",
        "<img width=64 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/MVA-logo15.png\"> https://www-tlab.math.ryukoku.ac.jp/wiki/?MVA/2024"
      ],
      "metadata": {
        "id": "P4preLw7SzqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 機械学習のデモ\n",
        "---\n",
        "\n",
        "この授業で学んだ内容の延長上には様々な話がありますが，ここでは，その一つの方向である **機械学習** についてのデモを実行してみましょう．\n",
        "機械学習については，3年1Q,2Qの「機械学習I/II」で学ぶことができます．\n",
        "\n",
        "「機械学習I/II」のページ https://www-tlab.math.ryukoku.ac.jp/wiki/?ML\n"
      ],
      "metadata": {
        "id": "Snu_5I6aGJS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# いつものいろいろインポート\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()\n",
        "\n",
        "import pickle\n",
        "import json\n",
        "import io\n",
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "# Python の深層学習フレームワーク PyTorch のいろいろ\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from torchvision.io.image import read_image, ImageReadMode\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "fNTL-WXQeUa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb6297a2-af65-4d1b-aea5-6d346b836ae1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 1000種類の物体を識別するニューラルネットを動かしてみよう\n",
        "\n",
        "ニューラルネットワークを用いた画像識別の実験をやってみましょう． いろんなものが識別できた方が楽しいと思いますので，1000種類の物体を識別させてみます． ただし，そういうことができるニューラルネットワークを一から学習させようとすると大変（↑ののりで実行したら何日もかかります）ですので，ここではすでに学習済みのものを利用することにします．"
      ],
      "metadata": {
        "id": "HKbbcYlyS1mi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 準備"
      ],
      "metadata": {
        "id": "m_05KKmfwFQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずは実験に使う画像データを準備します．\n",
        "\n",
        "**注意: 以下の画像をこの実験以外の目的で使用してはいけません**"
      ],
      "metadata": {
        "id": "P-AmCU9NCRGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/animalphoto.pickle\n",
        "with open('animalphoto.pickle', 'rb') as f:\n",
        "    hoge = pickle.load(f)\n",
        "\n",
        "imgList = []\n",
        "for d in hoge:\n",
        "    img = Image.frombytes(**d)\n",
        "    imgList.append(img)\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1Io3_Xdj5NMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1000個あるクラスの番号とクラスラベルの対応表を作成します．"
      ],
      "metadata": {
        "id": "dwjnxlnZqkSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageNet クラスラベルを表すJSONファイルを入手\n",
        "!wget -nc https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
        "class_index = json.load(open('imagenet_class_index.json', 'r'))\n",
        "\n",
        "K = len(class_index)\n",
        "labels = {}\n",
        "for ik, key in enumerate(class_index.keys()):\n",
        "    labels[ik] = f'{class_index[key][0]} {class_index[key][1]}'\n",
        "    if 276 <= ik < 300:\n",
        "        print(ik, labels[ik])"
      ],
      "metadata": {
        "id": "-5nFrG_ywpOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の出力は，1000クラスのうちの一部のものの名前を表します．「ネコ」みたいなものも1クラスではなく，281番 'tabby'（ぶち柄の猫），282番 'tiger_cat'（トラ縞の猫）等々のように分かれています．"
      ],
      "metadata": {
        "id": "goVX8Ln9CZ-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習済みのニューラルネットワークのパラメータを入手します．\n",
        "規模の大きいネットワークでパラメータがたくさんありますので，読み込みに少し時間がかかります．"
      ],
      "metadata": {
        "id": "v0srx3ogtOaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "vgg16.eval()\n",
        "print(vgg16)"
      ],
      "metadata": {
        "id": "uLg8zK7HyDKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のセルを実行すると，次のことが行われます．\n",
        "1. ニューラルネットワークの学習モデルを作成する．\n",
        "1. 学習済みのネットワークパラメータの値を読み込んでこのネットワークのパラメータに設定する．\n",
        "1. ネットワークモデルの構造を表示する．"
      ],
      "metadata": {
        "id": "g-V8tZ5Atyqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "参考:\n",
        "\n",
        "ここで用いているのは VGG16 というニューラルネットワークモデルです．イギリスオックスフォード大学の [Visual Geometry Group(VGG)](https://www.robots.ox.ac.uk/~vgg/) という研究グループが作った VGG-net というニューラルネットワークモデルのうちの，層が16層あるものです．\n",
        "VGG-net は，2014年に行われた [ILSVRC2014](https://www.image-net.org/challenges/LSVRC/2014/) という画像識別のコンペティションで世界第2位となったニューラルネットワークモデルです．\n",
        "ILSVRC2014では，[ImageNet](https://www.image-net.org/) という大規模な画像データセットの中から選ばれた 1000 種類の物体の画像約120万枚を学習データとしていました．\n"
      ],
      "metadata": {
        "id": "103RZrZeu1vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "画像をネットワークに入力できる形式に加工する処理を定義しておきます．\n"
      ],
      "metadata": {
        "id": "TVwByjcG1cyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "GeUATyKI2AYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 実験1\n",
        "\n",
        "上記のサンプル画像たちを VGG16 に識別させてみましょう．\n"
      ],
      "metadata": {
        "id": "uyWss1-izFXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 以下で 0 から 3 までの整数を選ぶと4つのサンプル画像の中から一つを選ぶことができます．\n",
        "i = 0 #@param [0, 1, 2, 3] {type: 'raw'}\n",
        "img = imgList[i]\n",
        "\n",
        "# 画像を表示\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(img)\n",
        "ax.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# VGG16 ネットワークに入力して出力を得る\n",
        "X = torch.unsqueeze(preprocess(imgList[i]), axis=0)\n",
        "Y = vgg16(X)\n",
        "Z = torch.nn.functional.softmax(Y, dim=1)\n",
        "P = Z[0].detach().numpy()\n",
        "\n",
        "# 出力の値の大きかった方から5つを表示\n",
        "for i, ik in enumerate(np.argsort(-P)[:5]):\n",
        "    print(f'rank{i+1}: {P[ik]:.6f} {labels[ik]}')"
      ],
      "metadata": {
        "id": "9pp3WWir8sLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の画像の下の出力は，1000個のクラスの中で，ネットワークの出力の値が大きかったもの上位5位までの，出力の値とクラス名を表します．\n",
        "出力の値は，そのクラスと判定することの「確信度」と解釈できます．"
      ],
      "metadata": {
        "id": "-dKliElj-rnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 実験2\n",
        "\n",
        "自分で用意した画像でも実験してみましょう．\n",
        "\n",
        "- 上記では動物の例ばかりですが，1000のクラスの中にはそれ以外にも様々なものがあります（人間のクラスはありません）\n",
        "- 面白い／不思議な結果が得られたら takataka に見せてくれると喜びます\n",
        "\n"
      ],
      "metadata": {
        "id": "Ss4c8IAe_9Um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) まずは，ウェブ等で適当な画像を探して，この Colab notebook を実行しているコンピュータへ保存しましょう．ファイル名が長かったり日本語を含んでいる場合は，短い名前に変更しておくのがよいです．\n",
        "\n",
        "(2) 以下のセルをコメントの指示にしたがって修正してから実行して，ファイルをアップロードします．"
      ],
      "metadata": {
        "id": "Sii3vXZ8AU2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 以下の 0 を 1 に修正してセルを実行しよう\n",
        "#\n",
        "if 1 == 0:\n",
        "    # Colab へファイルをアップロード\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        rv = files.upload()\n",
        "    except:\n",
        "        print('このコードは Colab 以外の環境では実行できないよ．')"
      ],
      "metadata": {
        "id": "o83_b8kY9_Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) 以下のセルの1行目のファイル名を上記でアップロードしたものに変えて実行しましょう．アルファベット大文字小文字の区別もありますので注意．うまくいけば画像が表示されるはずです．"
      ],
      "metadata": {
        "id": "PHZCqDSHBiG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fn = 'hoge.jpg' # ここを拡張子含めてアップロードしたファイルの名前に変更\n",
        "try:\n",
        "    myimg = Image.open(fn)\n",
        "    if myimg.mode != 'RGB':\n",
        "        myimg = myimg.convert('RGB')\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(myimg)\n",
        "    ax.axis('off')\n",
        "    plt.show()\n",
        "except FileNotFoundError:\n",
        "    print(f'ファイル {fn} が見つかりません．このセルの1行目を正しいファイル名に変更して実行し直してね．')"
      ],
      "metadata": {
        "id": "F72S_3eO9Ask"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4) 以下のセルを実行すれば結果が表示されます．"
      ],
      "metadata": {
        "id": "YGckmXO7Bzs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16 ネットワークに入力して出力を得る\n",
        "X = torch.unsqueeze(preprocess(myimg), axis=0)\n",
        "Y = vgg16(X)\n",
        "Z = torch.nn.functional.softmax(Y, dim=1)\n",
        "P = Z[0].detach().numpy()\n",
        "\n",
        "# 出力の値の大きかった方から5つを表示\n",
        "for i, ik in enumerate(np.argsort(-P)[:5]):\n",
        "    print(f'rank{i+1}: {P[ik]:.6f} {labels[ik]}')"
      ],
      "metadata": {
        "id": "u8vrSrciBbgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 物体検出してみよう\n",
        "\n",
        "画像の中に写っている複数の物体を検出する問題を扱うニューラルネットを動かしてみましょう．このニューラルネットは，一枚の画像を入力すると，画像中の物体ごとに，その位置とそれが何であるかを表す情報を出力します．"
      ],
      "metadata": {
        "id": "ZCS63ZHXhptY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 準備"
      ],
      "metadata": {
        "id": "zLdHNT52h65u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここでは，FasterRCNN と呼ばれる，ニューラルネットによる物体検出の仕組みの事前学習済みモデルを使います．\n",
        "このモデルは，COCO (https://cocodataset.org/) と呼ばれる大規模画像データセットで 81 種類の物体の検出を学習したものです．\n",
        "\n",
        "- Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun, \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks,\" NeurIPS 2015, https://arxiv.org/abs/1506.01497\n",
        "- https://pytorch.org/vision/0.15/models/generated/torchvision.models.detection.fasterrcnn_resnet50_fpn.html"
      ],
      "metadata": {
        "id": "jtDTE-kViDg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FasterRCNN の事前学習済みモデルを入手\n",
        "\n",
        "weights = models.detection.FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
        "preprocess = weights.transforms()\n",
        "model = models.detection.fasterrcnn_resnet50_fpn_v2(weights=weights, box_score_thresh=0.9)\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "#print(model)\n",
        "\n",
        "# 物体のクラスの一覧を出力\n",
        "n = 0\n",
        "for cn in weights.meta[\"categories\"]:\n",
        "    if cn != 'N/A':\n",
        "        print(n, cn, end='\\n')\n",
        "        n += 1"
      ],
      "metadata": {
        "id": "MGHUhrwpy1I2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "実験用のサンプル画像を入手します．これらは，COCOデータセットの学習用または評価用のデータの一部です．"
      ],
      "metadata": {
        "id": "leVkuWnycQ67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像を入手\n",
        "urlDict = {\n",
        "    'dog':'https://farm6.staticflickr.com/5124/5379029845_60f6314172_z.jpg',\n",
        "    'cats':'https://farm1.staticflickr.com/16/23200321_dcff6ba227_z.jpg',\n",
        "    'carelephant':'https://farm8.staticflickr.com/7157/6822207699_71e174fd3f_z.jpg',\n",
        "    'bicycles':'https://farm1.staticflickr.com/33/67728109_0d11a646ef_z.jpg',\n",
        "    'teddybears':'https://farm4.staticflickr.com/3584/3554604954_2e01e4d007_z.jpg',\n",
        "}\n",
        "\n",
        "for key in urlDict.keys():\n",
        "    rv = requests.get(urlDict[key])\n",
        "    assert rv.status_code == 200, '画像のダウンロードに失敗しました'\n",
        "    with io.BytesIO(rv.content) as buf:\n",
        "        img = Image.open(buf)\n",
        "        fn = f'{key}.png'\n",
        "        print(fn)\n",
        "        fig, ax = plt.subplots(1)\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "        img.save(fn)"
      ],
      "metadata": {
        "id": "GB2BmM_PD1WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 実験3\n",
        "\n",
        "上記のサンプル画像で実験してみましょう．"
      ],
      "metadata": {
        "id": "SNvkeOT8il0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 以下で 0 から 4 までの数をひとつ選んでからこのセルを実行すると，物体検出の結果が表示されます．\n",
        "i = 0 #@param [0, 1, 2, 3, 4] {type: 'raw'}\n",
        "\n",
        "key = list(urlDict.keys())[i]\n",
        "fn = f'{key}.png'\n",
        "print(fn)\n",
        "\n",
        "# 画像を読み込んでモデルへの入力に加工\n",
        "img = read_image(fn)\n",
        "X = torch.unsqueeze(preprocess(img), axis=0).to(device)\n",
        "\n",
        "# モデルの出力を計算\n",
        "Y = model(X)[0]\n",
        "\n",
        "# 出力の情報を画像に加工\n",
        "labels2 = [weights.meta['categories'][i] for i in Y['labels']]\n",
        "bbox = draw_bounding_boxes(img, boxes=Y['boxes'], labels=labels2, colors='#00ff00', width=3)\n",
        "imgResult = to_pil_image(bbox.detach())\n",
        "imgResult"
      ],
      "metadata": {
        "id": "agQUgL5CW2in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 実験4\n",
        "\n",
        "自分で用意した画像でも実験してみましょう．\n",
        "\n",
        "- 81種類の物体クラスのリストを参考に，適当な画像をいろいろ探してみよう\n",
        "- 面白い／不思議な結果が得られたら takataka に見せてくれると喜びます\n",
        "\n"
      ],
      "metadata": {
        "id": "6-C0GC57jnny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 以下の 0 を 1 に修正してセルを実行しよう\n",
        "#\n",
        "if 1 == 0:\n",
        "    # Colab へファイルをアップロード\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        rv = files.upload()\n",
        "    except:\n",
        "        print('このコードは Colab 以外の環境では実行できないよ．')"
      ],
      "metadata": {
        "id": "OUrxT8fckWB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fn = 'teddybears.png' # ここを拡張子含めてアップロードしたファイルの名前に変更\n",
        "try:\n",
        "    img = read_image(fn, mode=ImageReadMode.RGB)\n",
        "    X = torch.unsqueeze(preprocess(img), axis=0)\n",
        "    Y = model(X)[0]\n",
        "    labelss = [weights.meta['categories'][i] for i in Y['labels']]\n",
        "    bbox = draw_bounding_boxes(img, boxes=Y['boxes'], labels=labelss, colors='#00ff00', width=3)\n",
        "    imgResult = to_pil_image(bbox.detach())\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.imshow(imgResult)\n",
        "    ax.axis('off')\n",
        "except FileNotFoundError:\n",
        "    print(f'ファイル {fn} が見つかりません．このセルの1行目を正しいファイル名に変更して実行し直してね．')"
      ],
      "metadata": {
        "id": "EExunq0fXKrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X2d70sU5k0FL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}