{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOJZV18p4wd9Jkqzkamqs+7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/MVA/blob/main/MVA2024_ex15notebookA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MVA2024 ex15notebookA\n",
        "\n",
        "<img width=64 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/MVA-logo.png\"> https://www-tlab.math.ryukoku.ac.jp/wiki/?MVA/2024"
      ],
      "metadata": {
        "id": "P4preLw7SzqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 多変量解析から機械学習へ − 識別問題の例 −\n",
        "---\n",
        "\n",
        "「多変量解析及び演習」に続く科目はいくつかありますが，ここでは「機械学習I/II」（3年1Q2Q）や「機械学習特論I/II」（大学院1Q2Q）等で学ぶ内容を少しだけ紹介します．\n",
        "これらの授業の一部の回では，この授業の「判別分析」の回に学んだ識別問題，すなわち，与えられたデータを予め定めたいくつかのクラスに分類する問題を扱います．\n",
        "\n",
        "<b><font color=\"#ff0000\">\n",
        "注意:\n",
        "今回の notebook の中には，コードセルを実行すると問題の解答が表示されるようになっている箇所があります．\n",
        "</font>\n",
        "</b>\n"
      ],
      "metadata": {
        "id": "qFyVRrU4A005"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 準備あれこれ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()\n",
        "\n",
        "# scipy の多変量正規分布\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "### 機械学習ライブラリ scikit-learn のいろいろ\n",
        "#\n",
        "# データの準備他いろいろ\n",
        "from sklearn.datasets import make_moons, fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# 二次判別分析\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "# 混合正規分布モデル(Gaussian Mixture Model)\n",
        "from sklearn.mixture import GaussianMixture\n",
        "# 階層型ニューラルネットワーク\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# 「解答」を示す際に文字列を復号するのに使う\n",
        "import base64\n",
        "# 復号した文字列を Markdown 形式で（数式は LaTeX でフォーマットして）表示\n",
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "Uba-rqwa906l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 判別分析ではうまくいかない例\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4W_LrQcBYGAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "判別分析は，「クラスごとのデータが正規分布に従っている」という仮定をおく手法ですので，データがこの条件を満たさない場合は良い結果を得られないことがあります．\n",
        "「判別分析 (2)」の回の notebookB「判別分析に関する補足」で使ったのと同じようなデータでもう一度実験してみましょう．"
      ],
      "metadata": {
        "id": "0wMh4zVYYsRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### データの準備"
      ],
      "metadata": {
        "id": "BulPDB2Fa-CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 例題のデータを生成\n",
        "K = 2\n",
        "NL, NT = 500, 500\n",
        "X_moon, Y_moon = make_moons(n_samples=NL+NT, noise=0.2)\n",
        "XL, yL = X_moon[:NL, :], Y_moon[:NL]\n",
        "XT, yT = X_moon[NL:, :], Y_moon[NL:]\n",
        "print(XL.shape, yL.shape)\n",
        "print(XT.shape, yT.shape)"
      ],
      "metadata": {
        "id": "7-LwfOdbBZac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 散布図を表示\n",
        "xmin, xmax = -2, 3\n",
        "ymin, ymax = -2.5, 2.5\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "ax0 = fig.add_subplot(121)\n",
        "ax0.scatter(XL[yL==0, 0], XL[yL==0, 1], marker='.', label='Class0')\n",
        "ax0.scatter(XL[yL==1, 0], XL[yL==1, 1], marker='.', label='Class1')\n",
        "ax0.set_xlim(xmin, xmax)\n",
        "ax0.set_ylim(ymin, ymax)\n",
        "ax0.set_aspect('equal')\n",
        "ax0.legend()\n",
        "ax0.set_title('training data')\n",
        "ax1 = fig.add_subplot(122)\n",
        "ax1.scatter(XT[yT==0, 0], XT[yT==0, 1], marker='.', label='Class0')\n",
        "ax1.scatter(XT[yT==1, 0], XT[yT==1, 1], marker='.', label='Class1')\n",
        "ax1.set_xlim(-2, 3)\n",
        "ax1.set_ylim(-2.5, 2.5)\n",
        "ax1.set_aspect('equal')\n",
        "ax1.legend()\n",
        "ax1.set_title('test data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LB_SEe07BlZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "左図が学習データ（パラメータの推定に用いるデータ），右図がテストデータ（得られた識別モデルの性能評価に用いるデータ）を示します．クラスごとのデータが明らかに正規分布に従っていません．"
      ],
      "metadata": {
        "id": "liVvUi8XbVSs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 二次判別分析"
      ],
      "metadata": {
        "id": "kr_VyOstcNWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のデータに二次判別分析を適用してみると..."
      ],
      "metadata": {
        "id": "WMqRzzzo7i3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データを用いて二次判別分析モデルのパラメータを推定する\n",
        "#   ＝ クラスごとのデータに正規分布を当てはめる\n",
        "qda = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
        "qda.fit(XL, yL)\n",
        "mu = qda.means_\n",
        "cov = np.array(qda.covariance_)\n",
        "print(mu.shape, cov.shape)"
      ],
      "metadata": {
        "id": "rqJywJbeFff9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# グラフ描画用のグリッドデータの作成\n",
        "x_mesh, y_mesh = np.mgrid[xmin:xmax:0.02, ymin:ymax:0.02]\n",
        "X_mesh = np.dstack((x_mesh, y_mesh))\n",
        "\n",
        "# 尤度の計算\n",
        "p = qda.predict_proba(X_mesh.reshape((-1, 2))).T\n",
        "pp = p.reshape((K, X_mesh.shape[0], X_mesh.shape[1]))\n",
        "\n",
        "# グラフ\n",
        "fig = plt.figure(facecolor=\"white\", figsize=(10, 6))\n",
        "\n",
        "# 左図\n",
        "ax0 = fig.add_subplot(121)\n",
        "for k in range(K):\n",
        "    ax0.scatter(XL[yL==k, 0], XL[yL==k, 1], marker='.')\n",
        "    z = multivariate_normal.pdf(X_mesh, mean=mu[k], cov=cov[k])\n",
        "    ax0.contour(x_mesh, y_mesh, z, levels=4)\n",
        "ax0.set_xlim(xmin, xmax)\n",
        "ax0.set_ylim(ymin, ymax)\n",
        "ax0.set_aspect('equal')\n",
        "\n",
        "# 右図\n",
        "cmap = ['Blues', 'Oranges', 'Greens']\n",
        "ax1 = fig.add_subplot(122)\n",
        "for k in range(K):\n",
        "    ax1.scatter(XL[yL==k, 0], XL[yL==k, 1], marker='.')\n",
        "    ax1.contourf(x_mesh, y_mesh, pp[k], levels=[0.5, 0.6, 0.7, 0.8, 0.9, 1.0], cmap=cmap[k], alpha=0.3)\n",
        "ax1.set_xlim(xmin, xmax)\n",
        "ax1.set_ylim(ymin, ymax)\n",
        "ax1.set_aspect('equal')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 学習データ/テストデータの正答率\n",
        "print(f'学習データの正答率: {qda.score(XL, yL)}')\n",
        "print(f'テストデータの正答率: {qda.score(XT, yT)}')"
      ],
      "metadata": {
        "id": "BJD7SiGafrVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "左図は，推定された正規分布を学習データに重ねて表示しています．右図は，推定された正規分布を用いて計算した尤度の値を可視化しています．\n",
        "図の下の数値は，識別の正答率（accuracy）を表しています．\n",
        "\n",
        "予想通り，クラス毎のデータに正規分布がうまく当てはまらないため，2クラスをうまく分けることができていません．"
      ],
      "metadata": {
        "id": "TrJUwahbgZCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 問題1\n",
        "\n",
        "次の箱の中に入る数を答えなさい．\n",
        "\n",
        "この実験の場合，データの分布を表すための正規分布の平均は $\\fbox{?}$ 次元ベクトルで，分散共分散行列は $\\fbox{?} \\times \\fbox{?}$ 行列である．推定される平均は全部で $\\fbox{?}$個，推定される分散共分散行列は全部で $\\fbox{?}$ 個である．"
      ],
      "metadata": {
        "id": "RhChFtlY909j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# このセルを実行すると，上記の問に対する解答例が表示されます\n",
        "Q = b'CuWFqOOBpiAyCg=='\n",
        "display(Markdown(base64.b64decode(Q).decode('utf-8')))"
      ],
      "metadata": {
        "id": "cXBXNPLt-m5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 混合正規分布モデル\n",
        "\n"
      ],
      "metadata": {
        "id": "3GcR7kPPcFWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上で見たように，正規分布は単純すぎてうまくデータの分布を表現できないことがあります．\n",
        "そういう場合への対応の仕方はいろいろありますが，ここでは，「複数の正規分布の重み付き和」で表される「混合正規分布モデル」(Gaussian mixture model)を紹介します（注）．\n",
        "\n",
        "これは，$M$個の正規分布の重み付き和で，次のように表されます．\n",
        "\n",
        "$$\n",
        "p(\\pmb{x}) = \\sum_{m=1}^{M} w_m N(\\pmb{x}|\\pmb{\\mu}_m, \\Sigma_m) \\qquad (1)\n",
        "$$\n",
        "\n",
        "$N(\\pmb{x}|\\pmb{\\mu}_m, \\Sigma_m)$ は平均 $\\pmb{\\mu}_m$ 分散共分散行列 $\\Sigma_m$ の多変量正規分布です．$w_m$ は $m$ 番目の正規分布の重みを表し，$0 \\leq w_m \\leq 1, \\sum_{m=1}^M w_m = 1$ を満たします．\n",
        "混合正規分布モデルでは，$w_m, \\pmb{\\mu}_m, \\Sigma_m$ がモデルパラメータとなります．\n",
        "\n",
        "<br>\n",
        "<hr width=\"50%\" align=\"left\">\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: 「混合正規分布モデル」については，大学院科目「機械学習I/II」で学べるかも．</span>"
      ],
      "metadata": {
        "id": "drlhv8wBcboy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "試しに，上記のデータに $M=3$ の混合正規分布モデルを当てはめて識別する実験をやってみましょう．クラスごとのデータに 式$(1)$ 混合正規分布を当てはめます．\n",
        "詳しくは説明しませんが，判別分析のときと同様に，尤度の大小によってクラスを識別することができます．\n",
        "\n",
        "次のコードセルを実行すると，データに混合正規分布モデルを当てはめる計算を行います．"
      ],
      "metadata": {
        "id": "SfIEqZPOez8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M = 3 # クラスごとの GMM の混合数（正規分布の数）\n",
        "\n",
        "N, D = XL.shape\n",
        "\n",
        "# 事前確率 = クラスごとのデータの出現確率を推定\n",
        "py = np.empty(K)\n",
        "for k in range(K):\n",
        "    py[k] = np.sum(yL == k) / NL\n",
        "\n",
        "# クラスごとのデータの分布をGMMでモデル化\n",
        "mu = np.empty((K, M, D))\n",
        "cov = np.empty((K, M, D, D))\n",
        "gmm = np.empty(K, dtype=object)\n",
        "for k in range(K):\n",
        "    XX = XL[yL==k, :]\n",
        "    gmm[k] = GaussianMixture(n_components=M, covariance_type='full', verbose=2, verbose_interval=1)\n",
        "    gmm[k].fit(XX)\n",
        "    mu[k, ::] = gmm[k].means_\n",
        "    cov[k, ::] = gmm[k].covariances_"
      ],
      "metadata": {
        "id": "qw9Axaejk8pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のコードセルを実行すると，当てはめの結果と，それを用いて2次元平面上の各点を2クラスに識別した結果を可視化します．"
      ],
      "metadata": {
        "id": "FpM0uXES8uTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# グラフ描画用のグリッドデータの作成\n",
        "x_mesh, y_mesh = np.mgrid[xmin:xmax:0.02, ymin:ymax:0.02]\n",
        "X_mesh = np.dstack((x_mesh, y_mesh))\n",
        "print(X_mesh.shape)\n",
        "\n",
        "# 尤度の計算\n",
        "p = np.empty((K, X_mesh.shape[0]*X_mesh.shape[1]))\n",
        "for k in range(K):\n",
        "    proba = np.exp(gmm[k].score_samples(X_mesh.reshape((-1, 2))))\n",
        "    p[k, :] = py[k] * proba\n",
        "p /= np.sum(p, axis=0)\n",
        "pp = p.reshape((K, X_mesh.shape[0], X_mesh.shape[1]))\n",
        "\n",
        "# グラフ\n",
        "fig = plt.figure(facecolor=\"white\", figsize=(10, 6))\n",
        "\n",
        "# Gaussian を当てはめた結果\n",
        "ax0 = fig.add_subplot(121)\n",
        "for k in range(K):\n",
        "    ax0.scatter(XL[yL==k, 0], XL[yL==k, 1], marker='.')\n",
        "    for m in range(M):\n",
        "        z = multivariate_normal.pdf(X_mesh, mean=mu[k, m], cov=cov[k, m])\n",
        "        ax0.contour(x_mesh, y_mesh, z, levels=4)\n",
        "ax0.set_xlim(xmin, xmax)\n",
        "ax0.set_ylim(ymin, ymax)\n",
        "ax0.set_aspect('equal')\n",
        "\n",
        "# 尤度の可視化\n",
        "cmap = ['Blues', 'Oranges', 'Greens']\n",
        "ax1 = fig.add_subplot(122)\n",
        "for k in range(K):\n",
        "    ax1.scatter(XL[yL==k, 0], XL[yL==k, 1], marker='.')\n",
        "    ax1.contourf(x_mesh, y_mesh, pp[k], levels=[0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], cmap=cmap[k], alpha=0.3)\n",
        "ax1.set_xlim(xmin, xmax)\n",
        "ax1.set_ylim(ymin, ymax)\n",
        "ax1.set_aspect('equal')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 学習データの識別\n",
        "N = XL.shape[0]\n",
        "LL = np.empty((N, K))\n",
        "for k in range(K):\n",
        "    LL[:, k] = gmm[k].score_samples(XL) # 対数尤度\n",
        "Yp = np.argmax(LL, axis=1)\n",
        "ncorrect = np.sum(yL == Yp)\n",
        "print(f'学習データの正答率: {ncorrect/N}')\n",
        "\n",
        "# テストデータの識別\n",
        "N = XT.shape[0]\n",
        "LL = np.empty((N, K))\n",
        "for k in range(K):\n",
        "    LL[:, k] = gmm[k].score_samples(XT)\n",
        "Yp = np.argmax(LL, axis=1)\n",
        "ncorrect = np.sum(yT == Yp)\n",
        "print(f'テストデータの正答率: {ncorrect/N}')"
      ],
      "metadata": {
        "id": "80S58YAVcG7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習データテストデータともに，単一の正規分布を当てはめたとき（二次判別分析を適用したとき）よりも高い正答率が得られています（注）．\n",
        "\n",
        "<br>\n",
        "<hr width=\"50%\" align=\"left\">\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: データに単一の正規分布を当てはめる最尤推定では，一撃の計算で最適なパラメータが求まります．しかし，混合正規分布モデルの場合，パラメータの推定は，適当な初期値からより尤度の大きいパラメータを求める計算を繰り返して徐々に最適化していく手続きとなります．そのため，上記のセルの実行結果は，セルを実行し直すたびに少し変わり得ます．"
      ],
      "metadata": {
        "id": "nb46AcYXlGVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`M = 3` のところの数を変えると，正規分布の数を変えられます．いろいろ変えてみるとよいでしょう（あまり多くするとエラーになるかもしれません）．"
      ],
      "metadata": {
        "id": "zYSrQn4CgDss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 問題2\n",
        "\n",
        "次の箱の中に入る数を答えなさい．\n",
        "\n",
        "この実験で $M = 3$ とした場合，推定すべき平均は全部で $\\fbox{?}$個，推定すべき分散共分散行列は全部で $\\fbox{?}$ 個である．"
      ],
      "metadata": {
        "id": "udny-b3u-8rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# このセルを実行すると，上記の問に対する解答例が表示されます\n",
        "Q = b'Ck0gPSAzIOOBrua3t+WQiOato+imj+WIhuW4g+ODouODh+ODq+OBq+OBr++8jDPjgaTjga7lubPlnYfjgajliIbmlaPlhbHliIbmlaPooYzliJfjgYzjgYLjgorjgb7jgZnvvIjjgZ3jga7ku5bvvIzph43jgb8gJHdfMSwgd18yLCB3XzMkIOOCguaOqOWumuOBmeOBueOBjeODkeODqeODoeODvOOCv+OBqOOBquOCiuOBvuOBme+8ie+8jgrjgZPjga7lrp/pqJPjga8y44Kv44Op44K56K2Y5Yil5ZWP6aGM44Gq44Gu44Gn77yMMuOBpOOBruOCr+ODqeOCueOBruODh+ODvOOCv+OBq+OBneOCjOOBnuOCjOa3t+WQiOato+imj+WIhuW4g+ODouODh+ODq+OCkuW9k+OBpuOBr+OCgeOBvuOBme+8jgrjgZfjgZ/jgYzjgaPjgabvvIzmjqjlrprjgZnjgbnjgY3lubPlnYfjga/lhajpg6jjgacgJDIgXHRpbWVzIDMgPSA2JCDlgIvvvIzliIbmlaPlhbHliIbmlaPooYzliJfjgoLlhajpg6jjgacgJDYkIOWAi+OBguOCiuOBvuOBme+8jgo='\n",
        "display(Markdown(base64.b64decode(Q).decode('utf-8')))"
      ],
      "metadata": {
        "id": "8a8MZNay-8rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ニューラルネットワーク\n"
      ],
      "metadata": {
        "id": "1eJQdN7O8Nho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次は，ニューラルネットワークの例です．ニューラルネットワークは，こんにちのAIの中核となっている機械学習モデルです．\n",
        "ここではその詳細については省略します（注）．\n",
        "\n",
        "次のコードセルを実行すると，データを2クラスに分けるニューラルネットワークモデルのパラメータを推定します．その計算は，与えられたデータをモデルに入力して予測値を求め，予測値と正解との間のずれに応じてパラメータを修正する作業の繰り返しです．次のセルを実行して表示される `loss` の値は，学習データに対するそのずれの大きさを表します．\n",
        "\n",
        "<br>\n",
        "<hr width=\"50%\" align=\"left\">\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: 「ニューラルネットワーク」については，3年次科目「機械学習I/II」で学べるかも．</span>"
      ],
      "metadata": {
        "id": "7Gd13lbkCLrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ニューラルネットワークモデルの作成\n",
        "neunet = MLPClassifier(hidden_layer_sizes=[500, 500], activation='relu', verbose=True)\n",
        "# 学習（パラメータの推定）\n",
        "neunet.fit(XL, yL)"
      ],
      "metadata": {
        "id": "adWoT-jizIC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# グラフ描画用のグリッドデータの作成\n",
        "x_mesh, y_mesh = np.mgrid[xmin:xmax:0.02, ymin:ymax:0.02]\n",
        "X_mesh = np.dstack((x_mesh, y_mesh))\n",
        "\n",
        "# 事後確率の推定\n",
        "p = neunet.predict_proba(X_mesh.reshape((-1, 2))).T\n",
        "pp = p.reshape((K, X_mesh.shape[0], X_mesh.shape[1]))\n",
        "\n",
        "# グラフ\n",
        "fig = plt.figure(facecolor=\"white\", figsize=(4, 4))\n",
        "\n",
        "# 事後確率の可視化\n",
        "cmap = ['Blues', 'Oranges', 'Greens']\n",
        "ax1 = fig.add_subplot(111)\n",
        "for k in range(K):\n",
        "    ax1.scatter(XL[yL==k, 0], XL[yL==k, 1], marker='.')\n",
        "    ax1.contourf(x_mesh, y_mesh, pp[k], levels=[0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], cmap=cmap[k], alpha=0.3)\n",
        "ax1.set_xlim(xmin, xmax)\n",
        "ax1.set_ylim(ymin, ymax)\n",
        "ax1.set_aspect('equal')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 学習データ/テストデータの正答率\n",
        "print(f'学習データの正答率: {neunet.score(XL, yL)}')\n",
        "print(f'テストデータの正答率: {neunet.score(XT, yT)}')"
      ],
      "metadata": {
        "id": "KRhWqCPQ9TDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "混合正規分布モデルの場合と同様に，2つのクラスをそれなりにうまく分けることができているようです．"
      ],
      "metadata": {
        "id": "BpQPuPHdPB5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 手書き数字識別\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RB9mNGQWAnj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以前扱った手書き数字のデータと同様のものを用いて，10クラスの画像識別の実験をやってみましょう．"
      ],
      "metadata": {
        "id": "jqe2HP11HR5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### データの準備"
      ],
      "metadata": {
        "id": "QJdtom2DA0Fq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "「判別分析 (2)」の回の notebookC「演習課題: 手書き数字識別」で扱ったデータは，MNIST と呼ばれる有名な手書き数字データセット（全部で6万枚の数字画像から成る）から 6000 枚を取り出したものでしたが，ここでは2万枚を取り出して使います．"
      ],
      "metadata": {
        "id": "6EKXnf6HHlOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST データセットの入手\n",
        "Xraw, yraw = fetch_openml('mnist_784', version=1, parser='auto', return_X_y=True, as_frame=False)\n",
        "Xall = Xraw[:20000] / 255.0     # 画素値が [0, 255] の整数値なので [0, 1] の浮動小数点数値に変換\n",
        "yall = yraw[:20000].astype(int) # クラスラベル．0 から 9 の整数値\n",
        "\n",
        "# 学習データとテストデータの分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xall, yall, test_size=4000, random_state=4649, stratify=yall)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "N_train, N_test = len(X_train), len(X_test)\n",
        "\n",
        "K = 10"
      ],
      "metadata": {
        "id": "2aajL46Mqn6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2万枚のうち16000枚を学習（パラメータの推定）用にし，残り4000枚をテスト（性能の評価）用にします．"
      ],
      "metadata": {
        "id": "cneGt3HfILkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データの一部を可視化\n",
        "nrow, ncol = 4, 10\n",
        "fig, ax = plt.subplots(nrow, ncol, figsize=(8, 4))\n",
        "for i in range(nrow):\n",
        "    for j in range(ncol):\n",
        "        n = i * ncol + j\n",
        "        ax[i, j].imshow(X_train[n].reshape(28, 28), vmin=0, vmax=1, cmap='gray')\n",
        "        ax[i, j].axis('off')\n",
        "        ax[i, j].set_title(f'{y_train[n]}')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tlBtA5gV9d-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 二次判別分析"
      ],
      "metadata": {
        "id": "Z-HEcPlICMZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずは二次判別分析．"
      ],
      "metadata": {
        "id": "Bf9Vs4MnIVcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データを用いて二次判別分析のパラメータを推定\n",
        "qda = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
        "qda.fit(X_train, y_train)\n",
        "\n",
        "# 推定されたパラメータの shape を表示\n",
        "mu = qda.means_\n",
        "cov = np.array(qda.covariance_)\n",
        "print(f'mu.shape: {mu.shape}')\n",
        "print(f'cov.shape: {cov.shape}')\n",
        "\n",
        "# 平均を可視化\n",
        "fig, ax = plt.subplots(1, 10, figsize=(8, 1))\n",
        "for k in range(10):\n",
        "    ax[k].imshow(mu[k].reshape(28, 28), vmin=0, vmax=1, cmap='gray')\n",
        "    ax[k].axis('off')\n",
        "    ax[k].set_title(f'{k}')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8nOLsW9Dn75x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上の画像は，クラスごとのデータの平均を可視化したものです．\n",
        "推定されたパラメータを使って識別させてみて，その正答率を求めると，次のようになります．"
      ],
      "metadata": {
        "id": "Z6tv0-RpIqrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 正答率\n",
        "print(f'学習データの正答率   = {qda.score(X_train, y_train)}')\n",
        "print(f'テストデータの正答率 = {qda.score(X_test, y_test)}')\n",
        "print()\n",
        "# 混同行列  confusion[i, j] は，正解がクラス i で予測がクラス j だったものの数\n",
        "y_pred = qda.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "print(confusion)"
      ],
      "metadata": {
        "id": "kF7tnMyCtnZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "以前の実験よりもデータ数を増やしたので，次元削減しなくても一応それなりの結果が出ました．"
      ],
      "metadata": {
        "id": "744xst4NSJW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 混合正規分布モデル"
      ],
      "metadata": {
        "id": "HLhBt17RER3D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次は混合正規分布モデルを用いた実験です．2次元データの例では，混合正規分布モデルに含まれる正規分布の分散共分散行列の形には何ら制約はありませんでした．しかし，こちらのデータは次元数が大きい（784次元）ので，同じようにすると，推定しなければならないパラメータ数が膨大になり，パラメータをうまく推定できなくなる心配があります．そのため，ここでは，全ての分散共分散行列が対角行列であるとする制約を課すことにします．これによって，制約すべきパラメータ数を大きく減らすことができます（注）．\n",
        "\n",
        "<br>\n",
        "<hr width=\"50%\" align=\"left\">\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: 次元数 $D$ のとき，制約のない分散共分散行列のひとつのパラメータ数は $\\frac{1}{2}D(D+1)$ 個，対角行列に限定される場合は $D$ 個．\n",
        "</span>"
      ],
      "metadata": {
        "id": "OGSwjQSCSOB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習\n",
        "M = 3\n",
        "\n",
        "py = np.empty(K)\n",
        "gmm = np.empty(K, dtype=object)\n",
        "for k in range(K):\n",
        "    print(f'##### class{k} #####')\n",
        "    py[k] = np.sum(y_train == k) / NL\n",
        "    # covariance_type = 'diag' は，分散共分散行列を対角行列に限定．`full` だと任意\n",
        "    gmm[k] = GaussianMixture(n_components=M, covariance_type='diag', verbose=2, verbose_interval=1)\n",
        "    gmm[k].fit(X_train[y_train == k, :])\n",
        "\n",
        "# 平均の可視化\n",
        "fig, ax = plt.subplots(M, K, figsize=(8, 8/K*M))\n",
        "for k in range(K):\n",
        "    for m in range(M):\n",
        "        img = gmm[k].means_[m, :].reshape((28, 28))\n",
        "        ax[m, k].imshow(img, cmap=plt.cm.gray, vmin=0, vmax=1)\n",
        "        ax[m, k].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nFQXuzT1wma8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 問題3\n",
        "\n",
        "上の画像は，クラスごとの学習データに混合正規分布モデルを当てはめて得られる平均を可視化したものです．この画像の枚数が表示されたようになる理由を考えなさい．\n"
      ],
      "metadata": {
        "id": "TEuP3FNcU8qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データの識別\n",
        "LL = np.empty((N_train, K))\n",
        "for k in range(K):\n",
        "    LL[:, k] = gmm[k].score_samples(X_train) + np.log(py[k])\n",
        "y_pred = np.argmax(LL, axis=1)\n",
        "countL = np.sum(y_pred == y_train)\n",
        "\n",
        "# テストデータの識別\n",
        "LT = np.empty((N_test, K))\n",
        "for k in range(K):\n",
        "    LT[:, k] = gmm[k].score_samples(X_test) + np.log(py[k])\n",
        "y_pred = np.argmax(LT, axis=1)\n",
        "countT = np.sum(y_pred == y_test)\n",
        "\n",
        "# 結果の表示\n",
        "print(f'M = {M}   train: {countL}/{N_train} = {countL/N_train:.3f}   test: {countT}/{N_test} = {countT/N_test:.3f}')\n",
        "# 混同行列  confusion[i, j] は，正解がクラス i で予測がクラス j だったものの数\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "print(confusion)"
      ],
      "metadata": {
        "id": "PNoPIFcS2x5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "混合正規分布モデルを用いると，二次判別分析よりよい結果が得られるようです．`M` の値をいろいろ変えて実験してみましょう．"
      ],
      "metadata": {
        "id": "0OcFujPbVnV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ニューラルネットワーク"
      ],
      "metadata": {
        "id": "WKHhZoisJ9ih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次はニューラルネットワークの例です．次のコードセルを実行すると，ニューラルネットワークを学習（モデルパラメータを修正する作業を何度も繰り返す）させます．データの数も次元数も大きいので，数分かかります．"
      ],
      "metadata": {
        "id": "RF_klAx2WMCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ニューラルネットワークモデルの作成\n",
        "neunet = MLPClassifier(hidden_layer_sizes=[1000, 1000], activation='relu', verbose=True)\n",
        "# 学習（パラメータの推定）\n",
        "neunet.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "mpxJFjIFG9cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "二次判別分析や混合正規分布モデルを用いた手法と比べて，正答率はどう違うでしょうか．"
      ],
      "metadata": {
        "id": "HGre8bKoZP-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 正答率\n",
        "print(f'学習データの正答率   = {neunet.score(X_train, y_train)}')\n",
        "print(f'テストデータの正答率 = {neunet.score(X_test, y_test)}')\n",
        "print()\n",
        "# 混同行列  confusion[i, j] は，正解がクラス i で予測がクラス j だったものの数\n",
        "y_pred = neunet.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "print(confusion)"
      ],
      "metadata": {
        "id": "gNK8P3HGEWcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sbalyQFcMoN3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}