{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPSqcwmBwyhhtm0JwVOu3Ir",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/MVA/blob/2022/ex15notebookC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UzDNLmVS3po"
      },
      "source": [
        "# Data2022 ex15notebookC\n",
        "\n",
        "<img width=64 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/Data/Data-logo15.png\"> https://www-tlab.math.ryukoku.ac.jp/wiki/?Data/2022\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H45eNIcd2xB"
      },
      "source": [
        "----\n",
        "## 多変量解析や機械学習に関するデモ\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4-TmUdCd9FJ"
      },
      "source": [
        "---\n",
        "### 準備\n",
        "\n",
        "\n",
        "\n",
        "以下，コードセルを上から順に実行していってね．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ8M3640S1W7"
      },
      "source": [
        "# 科学技術計算のライブラリ NumPy のモジュールを np という名前で使えるようにする\n",
        "import numpy as np\n",
        "\n",
        "# グラフを描くためのライブラリ matplotlib の pyplot を plt という名前でインポート\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 機械学習のためのライブラリ scikit-learn のいろいろ\n",
        "from sklearn.cluster import KMeans                  # K-means 法のクラス\n",
        "from sklearn.preprocessing import StandardScaler    # 標準化の手続き\n",
        "from sklearn.linear_model import LogisticRegression # ロジスティック回帰\n",
        "from sklearn.neural_network import MLPClassifier    # 階層型ニューラルネット\n",
        "\n",
        "# 「1000種類の物体を識別するニューラルネットを動かしてみよう」のためのほげ\n",
        "import pickle\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####  データの最初の nx x ny 枚を可視化する関数の定義\n",
        "#\n",
        "def mosaicImage(ax, dat, nx, ny, nrow=64, ncol=64, gap=4):\n",
        "\n",
        "    # 並べた画像の幅と高さ\n",
        "    width  = nx * (ncol + gap) + gap\n",
        "    height = ny * (nrow + gap) + gap\n",
        "\n",
        "    # 画像の作成\n",
        "    img = np.zeros((height, width), dtype=int) + 128\n",
        "    for iy in range(ny):\n",
        "        lty = iy*(nrow + gap) + gap\n",
        "        for ix in range(nx):\n",
        "            if iy*nx+ix >= dat.shape[0]:\n",
        "                break\n",
        "            ltx = ix*(ncol + gap) + gap\n",
        "            img[lty:lty+nrow, ltx:ltx+ncol] = dat[iy*nx+ix, :].reshape((nrow, ncol))\n",
        "\n",
        "    # 表示\n",
        "    ax.axis('off')\n",
        "    ax.imshow(img, cmap='gray')\n"
      ],
      "metadata": {
        "id": "8BL9YM3EVBh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM4RlkyhP5yo"
      },
      "source": [
        "----\n",
        "### クラスター分析／クラスタリング\n",
        "\n",
        "**クラスター分析**／**クラスタリング** は，多変量データをクラスタ分けする（似たもの同士でグループに分ける）ための手法です．\n",
        "\n",
        "ここでは，「K-means法（K-平均法）」と呼ばれるアルゴリズムを使って，猫の画像をクラスタリングしてみましょう．まずは，データやプログラムの準備をします．以下のセルたちを順次実行してください．\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lnqr_MVSXeFT"
      },
      "source": [
        "(1) 猫画像データを入手して，一部を表示させます．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DZPnNd2WxEi"
      },
      "source": [
        "# 猫顔画像データを入手\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/Data/cat131.npz\n",
        "cat = np.load('cat131.npz')['cat131']\n",
        "Ncat, Dcat = cat.shape\n",
        "print(f'データ数 x 次元数 = {Ncat} x {Dcat}')\n",
        "\n",
        "# 最初の 20 枚を表示\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "mosaicImage(ax, cat, 5, 4)\n",
        "plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdSq_0oSXaFq"
      },
      "source": [
        "(2) K-means法によってクラスタリングを行います．K-means法は，データとデータの間の距離にもとづいて，データを K 通りのクラスタに分ける手法です（クラスタの数 K はあらかじめ指定します）．ここでは，Python で機械学習に関する様々な処理を行える scikit-learn というライブラリを使っています．\n",
        "\n",
        "- [scikit-learn](https://scikit-learn.org/)\n",
        "- [sklearn.cluster.KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpyiHu5dW2aC"
      },
      "source": [
        "K = 3  # K-means 法でいくつのクラスタに分けるか\n",
        "\n",
        "model = KMeans(n_clusters=K) # 学習モデルの定義． n_cluster でクラスタ数を指定\n",
        "model.fit(cat) # K-means クラスタリングを実行\n",
        "label = model.predict(cat) # 各画像の所属クラスタを求める\n",
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gQB5oKgXTGH"
      },
      "source": [
        "(3) 結果を表示させてみましょう．一つのクラスタに属する画像を横に並べてあります．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hqS3DxeXN7x"
      },
      "source": [
        "# 各クラスタに割り振られた画像のうち最初の10枚を横に並べて表示\n",
        "nc = 10\n",
        "dat = np.zeros((K, nc, Dcat))\n",
        "for ik in range(K):\n",
        "    idx = label == ik\n",
        "    n = np.sum(idx)\n",
        "    if n < nc:\n",
        "        dat[ik, :n, :] = cat[idx, :]\n",
        "    else:\n",
        "        dat[ik, :, :] = cat[idx, :][:nc, :]\n",
        "\n",
        "dat = dat.reshape((-1, Dcat))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "mosaicImage(ax, dat, nc, K)\n",
        "plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lo4pMhTYKvU"
      },
      "source": [
        "**★★★ 結果を観察しよう＆やってみよう★★★**\n",
        "\n",
        "上記では，猫画像を K = 3 の K-means法でクラスタリングする実験を行っています．\n",
        "\n",
        "K をいろいろ変えて（(2)のセルの `K = 3` の `3` を変えて）(2)と(3)の2つのコードセルを実行し直して，結果を観察しよう．\n",
        "\n",
        "ただし，データ数がそれほど多くないので，Kをあまり大きくすると空のクラスタができたりしてエラーになるかもしれません．また，K-meansクラスタリングの結果は初期値に依存するので，実行するたびに結果が変わります．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlfNl6Y-Uxuv"
      },
      "source": [
        "----\n",
        "### ロジスティック回帰やニューラルネットによる手書き数字画像の識別\n",
        "\n",
        "手書き数字画像のデータを使い，画像に描かれた数がいくつであるかを推測する実験をやってみましょう．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2QkGlRPb46h"
      },
      "source": [
        "#### データの準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UazekGU7ZpjS"
      },
      "source": [
        "データを入手して，一部を画像として眺めてみます．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StT7aUsJZrzn"
      },
      "source": [
        "# 手書き数字データの入手\n",
        "! wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/Data/minimnist.npz\n",
        "rv = np.load('minimnist.npz')\n",
        "X_train = rv['datL'].astype(float)\n",
        "Y_train = rv['labL']\n",
        "X_test = rv['datT'].astype(float)\n",
        "Y_test = rv['labT']\n",
        "#print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
        "\n",
        "K = 10 # クラス数\n",
        "\n",
        "# データの各要素を標準化（平均 0 分散1 にスケーリング）\n",
        "scaler = StandardScaler()\n",
        "XX_train = scaler.fit_transform(X_train)\n",
        "XX_test  = scaler.transform(X_test)\n",
        "\n",
        "print('### 手書き数字画像 ###')\n",
        "print(f'データ数 x 次元数 = {X_train.shape[0]} x {X_train.shape[1]}')\n",
        "\n",
        "# 最初の 60 枚を表示\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "mosaicImage(ax, X_train, 15, 4, nrow=28, ncol=28)\n",
        "plt.show()\n",
        "\n",
        "for i in range(4):\n",
        "    print(Y_train[i*15:(i+1)*15])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNesQEN9bP-T"
      },
      "source": [
        "このデータセットでは，1つの手書き数字画像は 28 x 28 画素ありますので，1つのデータを $784 (=28\\times 28)$ 次元ベクトルとして扱うことになります．\n",
        "画像の下に並んだ数字 `0 9 3 9 3 ...` は，これらの画像の手書き数字に対応する実際の数（正解）を表しています．"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ロジスティック回帰の実験\n",
        "\n",
        "前回ちょこっと説明した「ロジスティック回帰」は，与えられたデータを2通りに分類するものでしたが，よりたくさんの分類ができるように拡張できます．ここでは，784次元ベクトル5,000個から成る手書き数字画像データを，0 から 9 の10通りに分類させてみましょう．"
      ],
      "metadata": {
        "id": "bZe4Kaf2fDnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ロジスティック回帰モデルの学習では，間違えたらパラメータを修正することを何回も繰り返す必要があります．ここでは 500 回学習させてみます．少し時間がかかります．"
      ],
      "metadata": {
        "id": "NUJqXVBNf5Wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ロジスティック回帰モデルのインスタンスを生成\n",
        "model = LogisticRegression(max_iter=500)\n",
        "\n",
        "# 学習データを用いてモデルのパラメータを推定（学習）\n",
        "model.fit(XX_train, Y_train)"
      ],
      "metadata": {
        "id": "4WgehDDpfIT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習したモデルに数を予測させて，何個正解したか求めてみると，こんなんなります．"
      ],
      "metadata": {
        "id": "QZwMTjyxgD92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習データのクラスを予測させてみる\n",
        "Yt_train = model.predict(XX_train)\n",
        "nc_train = np.sum(Yt_train == Y_train) # 正解数\n",
        "\n",
        "# テストデータのクラスを予測させてみる\n",
        "Yt_test = model.predict(XX_test)\n",
        "nc_test = np.sum(Yt_test == Y_test) # 正解数\n",
        "\n",
        "# 結果を表示\n",
        "print(f'学習データ: {nc_train}/{len(Y_train)} = {nc_train/len(Y_train)}')\n",
        "print(f'テストデータ: {nc_test}/{len(Y_test)} = {nc_test/len(Y_test)}')"
      ],
      "metadata": {
        "id": "62dXrzARfWcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "テストデータの一部を画像として見るとこんなん．いくつか間違えてますね．"
      ],
      "metadata": {
        "id": "ZB0xv_enha4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "mosaicImage(ax, X_test, 15, 4, nrow=28, ncol=28)\n",
        "plt.show()\n",
        "print()\n",
        "print('予測:')\n",
        "for i in range(4):\n",
        "    print(Yt_test[i*15:(i+1)*15])\n",
        "print()\n",
        "print('正解:')\n",
        "for i in range(4):\n",
        "    print(Y_test[i*15:(i+1)*15])"
      ],
      "metadata": {
        "id": "WDM8ZKohgR-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0DMgSrtcDbu"
      },
      "source": [
        "#### ニューラルネットの実験\n",
        "\n",
        "次は，「ニューラルネットワーク」です．これは，最近のいわゆる人工知能の中核となっている機械学習の仕組みです（「深層学習 (deep learning)」という言葉を聞いたことがあるひともいるかもしれません）．\n",
        "以下では，簡単なニューラルネットの例で実験できるようにしてあります．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdD8AqG0dL4p"
      },
      "source": [
        "ここで使っているニューラルネットも学習の繰り返しが必要です．次のセルを実行すると，学習データ 5000 個を使って学習します． Iteration は1回の学習（5000個のデータ全部を使ってパラメータを推定する処理）を表し，loss はその学習を終えた時点での「損失」（正解とのずれの指標，小さいほど良い）の値を表します．\n",
        "\n",
        "繰り返すごとに損失が小さくなり，学習が進んでいくのがわかるでしょう．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHnkB1vMdXFw"
      },
      "source": [
        "# 階層型ニューラルネットのインスタンスを生成\n",
        "model = MLPClassifier(hidden_layer_sizes=(200, 200,), activation='relu', verbose=1)\n",
        "print(model)\n",
        "\n",
        "# 学習データを用いてモデルのパラメータを調整（学習）\n",
        "model.fit(XX_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OfKLBt8dcU0"
      },
      "source": [
        "学習したモデルに数を予測させて，何個正解したか求めてみると，こんなんなります．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNWlpkgNdlP9"
      },
      "source": [
        "# 学習データのクラスを予測させてみる\n",
        "Yt_train = model.predict(XX_train)\n",
        "nc_train = np.sum(Yt_train == Y_train) # 正解数\n",
        "\n",
        "# テストデータのクラスを予測させてみる\n",
        "Yt_test = model.predict(XX_test)\n",
        "nc_test = np.sum(Yt_test == Y_test) # 正解数\n",
        "\n",
        "# 結果を表示\n",
        "print(f'学習データ: {nc_train}/{len(Y_train)} = {nc_train/len(Y_train)}')\n",
        "print(f'テストデータ: {nc_test}/{len(Y_test)} = {nc_test/len(Y_test)}')     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KfdZ07KeqQi"
      },
      "source": [
        "**★★★ やってみよう★★★**\n",
        "\n",
        "1. ロジスティック回帰による手書き数字識別の実験をやって結果を観察しよう．正解率は何%くらい？\n",
        "1. ニューラルネットによる手書き数字識別の実験をやって結果を観察しよう．正解率は何%くらい？\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 1000種類の物体を識別するニューラルネットを動かしてみよう\n",
        "\n",
        "ニューラルネットワークを用いた画像識別の実験をやってみましょう． いろんなものが識別できた方が楽しいと思いますので，1000種類の物体を識別させてみます． ただし，そういうことができるニューラルネットワークを一から学習させようとすると大変（↑ののりで実行したら1週間以上かかかります）ですので，ここではすでに学習済みのものを利用することにします．"
      ],
      "metadata": {
        "id": "HKbbcYlyS1mi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 準備"
      ],
      "metadata": {
        "id": "m_05KKmfwFQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずは実験に使う画像データを準備します．\n",
        "\n",
        "**注意: 以下の画像をこの実験以外の目的で使用してはいけません**"
      ],
      "metadata": {
        "id": "P-AmCU9NCRGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://www-tlab.math.ryukoku.ac.jp/~takataka/course/ML/animalphoto.pickle\n",
        "with open('animalphoto.pickle', 'rb') as f:\n",
        "    hoge = pickle.load(f)\n",
        "\n",
        "imgList = []\n",
        "for d in hoge:\n",
        "    img = Image.frombytes(**d)\n",
        "    imgList.append(img)\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1Io3_Xdj5NMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1000個あるカテゴリの番号とそのラベルの対応表を作成します．"
      ],
      "metadata": {
        "id": "dwjnxlnZqkSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ImageNet カテゴリラベルを表すJSONファイルを入手\n",
        "!wget -nc https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
        "class_index = json.load(open('imagenet_class_index.json', 'r'))\n",
        "\n",
        "K = len(class_index)\n",
        "labels = {}\n",
        "for ik, key in enumerate(class_index.keys()):\n",
        "    labels[ik] = f'{class_index[key][0]} {class_index[key][1]}'\n",
        "    if 276 <= ik < 300: \n",
        "        print(ik, labels[ik])"
      ],
      "metadata": {
        "id": "-5nFrG_ywpOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の出力は，1000カテゴリのうちの一部のものの名前を表します．「ネコ」みたいなものも1カテゴリではなく，281番 'tabby'（ぶち柄の猫），282番 'tiger_cat'（トラ縞の猫）等々のように分かれています．"
      ],
      "metadata": {
        "id": "goVX8Ln9CZ-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習済みのニューラルネットワークのパラメータを入手します．\n",
        "規模の大きいネットワークでパラメータがたくさんありますので，読み込みに少し時間がかかります．"
      ],
      "metadata": {
        "id": "v0srx3ogtOaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = models.vgg16(pretrained=True)\n",
        "vgg16.eval()\n",
        "print(vgg16)"
      ],
      "metadata": {
        "id": "uLg8zK7HyDKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のセルを実行すると，次のことが行われます．\n",
        "1. ニューラルネットワークの学習モデルを作成する．\n",
        "1. 学習済みのネットワークパラメータの値を読み込んでこのネットワークのパラメータに設定する．\n",
        "1. ネットワークモデルの構造を表示する．"
      ],
      "metadata": {
        "id": "g-V8tZ5Atyqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここで用いているのは VGG16 というニューラルネットワークモデルです．イギリスオックスフォード大学の [Visual Geometry Group(VGG)](https://www.robots.ox.ac.uk/~vgg/) という研究グループが作った VGG-net というニューラルネットワークモデルのうちの，層が16層あるものです．\n",
        "VGG-net は，2014年に行われた [ILSVRC2014](https://www.image-net.org/challenges/LSVRC/2014/) という画像識別のコンペティションで世界第2位となったニューラルネットワークモデルです．\n",
        "\n",
        "ILSVRC2014では，[ImageNet](https://www.image-net.org/) という大規模な画像データセットの中から選ばれた画像約120万枚を使って画像識別のコンペが行われました．これらの画像には1000種類の物体のいずれか一つが写っており，何が写っているのかを表す情報も一緒に与えられていました．\n",
        "VGG16のニューラルネットワークは，そのような120万枚の画像を与えられて，それらの画像に写っているものが何であるか正しく識別するように訓練されています．訓練（学習）した1000種類の中のどれであるかを答えることしかできませんので，それ以外の画像を見せても，1000種類の中のどれかに間違えます．"
      ],
      "metadata": {
        "id": "103RZrZeu1vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "画像をネットワークに入力できる形式に加工する処理を定義しておきます．\n"
      ],
      "metadata": {
        "id": "TVwByjcG1cyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "GeUATyKI2AYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ★★★ やってみようその1\n",
        "\n",
        "上記のサンプル画像たちを VGG16 に識別させてみましょう．\n"
      ],
      "metadata": {
        "id": "uyWss1-izFXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 以下で 0 から 3 までの整数を選ぶと4つのサンプル画像の中から一つを選ぶことができます．\n",
        "i = 0 #@param [0, 1, 2, 3] {type: 'raw'}\n",
        "img = imgList[i]\n",
        "\n",
        "# 画像を表示\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(img)\n",
        "ax.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# VGG16 ネットワークに入力して出力を得る\n",
        "X = torch.unsqueeze(preprocess(imgList[i]), axis=0)\n",
        "Y = vgg16(X)\n",
        "Z = torch.nn.functional.softmax(Y, dim=1)\n",
        "P = Z[0].detach().numpy()\n",
        "\n",
        "# 出力の値の大きかった方から5つを表示\n",
        "for i, ik in enumerate(np.argsort(-P)[:5]):\n",
        "    print(f'rank{i+1}: {P[ik]:.6f} {labels[ik]}')"
      ],
      "metadata": {
        "id": "9pp3WWir8sLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の画像の下の出力は，1000個のカテゴリの中で，ネットワークの出力の値が大きかったもの上位5位までの，出力の値とカテゴリラベルを表します．\n",
        "出力の値は，そのカテゴリと判定することの「確信度」と解釈できます．"
      ],
      "metadata": {
        "id": "-dKliElj-rnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ★★★ やってみようその2\n",
        "\n",
        "自分で用意した画像でも実験してみましょう．\n",
        "\n",
        "- 上記では動物の例ばかりですが，1000のカテゴリの中にはそれ以外にも様々なものがあります（「人間」というカテゴリはありません．どうなる？）\n",
        "- 面白い／不思議な結果が得られたら takataka に見せてくれると喜びます\n",
        "\n"
      ],
      "metadata": {
        "id": "Ss4c8IAe_9Um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) まずは，ウェブ等で適当な画像を探して，この Colab notebook を実行しているコンピュータへ保存しましょう．ファイル名が長かったり日本語を含んでいる場合は，短い名前に変更しておくのがよいです．\n",
        "\n",
        "(2) 以下のセルを実行して，ファイルをアップロードします．"
      ],
      "metadata": {
        "id": "Sii3vXZ8AU2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab へファイルをアップロード\n",
        "try:\n",
        "    from google.colab import files\n",
        "    rv = files.upload()\n",
        "except:\n",
        "    print('このコードは Colab 以外の環境では実行できないよ．')"
      ],
      "metadata": {
        "id": "o83_b8kY9_Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) 以下のセルの1行目のファイル名を上記でアップロードしたものに変えて実行しましょう．アルファベット大文字小文字の区別もありますので注意．うまくいけば画像が表示されるはずです．"
      ],
      "metadata": {
        "id": "PHZCqDSHBiG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myimg = Image.open('hoge.png') # ファイル名を変更しましょう\n",
        "if myimg.mode != 'RGB':\n",
        "    myimg = myimg.convert('RGB')\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(myimg)\n",
        "ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F72S_3eO9Ask"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4) 以下のセルを実行すれば結果が表示されます．"
      ],
      "metadata": {
        "id": "YGckmXO7Bzs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16 ネットワークに入力して出力を得る\n",
        "X = torch.unsqueeze(preprocess(myimg), axis=0)\n",
        "Y = vgg16(X)\n",
        "Z = torch.nn.functional.softmax(Y, dim=1)\n",
        "P = Z[0].detach().numpy()\n",
        "\n",
        "# 出力の値の大きかった方から5つを表示\n",
        "for i, ik in enumerate(np.argsort(-P)[:5]):\n",
        "    print(f'rank{i+1}: {P[ik]:.6f} {labels[ik]}')"
      ],
      "metadata": {
        "id": "u8vrSrciBbgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e94_duuoCEcB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}