{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMiaGwBxw9oWKj7cIqtwAow",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/MVA/blob/2022/ex04notebookA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MVA2022 ex04notebookA\n",
        "\n",
        "<img width=64 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/MVA-logo.png\"> https://www-tlab.math.ryukoku.ac.jp/wiki/?MVA/2022"
      ],
      "metadata": {
        "id": "P4preLw7SzqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 注意\n",
        "---"
      ],
      "metadata": {
        "id": "AnF3LvGC-RA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "今回の授業で使う notebook では，出力のフォントの設定を適切にしないと表示が崩れて見づらい場合があります．今回の授業のページの「Colabの出力を固定幅にしよう」を参照して適切に設定してください．"
      ],
      "metadata": {
        "id": "bkqZa3xN-dUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "## 重回帰分析 (2)\n",
        "----"
      ],
      "metadata": {
        "id": "Kjddq7j6S48o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "前回の重回帰分析の説明では，統計学的な話は出てきませんでした．\n",
        "今回は，確率統計の考え方を導入して，回帰分析の問題を説明し直します．\n",
        "統計学の力を得ることで，より深い分析ができるようになります．\n"
      ],
      "metadata": {
        "id": "hHiVhy3jHUm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "seaborn.set()"
      ],
      "metadata": {
        "id": "cctqDki5y55F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 重回帰分析 ver.2\n",
        "\n",
        "確率統計の考え方にもとづいて重回帰分析の問題を設定し直します．\n"
      ],
      "metadata": {
        "id": "60pN0nMrzBRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " #### 問題設定"
      ],
      "metadata": {
        "id": "8CNc1t2se7kb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "変数 $x_1, x_2, \\ldots, x_D$ を用いて変数 $y$ を説明するために，両者の間に次の関係が成り立つと仮定します（このような関係のことを **線形回帰モデル** （線形重回帰モデル） といいます）．\n",
        " \n",
        "$$ y = w_0+w_1x_1 + w_2x_2 + \\cdots + w_Dx_D + \\epsilon \\qquad \\epsilon \\sim \\textrm{N}(0, \\sigma^2) \\qquad (1)$$\n",
        " \n",
        "ただし，$x_1, x_2, \\ldots, x_D$ （**説明変数**）は確率変数ではないものとします．\n",
        "一方， $\\epsilon$ （**誤差項**, 注）は確率変数で，平均 $0$ 分散 $\\sigma^2$ の正規分布に従うと仮定しています．\n",
        "$w_0, w_1, \\ldots, w_D$ および $\\sigma^2$ は定数です．\n",
        "$\\epsilon$ が確率変数であることから， $y$（**被説明変数**）も確率変数となります．\n",
        "\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: この文字はギリシャ文字で，「イプシロン」や「エプシロン」と読みます．\n",
        "</span>"
      ],
      "metadata": {
        "id": "zt7zfuqmWp1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "この式を変形すると\n",
        "\n",
        "$$\n",
        "\\epsilon = y - (w_0+w_1x_1+w_2x_2+\\cdots + w_Dx_D)\n",
        "$$\n",
        "\n",
        "となることからわかるように，\n",
        "誤差項は，$y$ を $w_0+w_1x_1+\\cdots + w_Dx_D$ で説明しようとして説明しきれなかったずれ（誤差）を表しています．\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qh-CD6TodF-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "重回帰分析の目的は，変数 $x_1, x_2, \\ldots, x_D$ と $y$ のペアから成る標本\n",
        "\n",
        "$$\n",
        "\\begin{array}{c}\n",
        "((x_{1,1}, x_{1,2}, \\ldots, x_{1,D}), y_1),\\\\\n",
        "((x_{2,1}, x_{2,2}, \\ldots, x_{2,D}), y_2),\\\\\n",
        "\\vdots \\\\\n",
        "((x_{N,1}, x_{N,2}, \\ldots, x_{N,D}), y_N)\\\\\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "が与えられたときに，式(1)で表されたモデルのパラメータ $w_0, w_1, \\ldots, w_D$ の値を推定することです．\n",
        "ただし，\n",
        "\n",
        "$$\n",
        "y_n = w_0+w_1x_{n,1} + w_2x_{n,2} + \\cdots + w_Dx_{n,D} + \\epsilon_n \\qquad (n = 1, 2, \\ldots, N)\n",
        "$$\n",
        "\n",
        "と表したときの誤差項 $\\epsilon_n$ は，互いに独立に $\\textrm{N}(0, \\sigma^2)$ に従うと仮定します．\n",
        "この仮定から，$y_n$ は互いに独立に\n",
        "\n",
        "$$\n",
        "\\textrm{N}(w_0+w_1x_{n,1} + w_2x_{n,2} + \\cdots + w_Dx_{n,D}, \\sigma^2)\n",
        "$$\n",
        "\n",
        "に従うことが導かれます（下図参照）．\n",
        "\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/regression.png\">"
      ],
      "metadata": {
        "id": "3IlOUZ_rduio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 回帰係数の推定"
      ],
      "metadata": {
        "id": "XWzBWXJ5jkPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の問題設定で説明した仮定のもとでは，与えられた標本を用いてパラメータ $w_0, w_1, \\ldots, w_D$ の推定値 $\\hat{w}_0, \\hat{w}_1, \\ldots, \\hat{w}_D$ （**回帰係数**） を求めるには，これらの標本に対する最小二乗法の問題を解けばよいことが知られています．\n",
        "つまり，$\\hat{w}_0, \\hat{w}_1, \\ldots, \\hat{w}_D$ の値は，\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "E(\\hat{w}_0, \\hat{w}_1, \\ldots, \\hat{w}_D) &=  \\sum_{n=1}^{N}(y_n - (\\hat{w}_0 + \\hat{w}_1x_{n,1} + \\cdots + \\hat{w}_Dx_{n,D}))^2\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "を最小化する問題の解であり，次の連立方程式（**正規方程式**）の解となります．\n",
        "\n",
        "$$\n",
        "X^{\\top}X\n",
        "\\begin{pmatrix}\n",
        "\\hat{w}_0 \\\\ \\hat{w}_1 \\\\ \\vdots \\\\ \\hat{w}_D\n",
        "\\end{pmatrix} =\n",
        "X^{\\top}Y\n",
        "$$\n",
        "\n",
        "ここで，行列 $X, Y$ は次のようにおきました．\n",
        "\n",
        "$$\n",
        "X = \n",
        "\\begin{pmatrix}\n",
        "1 & x_{1,1} & x_{1,2} & \\cdots & x_{1,D}\\\\\n",
        "1 & x_{2,1} & x_{2,2} & \\cdots & x_{2,D}\\\\\n",
        "& & \\vdots\\\\\n",
        "1 & x_{N,1} & x_{N,2} & \\cdots & x_{N,D}\\\\\n",
        "\\end{pmatrix}\n",
        "\\qquad\n",
        "Y = \\begin{pmatrix}\n",
        "y_1\\\\ y_2 \\\\ \\vdots \\\\ y_N\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "JUgIXD9flUeS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 回帰分析の結果の推定や検定"
      ],
      "metadata": {
        "id": "4TdbJkuvT86z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "「問題設定」で述べたように確率統計の問題として定式化したことで，回帰係数の推定値がどのくらい信頼できるかを判断したり，仮定したモデルが妥当だったかどうかを判断するために，統計的推定・統計的仮説検定の道具が使えるようになります．\n",
        "\n",
        "以下，その概略について，導出過程などの説明は省略して簡単に記します．"
      ],
      "metadata": {
        "id": "TJK08LeEqt9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "モデルの仮定から，最小二乗法によって得られる推定値 $\\hat{w}_0, \\hat{w}_1, \\ldots, \\hat{w}_D$ も正規分布に従うこと，さらには，それぞれの平均が $w_0, w_1, \\ldots, w_D$ に等しいことが導かれます．\n",
        "つまり，回帰係数の推定値は真の回帰係数の不偏推定量となっています．\n",
        "分散も求まりますが，式の説明は省略します．\n",
        "一方，母分散 $\\sigma^2$ の不偏推定量 $\\hat{\\sigma}^2$ は，次式の通りとなります．\n",
        "\n",
        "\n",
        "$$\n",
        "\\hat{\\sigma}^2 = \\frac{1}{N-D-1}\\sum_{n=1}^{N}(y_n - \\hat{y}_n)^2 = \\frac{1}{N-D-1}\\sum_{n=1}^{N}(y_n - (\\hat{a}x_n + \\hat{b}))^2\n",
        "$$"
      ],
      "metadata": {
        "id": "Jyi3-__itYZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のことから，$\\hat{w}_d$ の「標準誤差」（分散の推定値の平方根）を $\\textrm{se}(\\hat{w}_d)$ とおくと，\n",
        "\n",
        "$$\n",
        "\\frac{\\hat{w}_d - w_d}{\\textrm{se}(\\hat{w}_d)}\n",
        "$$\n",
        "\n",
        "は自由度 $N - D - 1$ の $t$ 分布に従うことが分かります（標準誤差の具体的な式や $t$ 分布に従うことのちゃんとした説明は省略します）．\n",
        "\n"
      ],
      "metadata": {
        "id": "W6EsvKanY4aA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このことを用いて，回帰係数 $w_d$ ($d=0,1,\\ldots, D$) の「区間推定」や「統計的仮説検定」を行うことができます．\n",
        "例えば...\n",
        "\n",
        "- 個々の回帰係数の信頼区間を求めることができる．\n",
        "つまり，次のようなことを言えます．\n",
        "> $w_d$ は95%の割合で区間 $[0.34, 0.56]$ に入っている\n",
        "- 個々の回帰係数について，帰無仮説を $w_d = 0$ として（対立仮説を $w_d\\ne 0$ として）統計的仮説検定を行うことができます．\n",
        "$w_d = 0$ ということは説明変数 $x_d$ が被説明変数 $y$ に影響を与えていないということを表すので，この帰無仮説が棄却されて $w_d \\ne 0$ という結論が得られるなら，$x_d$ は $y$ に影響を与えていると主張することができます．\n",
        "\n",
        "ここではこれ以上詳しいことは説明しません．\n",
        "もっと詳しいことが知りたいひとは，この授業のウェブページのリンク先「MVAの参考情報」のページに記載されている書籍などを参照してください．\n"
      ],
      "metadata": {
        "id": "MpTbFekTbF3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 統計分析ツールを使ってみる\n",
        "\n",
        "前の節で説明したような統計的推定・検定のための計算は，自分でコードを書いて行うこともできますが，統計分析ツールを利用すると楽ちんです．\n",
        "\n",
        "ここでは，Python で利用できる統計分析ツールの一つである statsmodels （ https://www.statsmodels.org/ ）を使ってみることにします．\n",
        "統計分析ツールはこれ以外にもいろいろ（Python 以外のプログラミング言語向けのもの，Excel等の表計算ソフト向けのもの，etc.）あり，いずれも同じようなことができます．\n",
        "\n"
      ],
      "metadata": {
        "id": "nHkLgS851WC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# statsmodels の機能を利用できるようにモジュールをインポート\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "6uI3D27ouBi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "前回使ったのと同じデータで， statsmodels を使った回帰分析をやってみましょう．"
      ],
      "metadata": {
        "id": "OhKXCUV0pgCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データの読み込み\n",
        "df = pd.read_csv('https://github.com/ghmagazine/python_stat_sample/raw/master/data/ch12_scores_reg.csv')\n",
        "df.drop(columns='通学方法', inplace=True)\n",
        "df"
      ],
      "metadata": {
        "id": "djVvht0JzJo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "statsmodels で重回帰分析を行う方法については，次のセルに記したコメントを参考にしてください．"
      ],
      "metadata": {
        "id": "IxwSp5OBonUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## (小テスト, 睡眠時間) vs 期末テストの重回帰分析\n",
        "\n",
        "# データ行列の用意\n",
        "X = df.loc[:, ['小テスト', '睡眠時間']].to_numpy()\n",
        "Y = df['期末テスト'].to_numpy()\n",
        "\n",
        "#X1 = np.vstack([np.ones(len(X)), X.T]).T\n",
        "X1 = sm.add_constant(X)  # statsmodels の機能で 1 を付け足せる\n",
        "\n",
        "# statsmodels で重回帰分析\n",
        "model = sm.OLS(Y, X1) # 普通の最小二乗法 (Ordinary Least Squares) による線形回帰モデルを用意\n",
        "rv = model.fit()         # 線形回帰モデルの当てはめを実行\n",
        "print(rv.summary())     # 結果を表示"
      ],
      "metadata": {
        "id": "sLwMaJ6NxsDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "「結果を表示」の出力の一部について，以下に説明を書いておきます．\n",
        "<img src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/ols_summary.png\">\n",
        "\n",
        "- 「自由度調整済み決定係数」については，後述します\n",
        "- （小テスト,睡眠時間）と期末テストの間に次の関係があると推測される結果となりました（これまで計算してきたのと同じです）．\n",
        "\n",
        "$$\n",
        "(期末テスト) = -1.8709 + 6.4289\\times (小テスト) + 4.1917\\times (睡眠時間) + (誤差項)\n",
        "$$\n",
        "\n",
        "- （小テスト）の回帰係数の95%信頼区間は $[4.412, 8.446]$ と分かります\n",
        "- 「回帰係数の $t$ 検定の $p$ 値」と記した項目の値は，「回帰係数の値が $0$ に等しい」という帰無仮説に対する検定の p 値です．例えば有意水準を5%(0.05)とすると，次のように言えます\n",
        "    - `const`: 定数項が 0 であるとの帰無仮説は棄却されない\n",
        "    - `x1`: （小テスト） の回帰係数が 0 であるとの帰無仮説は棄却される → （小テスト） は (期末テスト) に影響している\n",
        "    - `x2`: （睡眠時間） も同様\n",
        " "
      ],
      "metadata": {
        "id": "G5DBcABUwzU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデルの選択"
      ],
      "metadata": {
        "id": "gDPXOd_9yXKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の例では，データの中に「小テスト」と「睡眠時間」という二つの説明変数がありました．\n",
        "この場合，\n",
        "\n",
        "$$\n",
        "(期末テスト) = w_0 +  w_1\\cdot (小テスト) + w_2\\cdot (睡眠時間) + (誤差項)\n",
        "$$\n",
        "\n",
        "というモデルではなく，\n",
        "\n",
        "$$\n",
        "(期末テスト) = w_0 +  w_1\\cdot (小テスト) + (誤差項)\n",
        "$$\n",
        "\n",
        "や\n",
        "\n",
        "$$\n",
        "(期末テスト) = w_0 +  w_1\\cdot (睡眠時間) + (誤差項)\n",
        "$$\n",
        "\n",
        "といったモデルの方が真の変数間の関係を表しているという可能性があります（注）．\n",
        "他の変数も手に入った場合さらに，それらも説明変数に加えたモデルも考えることになるでしょう．\n",
        "\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: それぞれのモデルの式に同じ記号の回帰係数が出てきますが，実際にはそれぞれ別のものです．また，2つの説明変数がどちらも被説明変数に影響を与えていない，\n",
        "$$\n",
        "(期末テスト) = w_0 +  (誤差項)\n",
        "$$\n",
        "というモデルもありえます．\n",
        "</span>\n",
        "\n"
      ],
      "metadata": {
        "id": "jdK9qQ69mJSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このような場合，すべての説明変数を加えたモデルで回帰分析を行って，それぞれの回帰係数が $0$ かどうか検定して，説明変数を取捨選択する，というのが一つの方法です．\n",
        "他にもう一つ，より直接的に，「説明変数の選び方の異なる様々なモデルを作ってみて，それらの中から適切なモデルを選択する」という方法も考えられます．\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M8_otauaqs-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "後者の方法を採用する場合，各モデルの「良さ」を定量的に判断するための基準が必要となります．これまでに知っているものの中では，**決定係数**（**寄与率**と呼ばれることもあります, R-squared）が最もその目的に合いそうです．決定係数は次式で定義される量であり，モデルの当てはまりの良さの基準となるのでした．\n",
        "\n",
        "$$\n",
        "r^2 = 1 - \\frac{\\mbox{(残差平方和)}}{\\mbox{(総平方和)}} = 1 - \\frac{\\displaystyle\\sum_{n=1}^{N}(y_n - \\hat{y}_n)^2}{\\displaystyle\\sum_{n=1}^{N}(y_n - \\bar{y})^2}\n",
        "$$\n",
        "\n",
        "ただし，$\\bar{y}$ は $y_n$ の平均値です．\n",
        "\n"
      ],
      "metadata": {
        "id": "SoIZwdByr-Jl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "決定係数を使ってモデルを選択できるかどうか，実際に計算してみましょう．\n",
        "以下のセルたちを実行すると，いくつかのモデルの設定で回帰分析を行って，決定係数の値を表示させることができます．"
      ],
      "metadata": {
        "id": "5MtWH4TfvS_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  小テスト vs 期末テスト\n",
        "X = df.loc[:, ['小テスト']].to_numpy()\n",
        "Y = df['期末テスト'].to_numpy()\n",
        "X1 = sm.add_constant(X)  # statsmodels の機能で 1 を付け足せる\n",
        "model = sm.OLS(Y, X1)\n",
        "rv = model.fit()\n",
        "print(f'決定係数:            {rv.rsquared:.3f}')\n",
        "#print(f'自由度調整済み決定係数: {rv.rsquared_adj:.3f}')"
      ],
      "metadata": {
        "id": "KhK-PsUT3W86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  睡眠時間 vs 期末テスト\n",
        "X = df.loc[:, ['睡眠時間']].to_numpy()\n",
        "Y = df['期末テスト'].to_numpy()\n",
        "X1 = sm.add_constant(X)  # statsmodels の機能で 1 を付け足せる\n",
        "model = sm.OLS(Y, X1)\n",
        "rv = model.fit()\n",
        "print(f'決定係数:            {rv.rsquared:.3f}')\n",
        "#print(f'自由度調整済み決定係数: {rv.rsquared_adj:.3f}')"
      ],
      "metadata": {
        "id": "208URXHK3dt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  (小テスト, 睡眠時間) vs 期末テスト\n",
        "X = df.loc[:, ['小テスト', '睡眠時間']].to_numpy()\n",
        "Y = df['期末テスト'].to_numpy()\n",
        "X1 = sm.add_constant(X)  # statsmodels の機能で 1 を付け足せる\n",
        "model = sm.OLS(Y, X1)\n",
        "rv = model.fit()\n",
        "print(f'決定係数:            {rv.rsquared:.3f}')\n",
        "#print(f'自由度調整済み決定係数: {rv.rsquared_adj:.3f}')"
      ],
      "metadata": {
        "id": "8dVA4JdJoWy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "これらを見ると，「小テスト」と「睡眠時間」の両方を説明変数とする重回帰モデルの決定係数の値が最も大きく，このモデルがこれらの中では最適と言えそうです．\n",
        "\n",
        "ですが，ここで，このデータに余分なデータを付け足してみるとどうなるでしょうか．試しに，説明変数として，「1から始まるただの番号」と「$[0, 1)$の一様分布にしたがう乱数」を追加してみましょう．\n",
        "どちらも，「期末テスト」に影響を与えるとは考えられないものです．\n"
      ],
      "metadata": {
        "id": "vMW7l7r-vxd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 「1から始まる番号」と「[0,.1)の一様分布乱数」のデータを作る\n",
        "np.random.seed(0)\n",
        "X2 = np.vstack([np.arange(1, len(X)+1), np.random.random(len(X))]).T\n",
        "print(X2)"
      ],
      "metadata": {
        "id": "XjLiYpuau7gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "こうして説明変数を4つにしたモデルで回帰分析を行って決定係数を求めてみると..."
      ],
      "metadata": {
        "id": "e_S5SHpowxd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  (小テスト, 睡眠時間, 番号, 乱数) vs 期末テスト\n",
        "X = df.loc[:, ['小テスト', '睡眠時間']].to_numpy()\n",
        "Y = df['期末テスト'].to_numpy()\n",
        "X = np.hstack([X, X2])\n",
        "X1 = sm.add_constant(X)\n",
        "print(X1)\n",
        "model = sm.OLS(Y, X1)\n",
        "rv = model.fit()\n",
        "print(f'決定係数:            {rv.rsquared:.3f}')\n",
        "#print(f'自由度調整済み決定係数: {rv.rsquared_adj:.3f}')"
      ],
      "metadata": {
        "id": "TzUpQyR75PVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "こちらの方が決定係数の値が大きくなってしまいました．\n",
        "実は，決定係数には，「あるモデルに（何でもいいから）もう一つ説明変数を付け足したモデルの決定係数の値は，元のモデルの決定係数の値と等しいかそれより大きくなる」という性質があります．\n",
        "上記の説明変数4つのモデルの決定係数の値が2つのモデルのそれより大きくなったのはこのためです．\n",
        "\n",
        "このような性質があるため，決定係数はモデルの選択に使う基準としては適切ではありません．\n",
        "かわりの基準として，「モデルの変数の数の違い（自由度の違い）を考慮に入れて調整した」決定係数である，**自由度調整済み決定係数**(Adjusted R-squared) というものが考案されています．\n",
        "この授業では回帰分析モデルの自由度についてのちゃんとした説明はしていませんので，結論のみを示すと，次のようになります．\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\widetilde{r}^2 &= 1 - \\frac{\\frac{\\mbox{(残差平方和)}}{N-D-1}}{\\frac{\\mbox{(総平方和)}}{N-1}} = 1 - \\frac{N-1}{N-D-1} \\frac{\\displaystyle\\sum_{n=1}^{N}(y_n - \\hat{y}_n)^2}{\\displaystyle\\sum_{n=1}^{N}(y_n - \\bar{y})^2} \\\\\n",
        "&= 1 - \\frac{N-1}{N-D-1} (1-r^2)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "役に立たない変数を追加して $r^2$ が少し大きくなったとしても，$D$が大きくなる効果の方が上回れば $\\widetilde{r}^2$ は逆に小さくなる，ということになります．"
      ],
      "metadata": {
        "id": "lvyOrR-Kw8Hr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のコードセルそれぞれの最後の行の `#` を外すと，自由度調整済み決定係数の値も表示してくれるようになります．\n",
        "確認してみてください．"
      ],
      "metadata": {
        "id": "CQYNkN5zy3FU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 多重共線性\n",
        "\n",
        "重回帰分析を行う際に注意が必要な問題である，データの **多重共線性** について説明します．"
      ],
      "metadata": {
        "id": "cFnZDC9IBBPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "見通しをよくするため，$D = 2$ の重回帰モデルで説明します．\n",
        "\n",
        "$$ y_n = w_0+w_1x_{n,1} + w_2x_{n,2} + \\epsilon_n $$\n",
        "\n",
        "この場合，データの行列を\n",
        "$$\n",
        "X = \n",
        "\\begin{pmatrix}\n",
        "1 & x_{1,1} & x_{1,2} \\\\\n",
        "1 & x_{2,1} & x_{2,2} \\\\\n",
        "& & \\vdots\\\\\n",
        "1 & x_{N,1} & x_{N,2} \\\\\n",
        "\\end{pmatrix}\n",
        "\\qquad\n",
        "Y = \\begin{pmatrix}\n",
        "y_1\\\\ y_2 \\\\ \\vdots \\\\ y_N\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "とすると，正規方程式は\n",
        "\n",
        "$$\n",
        "X^{\\top}X\n",
        "\\begin{pmatrix}\n",
        "\\hat{w}_0 \\\\ \\hat{w}_1 \\\\ \\hat{w}_2\n",
        "\\end{pmatrix} =\n",
        "X^{\\top}Y\n",
        "$$\n",
        "\n",
        "と書けます．\n",
        "ここで，左辺の $(D+1)\\times (D+1)$ （いまは $3\\times 3$）行列 $X^{\\top}X$ に注目すると，\n",
        "\n",
        "$$\n",
        "X^{\\top}X = \n",
        "\\begin{pmatrix}\n",
        "1 & 1 & & 1\\\\\n",
        "x_{1,1} & x_{2,1} & \\cdots & x_{N,1} \\\\\n",
        "x_{1,2} & x_{2,2} & \\cdots & x_{N,2} \\\\\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "1 & x_{1,1} & x_{1,2} \\\\\n",
        "1 & x_{2,1} & x_{2,2} \\\\\n",
        "& & \\vdots\\\\\n",
        "1 & x_{N,1} & x_{N,2} \\\\\n",
        "\\end{pmatrix}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "\\sum 1 & \\sum x_{n,1} & \\sum x_{n,2}\\\\\n",
        "\\sum x_{n,1} & \\sum x_{n,1}x_{n,1} & \\sum x_{n,1}x_{n,2}\\\\\n",
        "\\sum x_{n,2} & \\sum x_{n,2}x_{n,1} & \\sum x_{n,2}x_{n,2}\\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "です．\n"
      ],
      "metadata": {
        "id": "6Oa62yhqBXA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "この問題設定において，2つの説明変数 $x_{n,1}$ と $x_{n,2}$ の間に，$k$を定数として\n",
        "\n",
        "$$\n",
        "x_{n,2} = kx_{n,1}\n",
        "$$\n",
        "\n",
        "という関係が成り立っていたとしましょう．2つの変数の一方がもう一方の定数倍で表せてしまいますので，本来はどちらか一方の変数だけ使って回帰分析すればよいはずの状況です．\n",
        "\n",
        "このとき，\n",
        "\n",
        "$$\n",
        "X^{\\top}X = \\begin{pmatrix}\n",
        "\\sum 1 & \\sum x_{n,1} & k\\sum x_{n,1}\\\\\n",
        "\\sum x_{n,1} & \\sum x_{n,1}x_{n,1} & k\\sum x_{n,1}x_{n,1}\\\\\n",
        "k\\sum x_{n,1} & k\\sum x_{n,1}x_{n,1} & k^2\\sum x_{n,1}x_{n,1}\\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "となるため，この行列の第3行が第2行のちょうど $k$ 倍となります（第3列も第2列の$k$倍）．\n",
        "これでは，この行列のランク（階数）が1つ下がってしまい，この行列が逆行列を持ち得なくなってしまいます．\n",
        "言い換えると，連立方程式に含まれる未知数の数に比べて方程式の数が1つ足りなくなっています（解が不定）．\n",
        "統計分析ツールは，このような場合でも回帰係数の推定値を出力してくれたりしますが，分析結果に様々な悪影響が及びます．\n"
      ],
      "metadata": {
        "id": "KlcC0KddFGtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "ここではある変数が厳密な意味で他の変数の定数倍になっている（両者の相関係数が $1$ または $-1$ である）ケースを考えましたが，厳密に定数倍でなくとも，相関係数が $\\pm 1$ に近くなっているような場合には，数値計算の精度の問題で同様のことが起こります．ある変数が他の変数たちの線形結合で表せてしまうような場合（注）も同じです．\n",
        "データにこのような性質がある場合，「データに**多重共線性**がある」といいます．\n",
        "\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: 定数 $p,q,r$ に対して $(ある変数) \\approx p\\times (別の変数) + q\\times (また別の変数) + r$ みたいな関係がある場合．\n",
        "</span>\n",
        "\n",
        "実際に重回帰分析を行う場合には，変数間の相関係数を調べる等して，多重共線性の有無を考慮することが必要となります．"
      ],
      "metadata": {
        "id": "ueNpRVzIJVFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  (小テスト, 睡眠時間, ほげ) vs 期末テスト\n",
        "X = df.loc[:, ['小テスト', '睡眠時間']].to_numpy()\n",
        "Y = df['期末テスト'].to_numpy()\n",
        "X = np.vstack([X.T, -2*X[:, 0]]).T # 1列目の (-2) 倍の値の列を付加\n",
        "X1 = sm.add_constant(X)\n",
        "print(X1)\n",
        "model = sm.OLS(Y, X1)\n",
        "rv = model.fit()\n",
        "print(rv.summary())"
      ],
      "metadata": {
        "id": "DAr_DEdFJ_Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "試しにやってみると上記のような結果が得られます．出力をよくみると，\n",
        "\n",
        "- 正規方程式の条件数（`Cond. No.`）が極端に大きい（悪い）．「条件数」は，連立方程式などの問題が数値計算に適しているかどうかを表す指標です．\n",
        "- それに関連して，`Notes` の二つ目に `This might indicate that there are strong multicollinearity problems or that the design matrix is singular.` という注意が出ている（*multicollinerity* = 多重共線性）．\n",
        "\n",
        "のが分かります．しかし，それに気づかないで回帰係数の検定の結果を見ると，変数`x1`も`x3` もどちらも有用なものだ（実際には一方は不必要）という主張をしてしまいかねません．\n"
      ],
      "metadata": {
        "id": "-hnC0bn9J9Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_iyImDyd5lGM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}