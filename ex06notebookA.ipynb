{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNTpG2wtNqgKWyPNGrJQ+Yd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takatakamanbou/MVA/blob/2023/ex06notebookA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MVA2023 ex06notebookA\n",
        "\n",
        "<img width=64 src=\"https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/MVA-logo.png\"> https://www-tlab.math.ryukoku.ac.jp/wiki/?MVA/2023"
      ],
      "metadata": {
        "id": "P4preLw7SzqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# いろいろインポート\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "seaborn.set()"
      ],
      "metadata": {
        "id": "9HCsHgFjR6jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "## 主成分分析 (2)\n",
        "----\n",
        "\n",
        "前回に続き，**主成分分析** (Principal Component Analysis, PCA) について考えます．\n",
        "\n"
      ],
      "metadata": {
        "id": "W3zGBgJJSWv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "前回の結果をまとめておきます．**1つのデータ（1つの標本）を列ベクトルとして扱っていることに注意** してください．前回も，考え方や理論を説明する notebookA ではそのようにして，Python + NumPy で実際に計算してみる notebookB では行ベクトルとして扱ったのでした．\n",
        "\n",
        "---\n",
        "\n",
        "［主成分分析］\n",
        "\n",
        "$N$個の$D$次元ベクトルから成るデータ\n",
        "\n",
        "$$\n",
        "\\{ \\mathbf{x}_n \\in {\\cal R}^{D} | n = 1, 2, \\ldots, N\\}\n",
        "$$\n",
        "\n",
        "を，$D \\times H$ 行列 $U$ によって\n",
        "\n",
        "$$\n",
        "\\mathbf{y}_n = U^{\\top}\\mathbf{x}_n\n",
        "$$\n",
        "\n",
        "と $H$ 次元に変換することを考える．ただし，$\\{\\mathbf{x}_n\\}$ の平均は $\\mathbf{0}$ とする．\n",
        "このとき，変換後のデータの分散がなるべく大きくなるように（元のデータの分散を保つように）したいならば，$U$ を次のように構成すればよい．\n",
        "\n",
        "1. データの分散共分散行列の固有値と固有ベクトルを求める．固有値を $\\lambda_1 \\geq \\lambda_2 \\geq \\lambda_3 \\geq \\cdots \\geq \\lambda_D$ とし，それぞれに対応する固有ベクトルを $\\mathbf{u}_1, \\mathbf{u}_2, \\ldots, \\mathbf{u}_D$ とおく．\n",
        "2. $\\mathbf{u}_1, \\mathbf{u}_2, \\ldots, \\mathbf{u}_H$ を並べてできる $D\\times H$ 行列を $U$ とする．ただし，1列目に $\\mathbf{u}_1$，2列目に $\\mathbf{u}_2$，...，と並べる．つまり，$U$ は次の通り．\n",
        "\n",
        "$$\n",
        "U =\n",
        "\\begin{pmatrix}\n",
        "\\mathbf{u}_{1} & \\mathbf{u}_{2} & \\cdots & \\mathbf{u}_{H}\n",
        "\\end{pmatrix} \\qquad (1)\n",
        "$$\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "OrEf0iSLUtkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 変換後のデータの性質\n",
        "\n",
        "主成分分析の成り立ちから，主成分（変換後のデータ）がもつ性質を知ることができます．"
      ],
      "metadata": {
        "id": "uSJ-5Dgz1v2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "［主成分の平均も $\\mathbf{0}$ となる］\n",
        "\n",
        "元のデータの平均が $\\mathbf{0}$ である，つまり，$\\frac{1}{N}\\sum_{n=1}^{N}\\mathbf{x}_n = \\mathbf{0}$ であることから，次のように，主成分すなわち変換後のデータの平均も $\\mathbf{0}$ であることが分かります．\n",
        "\n",
        "$$\n",
        "\\frac{1}{N}\\sum_{n=1}^{N}\\mathbf{y}_n = \\frac{1}{N}\\sum_{n=1}^{N}U^{\\top}\\mathbf{x}_n = U^{\\top}\\left( \\frac{1}{N}\\sum_{n=1}^{N}\\mathbf{x}_n \\right) = U^{\\top}\\mathbf{0} = \\mathbf{0}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "eBqVySOx15_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "［主成分の分散共分散行列は，元のデータの分散共分散行列の固有値が並んだ対角行列となる］\n",
        "\n",
        "元のデータ $\\{ \\mathbf{x}_n \\}$ の分散共分散行列を $V_x = \\frac{1}{N}\\sum_{n=1}^{N}\\mathbf{x}_n\\mathbf{x}_n^{\\top}$ とおくと，↑のことから，$\\{ \\mathbf{y}_n \\}$ の分散共分散行列 $V_y$ は次式のように表せます．\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "V_y &= \\frac{1}{N}\\sum_{n=1}^{N}\\mathbf{y}_n\\mathbf{y}_n^{\\top}\n",
        "= \\frac{1}{N}\\sum_{n=1}^{N}\\left(U^{\\top}\\mathbf{x}_n\\right)\\left(U^{\\top}\\mathbf{x}_n\\right)^{\\top} \\\\\n",
        "&= \\frac{1}{N}\\sum_{n=1}^{N} U^{\\top}\\mathbf{x}_n \\mathbf{x}_n^{\\top} U\n",
        "= U^{\\top}\\left(\\frac{1}{N}\\sum_{n=1}^{N} \\mathbf{x}_n \\mathbf{x}_n^{\\top} \\right) U \\\\\n",
        "&= U^{\\top}V_xU\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "ここで，式$(1)$より，\n",
        "\n",
        "$$\n",
        "V_y =\n",
        "\\begin{pmatrix}\n",
        "\\mathbf{u}_{1}^{\\top} \\\\\n",
        "\\mathbf{u}_{2}^{\\top} \\\\\n",
        "\\vdots \\\\\n",
        "\\mathbf{u}_{H}^{\\top} \\\\\n",
        "\\end{pmatrix}\n",
        "V_x\n",
        "\\begin{pmatrix}\n",
        "\\mathbf{u}_{1} & \\mathbf{u}_{2} & \\cdots \\mathbf{u}_{H}\n",
        "\\end{pmatrix}\n",
        "= \\begin{pmatrix}\n",
        "\\lambda_1 & & & \\\\\n",
        " & \\lambda_2 & & \\\\\n",
        " & & \\ddots & \\\\\n",
        " & & & \\lambda_H \\\\\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "\n",
        "が成り立ちます．ちょうど $H = D$ のときは，この式は $V_x$ の対角化そのものですね（注）．\n",
        "\n",
        "※注: $U = (\\mathbf{u}_{1}\\ \\mathbf{u}_2\\ \\cdots\\ \\mathbf{u}_{D})$ として，$U^{\\top}V_xU = \\textrm{diag}(\\lambda_1, \\lambda_2, \\ldots, \\lambda_D)$．\n",
        "\n"
      ],
      "metadata": {
        "id": "LMfaMxZJ46_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "主成分 $\\{ \\mathbf{y}_n \\}$ の分散共分散行列が対角行列になるということは，各主成分の間の共分散が $0$ であり，したがって相関係数も $0$ である（相関がない）ことを意味します．\n",
        "さらに，$\\lambda_1 \\geq \\lambda_2 \\geq \\cdots \\geq \\lambda_D$ から，番号の小さな主成分ほど分散が大きいことも分かります．"
      ],
      "metadata": {
        "id": "5ddPgsHC73wF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，乱数で作った2次元のデータに主成分分析を適用します．上記の性質が成り立っていることを確認しましょう．"
      ],
      "metadata": {
        "id": "yqsGMDRu9o3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2次元のデータを生成して X に入れる\n",
        "N = 500\n",
        "cov = np.array([[5, np.sqrt(3)], [np.sqrt(3), 1]])\n",
        "rng = np.random.default_rng(0)\n",
        "X = rng.multivariate_normal(mean=np.array([0, 0]), cov=cov, size=N)\n",
        "print('X.shape = ', X.shape)\n",
        "\n",
        "# X の分散共分散行列 Vx を求める\n",
        "Vx = X.T @ X / N\n",
        "print()\n",
        "print('Vx = ')\n",
        "print(Vx)\n",
        "\n",
        "# Vx の固有値・固有ベクトルを求める\n",
        "U, eval, Vt = np.linalg.svd(Vx)\n",
        "print()\n",
        "print('eval = ', eval)\n",
        "print('U = ')\n",
        "print(U)\n",
        "\n",
        "# Y ← X を U で変換\n",
        "#    U には固有ベクトルが列ベクトルとして入っているので，X @ U.T ではない\n",
        "Y = X @ U\n",
        "print()\n",
        "print('Y.shape = ', Y.shape)\n",
        "\n",
        "# Y の分散共分散行列 Vy を求める\n",
        "Vy = Y.T @ Y / N\n",
        "print()\n",
        "print('Vy = ')\n",
        "print(Vy)"
      ],
      "metadata": {
        "id": "qkdSD7dOvN4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Vy` の対角要素が `eval` と等しく，非対角要素がほぼ 0 になっていることが分かりますね．`X` と `Y` の散布図を描くとこんなんなります．"
      ],
      "metadata": {
        "id": "QGix9YxE-ZW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 左が X の散布図，右が Y の散布図\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "ax[0].scatter(X[:, 0], X[:, 1])\n",
        "ax[0].set_xlim(-10, 10)\n",
        "ax[0].set_ylim(-10, 10)\n",
        "ax[0].set_aspect('equal')\n",
        "ax[0].axhline(0, color='gray')\n",
        "ax[0].axvline(0, color='gray')\n",
        "ax[1].scatter(Y[:, 0], Y[:, 1])\n",
        "ax[1].set_xlim(-10, 10)\n",
        "ax[1].set_ylim(-10, 10)\n",
        "ax[1].set_aspect('equal')\n",
        "ax[1].axhline(0, color='gray')\n",
        "ax[1].axvline(0, color='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7tFB4qkx-xCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 寄与率と累積寄与率\n",
        "\n",
        "$D$ 次元のデータを $H$ 次元にできるというのは分かりましたが，$H$ をいくつにするかはどうやって決めればよいのでしょうか？\n"
      ],
      "metadata": {
        "id": "Su1NceZ4AngQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "一般に，「正方行列の対角要素の和は，その行列のすべての固有値の和に等しい」という性質が成り立ちます．これを分散共分散行列に当てはめて考えると，次のことがいえます（記号は↑で使っているものと同じです）．\n",
        "\n",
        "\n",
        "$$\n",
        "\\sum_{d=1}^{D} (d\\mbox{番目の変数 $\\{x_{n,d}\\}$ の分散}) = \\sum_{d=1}^{D}\\lambda_d\n",
        "$$\n",
        "\n",
        "この式の左辺は，「元のデータの変数ごとの分散」の総和です．一方右辺は，「変換後のデータの性質」での議論から分かるように，「主成分（変換後のデータの変数）ごとの分散」の総和に等しくなります．\n",
        "\n",
        "このことから，$H = D$ の場合，変換後も「変数ごとの分散の総和」が保たれることが分かります．\n",
        "一方，$H < D$ の場合，変換後の「変数ごとの分散の総和」は $\\sum_{d=1}^{H}\\lambda_d$ （和は $D$ までではなく $H$ まで）となり，次元を削減したせいで元データの「変数ごとの分散の総和」より減少することになります．\n"
      ],
      "metadata": {
        "id": "uEBzsz5R-sZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以上の議論から，$\\sum_{d=1}^{D}\\lambda_d$ に対する $\\lambda_d$ の比\n",
        "\n",
        "$$\n",
        "c_d = \\frac{\\lambda_d}{\\sum_{i=1}^{D}\\lambda_{i}} \\qquad (d = 1, 2, \\ldots, D)\n",
        "$$\n",
        "\n",
        "の値によって，$d$番目の主成分が「変数ごとの分散の総和」のうちどのくらいの割合を表しているのかを測れることが分かります．この値のことを，**寄与率** (contribution ratio)といいます．\n",
        "$0 \\leq c_d \\leq 1$ かつ $c_1 \\geq c_2 \\geq \\cdots \\geq c_D$ です．\n"
      ],
      "metadata": {
        "id": "7uMGvW9KFiXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "また，\n",
        "\n",
        "\n",
        "$$\n",
        "\\tilde{c}_h = \\frac{\\sum_{i=1}^{h}\\lambda_{i}}{\\sum_{i=1}^{D}\\lambda_{i}}\n",
        "= \\sum_{i=1}^{h}c_{i}\\qquad (h = 1, 2, \\ldots, D)\n",
        "$$\n",
        "\n",
        "という値は，第1主成分から第$h$主成分までを取り出して $h$ 次元に次元削減したときに，「変数ごとの分散の総和」がどのくらい保たれるかを表すことになります．\n",
        "これを **累積寄与率** (cumulative contrivution ratio) といいます．$0 \\leq \\tilde{c}_d \\leq 1$ かつ $\\tilde{c}_1 \\leq \\tilde{c}_2 \\leq \\cdots \\leq \\tilde{c}_D = 1$ です．"
      ],
      "metadata": {
        "id": "MxJvEx8YHo7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "寄与率や累積寄与率は，主成分分析の結果を吟味する際の指標となります．主成分分析を用いて100次元のデータを10次元にしたとして，10番目の主成分までの累積寄与率が大きければ（$1$に近ければ），上位10個の主成分が元のデータをよく表しているといえるでしょう．逆にその累積寄与率が小さければ，削減後の次元をもっと大きくした方がよいでしょう．次元削減を目的として主成分分析を行う場合は，累積寄与率の目標を定めておいて（0.8とか0.9とか），累積寄与率がその値以上となる最小の次元数を $H$ に選ぶ，ということをします．"
      ],
      "metadata": {
        "id": "M4eZU6lFLDeE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "前回使った国語・数学・英語の点数30人分のデータで寄与率・累積寄与率を求めてみましょう．"
      ],
      "metadata": {
        "id": "d_QNMEibRqFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 国数英\n",
        "dfJME = pd.read_csv('https://www-tlab.math.ryukoku.ac.jp/~takataka/course/MVA/jme.txt', delimiter=' ', header=None)\n",
        "dfJME.rename(columns={0:'国語', 1:'数学', 2:'英語'}, inplace=True)\n",
        "dfJME.head(5)"
      ],
      "metadata": {
        "id": "gy-ZfCnDNt9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 平均を引いたデータを X とする\n",
        "Xorg = dfJME.to_numpy()\n",
        "X = Xorg - np.mean(Xorg, axis=0)\n",
        "N, D = X.shape\n",
        "print(f'N = {N}, D = {D}')\n",
        "\n",
        "# Xの共分散行列とその対角和\n",
        "Vx = X.T @ X / N\n",
        "print()\n",
        "print('Vx = ')\n",
        "print(Vx, Vx.shape)\n",
        "print(f'(Xの変数ごとの分散の和) = (Vxの対角和) = {np.trace(Vx):.2f}')\n",
        "\n",
        "# Vx の固有値・固有ベクトル\n",
        "U, eval, Vt = np.linalg.svd(Vx)\n",
        "print()\n",
        "print('eval = ', eval)\n",
        "print(f'sum(eval) = {np.sum(eval):.2f}')\n",
        "#print('U = ')\n",
        "#print(U, U.shape)\n",
        "\n",
        "# 寄与率と累積寄与率\n",
        "c = eval / np.sum(eval)\n",
        "print()\n",
        "print('寄与率:　　', c)\n",
        "cc = np.cumsum(c)  # np.cumsum がやってるのは以下と同じ\n",
        "'''\n",
        "cc = np.empty_like(c)\n",
        "cc[0] = c[0]\n",
        "for d in range(1, len(c)):\n",
        "    cc[d] = cc[d-1] + c[d]\n",
        "'''\n",
        "print('累積寄与率:', cc)\n"
      ],
      "metadata": {
        "id": "zIDQBaM6N0uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このデータの場合，第1主成分だけで元の分散の 81%，第2主成分までだと元の分散の 98% を表していることが分かりますね．"
      ],
      "metadata": {
        "id": "SPyKidrnSGkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 主成分負荷量\n",
        "\n",
        "前回の notebookB では，固有ベクトルの要素の値を見て，各主成分がどのような量を表しているかを解釈することを試みていました．第 $h$ 主成分 $y_h$ が\n",
        "\n",
        "$$\n",
        "y_h = u_{h,1}x_1 + u_{h,2}x_2 + \\cdots + u_{h,D}x_D\n",
        "$$\n",
        "\n",
        "と表される場合，「変数 $x_1$ が $1$ だけ大きくなると $y_h$ の値は $u_{h,1}$ だけ大きくなる」ということがいえるので，$u_{h,d}$ ($d=1,2,\\ldots,D$) の値から $y_h$ がどのような量を表すか解釈する，ということでした．\n",
        "\n",
        "この方法も有効ですが，元データの変数ごとの分散が不揃いな場合，解釈が難しくなります（分散が小さい変数と大きい変数では，値が $1$ 大きくなることの意味が違ってきます）．その点を考慮して，主成分分析の結果を解釈する際には，次式で定義される **主成分負荷量**（注） を用いることがあります．\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "L(d,h) &= (\\mbox{元データの $d$ 番目の変数と第 $h$ 主成分との主成分負荷量})\\\\\n",
        "& = (\\mbox{両者の間の相関係数}) = \\frac{\\mbox{$x_{d}$と$y_{h}$の共分散}}{\\sqrt{\\mbox{$x_{d}$の分散}}\\sqrt{\\mbox{$y_{h}$の分散}}}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "導出は省略しますが，主成分負荷量は，上の定義の通りに求めるかわりに，次式のように元の変数の分散（分散共分散行列の対角要素） $s_{d}^2$，分散共分散行列の固有値 $\\lambda_h$ と固有ベクトルの要素 $u_{h,d}$ から計算することもできます．\n",
        "\n",
        "$$\n",
        "L(d, h) = \\sqrt{\\frac{\\lambda_h}{s_{d}^2}} u_{h,d}\n",
        "$$\n",
        "\n",
        "ただし，$u_{h,d}$ は，$\\lambda_h$ に対応する固有ベクトル $\\mathbf{u}_h$ の $d$ 番目の要素を表します．\n",
        "\n",
        "<span style=\"font-size: 75%\">\n",
        "※注: 主成分分析と似た多変量解析手法である「因子分析」に現れる「因子負荷量」という量と同じ概念のものであるため，「因子負荷量」と呼ばれることもあります．\n",
        "</span>"
      ],
      "metadata": {
        "id": "W4hruQD00B1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下に，上で使った国数英のデータについて求めた主成分負荷量を示します．"
      ],
      "metadata": {
        "id": "Ih4FeOSINMwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (d, h) 要素 = L(d, h)，第 h 列が第 h 主成分の主成分負荷量\n",
        "Lmat = np.diag(np.diag(Vx)**(-0.5)) @ U @ np.diag(np.sqrt(eval))\n",
        "print('              国語         数学         英語')\n",
        "for h in range(3):\n",
        "    print(f'第{h+1}主成分:', end=' ')\n",
        "    print(Lmat[:, h])"
      ],
      "metadata": {
        "id": "--Cd6wa8Jhwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "第1主成分は3つの変数すべてと強い負の相関があり，それぞれの科目の点数が平均より高いと第1主成分の値は小さくなることが分かります．したがって，前回の notebookB で考察したように，第1主成分は\n",
        "「3科目の総合力」（ただし値が小さい方が総合力が高い）を表すと解釈できます．\n",
        "\n",
        "第2主成分は国語と正の相関，数学と負の相関があり，英語とはあまり相関がないため，第2主成分は「国語 - 数学」 （数学と比べた国語の得意度合い，値が大きい方が数学に比べて国語が得意）と解釈できます．"
      ],
      "metadata": {
        "id": "HNr5VmytNdf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 主成分分析とデータの標準化"
      ],
      "metadata": {
        "id": "BminNFg9PXbB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "主成分分析の結果は，変数ごとの分散の大きさによって変化します．あるデータをそのまま主成分分析した場合と，一つの変数を定数倍してから主成分分析した場合では，異なる結果が導かれます．したがって，変数の単位のとり方を変えると結果が変わってしまいます．"
      ],
      "metadata": {
        "id": "GJZr3seSXzWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次のセルを実行すると，乱数を生成して作ったデータ `X` と，その変数の1つを $1/5$ 倍したデータ `X2` のそれぞれを主成分分析した結果を出力します．"
      ],
      "metadata": {
        "id": "j6SHe3cNZAgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2次元のデータを生成して X に入れる\n",
        "N = 500\n",
        "cov = np.array([[5, np.sqrt(3)], [np.sqrt(3), 1]])\n",
        "rng = np.random.default_rng(0)\n",
        "X = rng.multivariate_normal(mean=np.array([0, 0]), cov=cov, size=N)\n",
        "\n",
        "# 分散共分散行列の固有値・固有ベクトルを求める\n",
        "U, eval, _ = np.linalg.svd(X.T @ X / N)\n",
        "print()\n",
        "print('### X の分散共分散行列の固有値と固有ベクトル')\n",
        "print('eval = ', eval)\n",
        "print('U = ')\n",
        "print(U)\n",
        "\n",
        "# Y ← X を U で変換\n",
        "Y = X @ U\n",
        "\n",
        "# X の0列目を 1/5 倍したものを X2 とする\n",
        "X2 = np.copy(X)\n",
        "X2[:, 0] /= 5\n",
        "\n",
        "# Vx2 の固有値・固有ベクトルを求める\n",
        "U2, eval2, _ = np.linalg.svd(X2.T @ X2 / N)\n",
        "print()\n",
        "print('### X2 の分散共分散行列の固有値と固有ベクトル')\n",
        "print('eval2 = ', eval2)\n",
        "print('U2 = ')\n",
        "print(U2)\n",
        "\n",
        "# Y2 ← X2 を U で変換\n",
        "Y2 = X2 @ U2"
      ],
      "metadata": {
        "id": "4EmC1u4FQLU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 左が X の散布図，右が X2 の散布図\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "ax[0].scatter(X[:, 0], X[:, 1], label='X')\n",
        "xx = np.array([-10, 10])\n",
        "yy = xx * U[1, 0] / U[0, 0]\n",
        "ax[0].plot(xx, yy, color='red') # 第1主成分軸\n",
        "ax[0].set_xlim(-10, 10)\n",
        "ax[0].set_ylim(-10, 10)\n",
        "ax[0].set_aspect('equal')\n",
        "ax[0].axhline(0, color='gray')\n",
        "ax[0].axvline(0, color='gray')\n",
        "ax[0].legend()\n",
        "ax[1].scatter(X2[:, 0], X2[:, 1], label='X2')\n",
        "xx = np.array([-10, 10])\n",
        "yy = xx * U2[1, 0] / U2[0, 0]\n",
        "ax[1].plot(xx, yy, color='red') # 第1主成分軸\n",
        "ax[1].set_xlim(-10, 10)\n",
        "ax[1].set_ylim(-10, 10)\n",
        "ax[1].set_aspect('equal')\n",
        "ax[1].axhline(0, color='gray')\n",
        "ax[1].axvline(0, color='gray')\n",
        "ax[1].legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tZ84jqSmRaEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "赤い直線はそれぞれの第1主成分の方向（最大固有値に対応した固有ベクトルの方向）です．当然ですが，両者で全く異なっています．"
      ],
      "metadata": {
        "id": "nDPvp_TmZcZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "実際に主成分分析を行う際は，このような問題を避けるために，あらかじめデータの各変数を **標準化** しておくことがよくあります．標準化とは，データの平均を $0$ に，分散を $1$ にする処理のことです（※）．\n",
        "\n",
        "※注: 「データ分析」を履修したひとは，「データの正規化（標準化）」の話で登場しています．\n",
        "そのときの資料が参考になるかもしれません （2023年度「データ分析」[第6回](https://www-tlab.math.ryukoku.ac.jp/wiki/?Data/2023#ex06)）．\n",
        "\n"
      ],
      "metadata": {
        "id": "uR6FHRciaRMz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "データを標準化したものの分散共分散行列は，元のデータの変数間の相関係数をならべた行列（これを「相関行列」と呼びます）と一致します．そのため，標準化しない主成分分析のことを「分散共分散行列を用いる主成分分析」，標準化してから行う主成分分析を「相関行列を用いる主成分分析」と呼ぶことがあります．"
      ],
      "metadata": {
        "id": "ufBl-ssXcWDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "実際にデータを標準化して主成分分析を行う手順は，演習課題の方でやってみることにして，ここでは実例の紹介は省略します．"
      ],
      "metadata": {
        "id": "JlcszKI4dSvH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RrdAOFMSbhKF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}